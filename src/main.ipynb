{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pancreatic Cancer Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from dataset import Dataset\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "torch.manual_seed(94)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>patient_cohort</th>\n",
       "      <th>sample_origin</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>stage</th>\n",
       "      <th>benign_sample_diagnosis</th>\n",
       "      <th>plasma_CA19_9</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>LYVE1</th>\n",
       "      <th>REG1B</th>\n",
       "      <th>TFF1</th>\n",
       "      <th>REG1A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1</td>\n",
       "      <td>Cohort1</td>\n",
       "      <td>BPTB</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1.83222</td>\n",
       "      <td>0.893219</td>\n",
       "      <td>52.94884</td>\n",
       "      <td>654.282174</td>\n",
       "      <td>1262.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S10</td>\n",
       "      <td>Cohort1</td>\n",
       "      <td>BPTB</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97266</td>\n",
       "      <td>2.037585</td>\n",
       "      <td>94.46703</td>\n",
       "      <td>209.488250</td>\n",
       "      <td>228.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S100</td>\n",
       "      <td>Cohort2</td>\n",
       "      <td>BPTB</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.78039</td>\n",
       "      <td>0.145589</td>\n",
       "      <td>102.36600</td>\n",
       "      <td>461.141000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S101</td>\n",
       "      <td>Cohort2</td>\n",
       "      <td>BPTB</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.70122</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>60.57900</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S102</td>\n",
       "      <td>Cohort2</td>\n",
       "      <td>BPTB</td>\n",
       "      <td>62</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.21489</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>65.54000</td>\n",
       "      <td>41.088000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_id patient_cohort sample_origin  age sex  diagnosis stage   \n",
       "0        S1        Cohort1          BPTB   33   F          1   NaN  \\\n",
       "1       S10        Cohort1          BPTB   81   F          1   NaN   \n",
       "2      S100        Cohort2          BPTB   51   M          1   NaN   \n",
       "3      S101        Cohort2          BPTB   61   M          1   NaN   \n",
       "4      S102        Cohort2          BPTB   62   M          1   NaN   \n",
       "\n",
       "  benign_sample_diagnosis  plasma_CA19_9  creatinine     LYVE1      REG1B   \n",
       "0                     NaN           11.7     1.83222  0.893219   52.94884  \\\n",
       "1                     NaN            NaN     0.97266  2.037585   94.46703   \n",
       "2                     NaN            7.0     0.78039  0.145589  102.36600   \n",
       "3                     NaN            8.0     0.70122  0.002805   60.57900   \n",
       "4                     NaN            9.0     0.21489  0.000860   65.54000   \n",
       "\n",
       "         TFF1     REG1A  \n",
       "0  654.282174  1262.000  \n",
       "1  209.488250   228.407  \n",
       "2  461.141000       NaN  \n",
       "3  142.950000       NaN  \n",
       "4   41.088000       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "urinary_data = Dataset(filePath='../data/urinary_data.csv',\n",
    "                       label_column='diagnosis',\n",
    "                       separator=',', \n",
    "                       name='urinary_data')\n",
    "display(urinary_data.dataframe.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset cleaning and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>patient_cohort</th>\n",
       "      <th>sample_origin</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>stage</th>\n",
       "      <th>benign_sample_diagnosis</th>\n",
       "      <th>plasma_CA19_9</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>LYVE1</th>\n",
       "      <th>REG1B</th>\n",
       "      <th>TFF1</th>\n",
       "      <th>REG1A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "      <td>181</td>\n",
       "      <td>337</td>\n",
       "      <td>391</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>266</td>\n",
       "      <td>93</td>\n",
       "      <td>265</td>\n",
       "      <td>402</td>\n",
       "      <td>242</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>62</td>\n",
       "      <td>75</td>\n",
       "      <td>108</td>\n",
       "      <td>412</td>\n",
       "      <td>347</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>47</td>\n",
       "      <td>351</td>\n",
       "      <td>209</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>70</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>360</td>\n",
       "      <td>117</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id  patient_cohort  sample_origin  age  sex  diagnosis  stage   \n",
       "0          0               0              0    6    0          0      8  \\\n",
       "1          1               0              0   54    0          0      8   \n",
       "2          2               1              0   24    1          0      8   \n",
       "3          3               1              0   34    1          0      8   \n",
       "4          4               1              0   35    1          0      8   \n",
       "\n",
       "   benign_sample_diagnosis  plasma_CA19_9  creatinine  LYVE1  REG1B  TFF1   \n",
       "0                       52             78         158    181    337   391  \\\n",
       "1                       52            266          93    265    402   242   \n",
       "2                       52             62          75    108    412   347   \n",
       "3                       52             67          68     47    351   209   \n",
       "4                       52             70          16     14    360   117   \n",
       "\n",
       "   REG1A  \n",
       "0    247  \n",
       "1    151  \n",
       "2    298  \n",
       "3    298  \n",
       "4    298  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: 0 rows | 1 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_cohort</th>\n",
       "      <th>sample_origin</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>stage</th>\n",
       "      <th>benign_sample_diagnosis</th>\n",
       "      <th>plasma_CA19_9</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>LYVE1</th>\n",
       "      <th>REG1B</th>\n",
       "      <th>TFF1</th>\n",
       "      <th>REG1A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "      <td>181</td>\n",
       "      <td>337</td>\n",
       "      <td>391</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>266</td>\n",
       "      <td>93</td>\n",
       "      <td>265</td>\n",
       "      <td>402</td>\n",
       "      <td>242</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>62</td>\n",
       "      <td>75</td>\n",
       "      <td>108</td>\n",
       "      <td>412</td>\n",
       "      <td>347</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>47</td>\n",
       "      <td>351</td>\n",
       "      <td>209</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>70</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>360</td>\n",
       "      <td>117</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_cohort  sample_origin  age  sex  diagnosis  stage   \n",
       "0               0              0    6    0          0      8  \\\n",
       "1               0              0   54    0          0      8   \n",
       "2               1              0   24    1          0      8   \n",
       "3               1              0   34    1          0      8   \n",
       "4               1              0   35    1          0      8   \n",
       "\n",
       "   benign_sample_diagnosis  plasma_CA19_9  creatinine  LYVE1  REG1B  TFF1   \n",
       "0                       52             78         158    181    337   391  \\\n",
       "1                       52            266          93    265    402   242   \n",
       "2                       52             62          75    108    412   347   \n",
       "3                       52             67          68     47    351   209   \n",
       "4                       52             70          16     14    360   117   \n",
       "\n",
       "   REG1A  \n",
       "0    247  \n",
       "1    151  \n",
       "2    298  \n",
       "3    298  \n",
       "4    298  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# urinary_data.cleanDataframe()\n",
    "# Encode labels\n",
    "for column in urinary_data.dataframe.columns:\n",
    "    urinary_data.encode_column(column)\n",
    "\n",
    "display(urinary_data.dataframe.head())\n",
    "\n",
    "# Dataset Cleaning\n",
    "urinary_data.cleanDataframe()\n",
    "\n",
    "display(urinary_data.dataframe.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Dataset split\n",
    "X = urinary_data.dataframe.iloc[:, urinary_data.dataframe.columns != urinary_data.label_column].squeeze()\n",
    "y = urinary_data.dataframe[urinary_data.label_column].values.reshape(-1, 1)\n",
    "# Transform y to tensor of size equal to the number of classes\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit(y)\n",
    "y = ohe.transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set sizes: Train: 377, Validation: 95, Test: 118\n",
      "X_train shape: torch.Size([377, 12])\n",
      "y_train shape: torch.Size([377, 3])\n",
      "X_val shape: torch.Size([95, 12])\n",
      "y_val shape: torch.Size([95, 3])\n",
      "X_test shape: torch.Size([118, 12])\n",
      "y_test shape: torch.Size([118, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Set sizes: Train: {}, Validation: {}, Test: {}\".format(len(X_train), len(X_val), len(X_test)))\n",
    "\n",
    "# Convert to tensors\n",
    "X_train = torch.from_numpy(X_train.values).float().squeeze()\n",
    "X_val = torch.from_numpy(X_val.values).float().squeeze()  \n",
    "X_test = torch.from_numpy(X_test.values).float().squeeze()\n",
    "y_train = torch.from_numpy(y_train).float().squeeze()\n",
    "y_val = torch.from_numpy(y_val).float().squeeze()\n",
    "y_test = torch.from_numpy(y_test).float().squeeze()\n",
    "\n",
    "\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"X_val shape: {}\".format(X_val.shape))\n",
    "print(\"y_val shape: {}\".format(y_val.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary for label column\n",
    "# 3 (pancreatic cancer), 2 (non-cancerous pancreas condition),  1 (healthy)\n",
    "label_dict = {1: 'healthy', 2: 'non-cancerous pancreas condition', 3: 'pancreatic cancer'}\n",
    "urinary_data.init_label_dictionary(label_column='diagnosis', label_dict=label_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.141438364982605, Accuracy: 0.42440319061279297, Test Loss: 1.1574848890304565, Test Accuracy: 0.41525423526763916\n",
      "Epoch: 10, Loss: 1.0597195625305176, Accuracy: 0.32625994086265564, Test Loss: 1.0404177904129028, Test Accuracy: 0.43220338225364685\n",
      "Epoch: 20, Loss: 1.0626325607299805, Accuracy: 0.3289124667644501, Test Loss: 1.0371259450912476, Test Accuracy: 0.3644067943096161\n",
      "Epoch: 30, Loss: 1.060034990310669, Accuracy: 0.29708221554756165, Test Loss: 1.0351332426071167, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 40, Loss: 1.0583877563476562, Accuracy: 0.29708221554756165, Test Loss: 1.0351332426071167, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 50, Loss: 1.0583741664886475, Accuracy: 0.29708221554756165, Test Loss: 1.0351332426071167, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 60, Loss: 1.0583739280700684, Accuracy: 0.29708221554756165, Test Loss: 1.0351332426071167, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 70, Loss: 1.058372139930725, Accuracy: 0.29708221554756165, Test Loss: 1.0351332426071167, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 80, Loss: 1.0588979721069336, Accuracy: 0.29708221554756165, Test Loss: 1.0351332426071167, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 90, Loss: 1.054739236831665, Accuracy: 0.29708221554756165, Test Loss: 1.0351332426071167, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 100, Loss: 1.052396297454834, Accuracy: 0.2944297194480896, Test Loss: 1.0351332426071167, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 110, Loss: 1.0465956926345825, Accuracy: 0.2944297194480896, Test Loss: 1.0258592367172241, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 120, Loss: 1.0444124937057495, Accuracy: 0.2944297194480896, Test Loss: 1.026910662651062, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 130, Loss: 1.0441712141036987, Accuracy: 0.2944297194480896, Test Loss: 1.0205059051513672, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 140, Loss: 1.0439558029174805, Accuracy: 0.29708221554756165, Test Loss: 1.0167574882507324, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 150, Loss: 1.0439404249191284, Accuracy: 0.29708221554756165, Test Loss: 1.016583800315857, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 160, Loss: 1.04391348361969, Accuracy: 0.29708221554756165, Test Loss: 1.016505241394043, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 170, Loss: 1.0439125299453735, Accuracy: 0.29708221554756165, Test Loss: 1.0164679288864136, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 180, Loss: 1.043911337852478, Accuracy: 0.29708221554756165, Test Loss: 1.0165292024612427, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 190, Loss: 1.043911099433899, Accuracy: 0.29708221554756165, Test Loss: 1.0165451765060425, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 200, Loss: 1.043911099433899, Accuracy: 0.29708221554756165, Test Loss: 1.016547679901123, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 210, Loss: 1.0439109802246094, Accuracy: 0.29708221554756165, Test Loss: 1.0165451765060425, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 220, Loss: 1.0439109802246094, Accuracy: 0.29708221554756165, Test Loss: 1.0165404081344604, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 230, Loss: 1.0439109802246094, Accuracy: 0.29708221554756165, Test Loss: 1.0165352821350098, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 240, Loss: 1.0439108610153198, Accuracy: 0.29708221554756165, Test Loss: 1.0165305137634277, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 250, Loss: 1.0439107418060303, Accuracy: 0.29708221554756165, Test Loss: 1.0165263414382935, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 260, Loss: 1.0439107418060303, Accuracy: 0.29708221554756165, Test Loss: 1.016523003578186, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 270, Loss: 1.0439107418060303, Accuracy: 0.29708221554756165, Test Loss: 1.0165201425552368, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 280, Loss: 1.0439107418060303, Accuracy: 0.29708221554756165, Test Loss: 1.0165175199508667, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 290, Loss: 1.0439107418060303, Accuracy: 0.29708221554756165, Test Loss: 1.0165152549743652, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 300, Loss: 1.0439107418060303, Accuracy: 0.29708221554756165, Test Loss: 1.0165129899978638, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 310, Loss: 1.0439107418060303, Accuracy: 0.29708221554756165, Test Loss: 1.0165109634399414, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 320, Loss: 1.0439107418060303, Accuracy: 0.29708221554756165, Test Loss: 1.0165088176727295, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 330, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0165066719055176, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 340, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0165045261383057, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 350, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0165024995803833, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 360, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016500473022461, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 370, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016498327255249, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 380, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164963006973267, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 390, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164942741394043, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 400, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164921283721924, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 410, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.01649010181427, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 420, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164881944656372, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 430, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164861679077148, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 440, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164841413497925, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 450, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164821147918701, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 460, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164800882339478, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 470, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016478180885315, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 480, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164761543273926, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 490, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164741277694702, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 500, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164721012115479, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 510, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016470193862915, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 520, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164681673049927, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 530, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164662599563599, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 540, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164642333984375, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 550, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164623260498047, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 560, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164602994918823, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 570, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164583921432495, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 580, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164563655853271, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 590, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164544582366943, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 600, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016452431678772, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 610, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164505243301392, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 620, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164486169815063, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 630, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016446590423584, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 640, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164446830749512, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 650, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164427757263184, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 660, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016440749168396, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 670, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164388418197632, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 680, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164369344711304, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 690, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164350271224976, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 700, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164331197738647, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 710, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016431212425232, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 720, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164293050765991, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 730, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164273977279663, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 740, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164254903793335, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 750, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164235830307007, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 760, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164217948913574, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 770, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016419768333435, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 780, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164179801940918, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 790, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016416072845459, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 800, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164141654968262, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 810, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164122581481934, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 820, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164103507995605, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 830, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164084434509277, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 840, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016406536102295, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 850, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016404628753662, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 860, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164027214050293, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 870, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0164008140563965, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 880, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163990259170532, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 890, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163969993591309, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 900, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163952112197876, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 910, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163931846618652, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 920, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163912773132324, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 930, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163893699645996, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 940, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163874626159668, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 950, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016385555267334, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 960, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163836479187012, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 970, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163817405700684, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 980, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163798332214355, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 990, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163779258728027, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1000, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.01637601852417, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1010, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016374111175537, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1020, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163722038269043, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1030, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163702964782715, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1040, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163683891296387, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1050, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163664817810059, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1060, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016364574432373, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1070, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163626670837402, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1080, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163607597351074, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1090, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016358733177185, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1100, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163569450378418, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1110, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163549184799194, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1120, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163530111312866, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1130, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163511037826538, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1140, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016349196434021, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1150, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163471698760986, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1160, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163452625274658, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1170, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016343355178833, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1180, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163413286209106, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1190, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163394212722778, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1200, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016337513923645, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1210, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163354873657227, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1220, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163335800170898, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1230, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163315534591675, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1240, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163296461105347, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1250, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163276195526123, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1260, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163257122039795, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1270, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163236856460571, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1280, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163217782974243, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1290, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016319751739502, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1300, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163177251815796, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1310, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163158178329468, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1320, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163136720657349, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1330, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016311764717102, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1340, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163097381591797, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1350, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163077116012573, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1360, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163058042526245, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1370, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163038969039917, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1380, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0163019895553589, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1390, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016300082206726, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1400, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162981748580933, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1410, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016296148300171, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1420, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016294240951538, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1430, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162923336029053, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1440, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162904262542725, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1450, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.01628839969635, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1460, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162863731384277, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1470, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016284465789795, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1480, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162824392318726, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1490, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162805318832397, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1500, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162785053253174, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1510, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016276478767395, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1520, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162745714187622, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1530, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162725448608398, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1540, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016270637512207, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1550, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162686109542847, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1560, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162665843963623, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1570, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.01626455783844, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1580, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162626504898071, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1590, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162606239318848, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1600, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162585973739624, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1610, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.01625657081604, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1620, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162545442581177, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1630, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162525177001953, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1640, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162503719329834, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1650, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162484645843506, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1660, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162464380264282, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1670, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162442922592163, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1680, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162421464920044, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1690, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162402391433716, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1700, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162382125854492, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1710, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162359476089478, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1720, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016234040260315, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1730, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162320137023926, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1740, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162298679351807, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1750, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162278413772583, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1760, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162256956100464, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1770, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016223669052124, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1780, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016221523284912, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1790, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162193775177002, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1800, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162172317504883, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1810, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016215205192566, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1820, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162131786346436, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1830, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016210913658142, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1840, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162087678909302, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1850, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162067413330078, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1860, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016204595565796, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1870, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016202449798584, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1880, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0162001848220825, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1890, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161981582641602, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1900, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161960124969482, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1910, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161937475204468, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1920, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161914825439453, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1930, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161893367767334, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1940, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016187310218811, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1950, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.01618492603302, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1960, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016182780265808, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1970, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161805152893066, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1980, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161783695220947, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 1990, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161762237548828, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2000, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161738395690918, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2010, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161714553833008, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2020, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161690711975098, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2030, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161668062210083, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2040, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161641836166382, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2050, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016161561012268, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2060, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016159176826477, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2070, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016156792640686, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2080, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161542892456055, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2090, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016151785850525, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2100, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161492824554443, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2110, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161467790603638, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2120, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161442756652832, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2130, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161418914794922, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2140, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016139268875122, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2150, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016136646270752, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2160, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161341428756714, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2170, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161316394805908, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2180, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161292552947998, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2190, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161266326904297, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2200, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.01612389087677, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2210, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161212682724, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2220, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161190032958984, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2230, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161163806915283, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2240, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161136388778687, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2250, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016110897064209, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2260, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161083936691284, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2270, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161060094833374, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2280, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161033868789673, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2290, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0161006450653076, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2300, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016097903251648, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2310, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160953998565674, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2320, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160928964614868, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2330, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160902738571167, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2340, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160876512527466, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2350, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016084909439087, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2360, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160822868347168, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2370, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160794258117676, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2380, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016076922416687, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2390, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160744190216064, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2400, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160716772079468, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2410, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016068696975708, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2420, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160658359527588, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2430, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160632133483887, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2440, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160608291625977, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2450, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016058087348938, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2460, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160549879074097, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2470, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016052007675171, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2480, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160493850708008, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2490, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160468816757202, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2500, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160443782806396, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2510, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160412788391113, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2520, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016038179397583, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2530, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160353183746338, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2540, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160326957702637, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2550, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016030192375183, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2560, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160274505615234, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2570, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160242319107056, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2580, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160211324691772, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2590, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160181522369385, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2600, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016015648841858, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2610, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160129070281982, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2620, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016010046005249, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2630, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160068273544312, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2640, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0160037279129028, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2650, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.016000747680664, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2660, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159980058670044, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2670, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159951448440552, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2680, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015992283821106, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2690, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159894227981567, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2700, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159862041473389, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2710, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159832239151, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2720, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159802436828613, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2730, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015977144241333, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2740, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159741640090942, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2750, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015971302986145, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2760, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159684419631958, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2770, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015965461730957, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2780, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159623622894287, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2790, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159592628479004, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2800, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015955924987793, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2810, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159529447555542, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2820, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159502029418945, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2830, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159472227096558, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2840, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015944242477417, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2850, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159409046173096, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2860, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159374475479126, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2870, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159342288970947, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2880, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159311294555664, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2890, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159275531768799, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2900, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159235000610352, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2910, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159193277359009, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2920, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159153938293457, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2930, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159108638763428, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2940, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159060955047607, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2950, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0159014463424683, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2960, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0158970355987549, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2970, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0158928632736206, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2980, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0158886909484863, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 2990, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0158840417861938, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3000, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0158793926239014, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3010, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0158748626708984, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3020, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015870451927185, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3030, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0158665180206299, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3040, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0158618688583374, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3050, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0158568620681763, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3060, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0158522129058838, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3070, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.01584792137146, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3080, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0158430337905884, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3090, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0158376693725586, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3100, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0158326625823975, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3110, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0158271789550781, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3120, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0158215761184692, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3130, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015816569328308, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3140, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0158110857009888, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3150, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0158058404922485, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3160, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015800952911377, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3170, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0157963037490845, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3180, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015791416168213, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3190, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015786051750183, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3200, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0157808065414429, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3210, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0157756805419922, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3220, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0157710313796997, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3230, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0157666206359863, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3240, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015762209892273, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3250, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015757441520691, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3260, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0157523155212402, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3270, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015747308731079, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3280, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015742540359497, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3290, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0157381296157837, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3300, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0157337188720703, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3310, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0157296657562256, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3320, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015724778175354, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3330, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0157197713851929, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3340, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0157146453857422, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3350, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0157099962234497, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3360, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0157057046890259, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3370, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0157015323638916, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3380, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0156975984573364, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3390, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015692949295044, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3400, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0156878232955933, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3410, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0156828165054321, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3420, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0156781673431396, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3430, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0156737565994263, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3440, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015669822692871, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3450, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0156657695770264, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3460, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0156608819961548, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3470, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0156551599502563, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3480, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0156500339508057, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3490, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0156455039978027, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3500, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0156406164169312, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3510, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.01563560962677, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3520, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0156307220458984, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3530, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015626072883606, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3540, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0156216621398926, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3550, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015617847442627, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3560, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0156139135360718, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3570, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0156089067459106, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3580, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.01560378074646, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3590, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0155987739562988, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3600, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015594244003296, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3610, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0155901908874512, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3620, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0155863761901855, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3630, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015582799911499, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3640, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0155794620513916, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3650, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0155757665634155, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3660, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0155709981918335, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3670, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0155659914016724, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3680, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0155613422393799, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3690, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015556812286377, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3700, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0155528783798218, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3710, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0155490636825562, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3720, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0155454874038696, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3730, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0155422687530518, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3740, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0155384540557861, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3750, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0155329704284668, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3760, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0155278444290161, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3770, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0155233144760132, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3780, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0155187845230103, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3790, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.01551353931427, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3800, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0155088901519775, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3810, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015504002571106, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3820, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.015499234199524, Test Accuracy: 0.35593220591545105\n",
      "Epoch: 3830, Loss: 1.0439106225967407, Accuracy: 0.29708221554756165, Test Loss: 1.0154948234558105, Test Accuracy: 0.35593220591545105\n"
     ]
    }
   ],
   "source": [
    "# Define loss function\n",
    "# Binary classification => BCELoss\n",
    "from models import train_binary_logits\n",
    "from models import PCDModel_1\n",
    "from models import MulticlassClassification\n",
    "from models import accuracy_fn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from matplotlib import pyplot as plt\n",
    "# TRAINING\n",
    "epochs = 1000000\n",
    "model_0 = PCDModel_1(urinary_data.get_feature_count(), urinary_data.get_label_count())\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_0.parameters(), lr=0.0001)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    model_0.train()\n",
    "\n",
    "    # 1. Forward pass\n",
    "    y_logits = model_0(X_train).squeeze()\n",
    "    y_pred = torch.sigmoid(y_logits)\n",
    "    #print(y_pred.shape)\n",
    "    # 2. Compute loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    losses.append(loss)\n",
    "\n",
    "    # 2.1 Compute accuracy\n",
    "    acc = (torch.argmax(y_pred, 1) == torch.argmax(y_train, 1)).float().mean()\n",
    "\n",
    "\n",
    "    # 3. Optimizer zero_grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "    # 6. Test\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        # 6.1 Forward pass\n",
    "        test_logits = model_0(X_test).squeeze() \n",
    "        test_pred = torch.sigmoid(test_logits)\n",
    "        # 6.2 Compute loss\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "        # 6.3 Compute accuracy\n",
    "        test_acc = (torch.argmax(test_pred, 1) == torch.argmax(y_test, 1)).float().mean()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Epoch: {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}\".format(epoch, loss, acc, test_loss, test_acc))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1.])\n",
      "tensor([-18.6728, -20.9609, -12.0012], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pred = model_0(X_test[10]).squeeze()\n",
    "print(y_test[10])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
