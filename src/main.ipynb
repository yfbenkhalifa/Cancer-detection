{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pancreatic Cancer Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(94)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from utils import Utilities as utils\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        return torch.Tensor(sample).float() \n",
    "    \n",
    "class DataFrameEntry():\n",
    "    def __init__(self, columns : list, values : list, name = '') -> None:\n",
    "        self.columns = columns\n",
    "        self.values = values\n",
    "        self.name = name\n",
    "\n",
    "class DataFrameLabel():\n",
    "    def __init__(self, columns : list, values : list, name = '') -> None:\n",
    "        self.columns = columns\n",
    "        self.values = values\n",
    "        self.name = name\n",
    "        \n",
    "    \n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, filePath : str, label_column : list, separator = ';', name=''):\n",
    "        self.dataframe = utils.createDataframe(filepath=filePath, \n",
    "                                               separator=separator)\n",
    "        self.label_column = label_column\n",
    "        self.encoders = {}\n",
    "        self.label_dicts = {}\n",
    "\n",
    "    def init_label_dictionary(self, label_column : str | int, label_dict : dict):\n",
    "        self.label_dicts[label_column] = label_dict\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.df[self.label_column]\n",
    "\n",
    "    def encode_column(self, column : str | int) -> None:\n",
    "        if self.encoders.get(column) is None:\n",
    "            self.encoders[column] = preprocessing.LabelEncoder()\n",
    "            self.encoders[column].fit(self.dataframe[column].values)\n",
    "        self.dataframe[column] = self.encoders[column].transform(self.dataframe[column].values)\n",
    "\n",
    "    def decode_column(self, column : str | int) -> None:\n",
    "        if self.encoders.get(column) is not None:\n",
    "            self.dataframe[column] = self.encoders[column].inverse_transform(self.dataframe[column].values)\n",
    "        else:\n",
    "            print('Warning: Column not encoded')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        return self.dataframe.iloc[idx]\n",
    "    \n",
    "    def get_column_types(self, column : str | int) -> str:\n",
    "        if self.__len__() > 0:\n",
    "            return type(self.dataframe[column][0])\n",
    "        else:\n",
    "            raise Exception('Dataset is empty')\n",
    "    \n",
    "\n",
    "            \n",
    "    def addDataset(self, filePath : str, separator = ';', name='') -> None:\n",
    "        self.df = utils.createDataframe(self.base_path + filePath, separator=separator)\n",
    "        \n",
    "        if self.df is None:\n",
    "            print('Error: File not found or not valid')\n",
    "        else:\n",
    "            if self.dataframes.get(name) is None:\n",
    "                self.dataframes[name] = self.df\n",
    "                self.encode_df = self.df.copy()\n",
    "                print('Added ' + filePath + ' to dataset')\n",
    "            else: \n",
    "                print('Warning: Dataset name already exists')\n",
    "             \n",
    "    \n",
    "    def createDataset(self, files : list) -> None:\n",
    "        frames = []\n",
    "        for file in files:\n",
    "            csv = self.base_path + file\n",
    "            df = pd.read_csv(csv, sep=\";\")\n",
    "            frames.append(df)\n",
    "        self.df = pd.concat(frames) \n",
    "        self.df.drop_duplicates(inplace=True)\n",
    "\n",
    "    def get_feature_count(self):\n",
    "        return len(self.dataframe.columns) - 1\n",
    "    \n",
    "    def get_label_count(self):\n",
    "        return len(self.dataframe[self.label_column].unique())\n",
    "        \n",
    "    def cleanDataframe(self):\n",
    "        # Check for columns with all different values\n",
    "        size = self.dataframe.shape\n",
    "        self.dataframe = self.dataframe.loc[:, self.dataframe.apply(pd.Series.nunique) != self.dataframe.shape[0]]\n",
    "        \n",
    "        # Exclude some entries as to make it even\n",
    "        self.dataframe = self.dataframe[:self.dataframe.shape[0] - (self.dataframe.shape[0] % 10)]\n",
    "        print(\"Removed: \" + str(size[0] - self.dataframe.shape[0]) + \" rows | \" + \n",
    "              str(size[1] - self.dataframe.shape[1]) + \" columns\")\n",
    "         \n",
    "    def applyPreprocessing(self, columns:list):\n",
    "        size = self.df.shape[1]\n",
    "        self.select(columns)\n",
    "        print(\"Removed \" + str(size - self.df.shape[1]) + \" columns\")\n",
    "        \n",
    "    def select(self, columns:list):\n",
    "        if self.deleted is None:\n",
    "            self.deleted = pd.DataFrame()\n",
    "        \n",
    "        # Restore the deleted columns\n",
    "        # self.restore(columns)\n",
    "                \n",
    "        # Keep track of the deleted columns\n",
    "        _deletedColumns = self.df.columns.difference(columns)\n",
    "        \n",
    "        if self.deleted.empty:\n",
    "            self.deleted = self.df[_deletedColumns]\n",
    "        else:\n",
    "            self.deleted = pd.concat([self.deleted, self.df[_deletedColumns]], axis=0)\n",
    "\n",
    "            \n",
    "        self.df.drop(_deletedColumns, axis=1, inplace=True)\n",
    "\n",
    "    ## NEEDS TO BE FIXED ##\n",
    "    def restore(self, columns : list):\n",
    "        restored = 0\n",
    "        if self.deleted is None or self.deleted.empty:\n",
    "            print(\"No columns to restore\")\n",
    "            return\n",
    "        else:\n",
    "            for col in (set(self.deleted.columns) & set(columns)):\n",
    "                restored += 1\n",
    "                _restored = self.deleted[col]\n",
    "\n",
    "                self.df = pd.concat([self.df, _restored], axis=1, ignore_index=True)\n",
    "                print(self.df.columns)\n",
    "                # self.df.append(self.deleted[col])\n",
    "        print(\"Restored \" + str(restored) + \" columns\")\n",
    "            \n",
    "    \n",
    "    def applyFilter(self, column, value, maxrows=None, criterion='equal'):\n",
    "        if maxrows is not None:\n",
    "            self.df = self.df.head(maxrows)\n",
    "        if criterion == 'equal':\n",
    "            self.df = self.df[self.df[column] == value]\n",
    "        elif criterion == 'contains':\n",
    "            self.df = self.df[self.df[column].str.contains(value)]\n",
    "\n",
    "    def colSize(self):\n",
    "        return len(self.df.columns)\n",
    "    \n",
    "    def rowSize(self):\n",
    "        return len(self.df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>patient_cohort</th>\n",
       "      <th>sample_origin</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>stage</th>\n",
       "      <th>benign_sample_diagnosis</th>\n",
       "      <th>plasma_CA19_9</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>LYVE1</th>\n",
       "      <th>REG1B</th>\n",
       "      <th>TFF1</th>\n",
       "      <th>REG1A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1</td>\n",
       "      <td>Cohort1</td>\n",
       "      <td>BPTB</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1.83222</td>\n",
       "      <td>0.893219</td>\n",
       "      <td>52.94884</td>\n",
       "      <td>654.282174</td>\n",
       "      <td>1262.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S10</td>\n",
       "      <td>Cohort1</td>\n",
       "      <td>BPTB</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97266</td>\n",
       "      <td>2.037585</td>\n",
       "      <td>94.46703</td>\n",
       "      <td>209.488250</td>\n",
       "      <td>228.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S100</td>\n",
       "      <td>Cohort2</td>\n",
       "      <td>BPTB</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.78039</td>\n",
       "      <td>0.145589</td>\n",
       "      <td>102.36600</td>\n",
       "      <td>461.141000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S101</td>\n",
       "      <td>Cohort2</td>\n",
       "      <td>BPTB</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.70122</td>\n",
       "      <td>0.002805</td>\n",
       "      <td>60.57900</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S102</td>\n",
       "      <td>Cohort2</td>\n",
       "      <td>BPTB</td>\n",
       "      <td>62</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.21489</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>65.54000</td>\n",
       "      <td>41.088000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_id patient_cohort sample_origin  age sex  diagnosis stage   \n",
       "0        S1        Cohort1          BPTB   33   F          1   NaN  \\\n",
       "1       S10        Cohort1          BPTB   81   F          1   NaN   \n",
       "2      S100        Cohort2          BPTB   51   M          1   NaN   \n",
       "3      S101        Cohort2          BPTB   61   M          1   NaN   \n",
       "4      S102        Cohort2          BPTB   62   M          1   NaN   \n",
       "\n",
       "  benign_sample_diagnosis  plasma_CA19_9  creatinine     LYVE1      REG1B   \n",
       "0                     NaN           11.7     1.83222  0.893219   52.94884  \\\n",
       "1                     NaN            NaN     0.97266  2.037585   94.46703   \n",
       "2                     NaN            7.0     0.78039  0.145589  102.36600   \n",
       "3                     NaN            8.0     0.70122  0.002805   60.57900   \n",
       "4                     NaN            9.0     0.21489  0.000860   65.54000   \n",
       "\n",
       "         TFF1     REG1A  \n",
       "0  654.282174  1262.000  \n",
       "1  209.488250   228.407  \n",
       "2  461.141000       NaN  \n",
       "3  142.950000       NaN  \n",
       "4   41.088000       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "urinary_data = Dataset(filePath='../data/urinary_data.csv',\n",
    "                       label_column='diagnosis',\n",
    "                       separator=',', \n",
    "                       name='urinary_data')\n",
    "display(urinary_data.dataframe.head())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset cleaning and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>patient_cohort</th>\n",
       "      <th>sample_origin</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>stage</th>\n",
       "      <th>benign_sample_diagnosis</th>\n",
       "      <th>plasma_CA19_9</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>LYVE1</th>\n",
       "      <th>REG1B</th>\n",
       "      <th>TFF1</th>\n",
       "      <th>REG1A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "      <td>181</td>\n",
       "      <td>337</td>\n",
       "      <td>391</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>266</td>\n",
       "      <td>93</td>\n",
       "      <td>265</td>\n",
       "      <td>402</td>\n",
       "      <td>242</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>62</td>\n",
       "      <td>75</td>\n",
       "      <td>108</td>\n",
       "      <td>412</td>\n",
       "      <td>347</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>47</td>\n",
       "      <td>351</td>\n",
       "      <td>209</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>70</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>360</td>\n",
       "      <td>117</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id  patient_cohort  sample_origin  age  sex  diagnosis  stage   \n",
       "0          0               0              0    6    0          0      8  \\\n",
       "1          1               0              0   54    0          0      8   \n",
       "2          2               1              0   24    1          0      8   \n",
       "3          3               1              0   34    1          0      8   \n",
       "4          4               1              0   35    1          0      8   \n",
       "\n",
       "   benign_sample_diagnosis  plasma_CA19_9  creatinine  LYVE1  REG1B  TFF1   \n",
       "0                       52             78         158    181    337   391  \\\n",
       "1                       52            266          93    265    402   242   \n",
       "2                       52             62          75    108    412   347   \n",
       "3                       52             67          68     47    351   209   \n",
       "4                       52             70          16     14    360   117   \n",
       "\n",
       "   REG1A  \n",
       "0    247  \n",
       "1    151  \n",
       "2    298  \n",
       "3    298  \n",
       "4    298  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: 0 rows | 1 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_cohort</th>\n",
       "      <th>sample_origin</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>stage</th>\n",
       "      <th>benign_sample_diagnosis</th>\n",
       "      <th>plasma_CA19_9</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>LYVE1</th>\n",
       "      <th>REG1B</th>\n",
       "      <th>TFF1</th>\n",
       "      <th>REG1A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "      <td>181</td>\n",
       "      <td>337</td>\n",
       "      <td>391</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>266</td>\n",
       "      <td>93</td>\n",
       "      <td>265</td>\n",
       "      <td>402</td>\n",
       "      <td>242</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>62</td>\n",
       "      <td>75</td>\n",
       "      <td>108</td>\n",
       "      <td>412</td>\n",
       "      <td>347</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>47</td>\n",
       "      <td>351</td>\n",
       "      <td>209</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>70</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>360</td>\n",
       "      <td>117</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_cohort  sample_origin  age  sex  diagnosis  stage   \n",
       "0               0              0    6    0          0      8  \\\n",
       "1               0              0   54    0          0      8   \n",
       "2               1              0   24    1          0      8   \n",
       "3               1              0   34    1          0      8   \n",
       "4               1              0   35    1          0      8   \n",
       "\n",
       "   benign_sample_diagnosis  plasma_CA19_9  creatinine  LYVE1  REG1B  TFF1   \n",
       "0                       52             78         158    181    337   391  \\\n",
       "1                       52            266          93    265    402   242   \n",
       "2                       52             62          75    108    412   347   \n",
       "3                       52             67          68     47    351   209   \n",
       "4                       52             70          16     14    360   117   \n",
       "\n",
       "   REG1A  \n",
       "0    247  \n",
       "1    151  \n",
       "2    298  \n",
       "3    298  \n",
       "4    298  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# urinary_data.cleanDataframe()\n",
    "# Encode labels\n",
    "for column in urinary_data.dataframe.columns:\n",
    "    urinary_data.encode_column(column)\n",
    "\n",
    "display(urinary_data.dataframe.head())\n",
    "\n",
    "# Dataset Cleaning\n",
    "urinary_data.cleanDataframe()\n",
    "\n",
    "display(urinary_data.dataframe.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type = <class 'numpy.ndarray'>\n",
      "Shape = (590, 12)\n",
      "Type = <class 'numpy.ndarray'>\n",
      "Shape = (590,)\n",
      "Type = <class 'torch.Tensor'>\n",
      "Shape = torch.Size([590, 12])\n",
      "Type = <class 'torch.Tensor'>\n",
      "Shape = torch.Size([590])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Dataset split\n",
    "X = urinary_data.dataframe.iloc[:, urinary_data.dataframe.columns != urinary_data.label_column].squeeze()\n",
    "y = urinary_data.dataframe[urinary_data.label_column].values.reshape(-1, 1).squeeze()\n",
    "\n",
    "\n",
    "print(f\"Type = {type(X.values)}\")\n",
    "print(f\"Shape = {X.shape}\")\n",
    "print(f\"Type = {type(y)}\")\n",
    "print(f\"Shape = {y.shape}\")\n",
    "\n",
    "# Convert to tensors\n",
    "X = torch.from_numpy(X.values).type(torch.float32)\n",
    "y = torch.from_numpy(y).type(torch.LongTensor)\n",
    "\n",
    "print(f\"Type = {type(X)}\")\n",
    "print(f\"Shape = {X.shape}\")\n",
    "print(f\"Type = {type(y)}\")\n",
    "print(f\"Shape = {y.shape}\")\n",
    "\n",
    "# Send to GPU\n",
    "X = X.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set sizes: Train: 377, Validation: 95, Test: 118\n",
      "X_train shape: torch.Size([377, 12])\n",
      "y_train shape: torch.Size([377])\n",
      "X_val shape: torch.Size([95, 12])\n",
      "y_val shape: torch.Size([95])\n",
      "X_test shape: torch.Size([118, 12])\n",
      "y_test shape: torch.Size([118])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.to(device)\n",
    "X_val.to(device)\n",
    "X_test.to(device)\n",
    "y_train.to(device)\n",
    "y_val.to(device)\n",
    "y_test.to(device)\n",
    "\n",
    "print(\"Set sizes: Train: {}, Validation: {}, Test: {}\".format(len(X_train), len(X_val), len(X_test)))\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"X_val shape: {}\".format(X_val.shape))\n",
    "print(\"y_val shape: {}\".format(y_val.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.state_dict of PCDModel_1(\n",
      "  (linearBlock): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=32, bias=True)\n",
      "    (1): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (2): Linear(in_features=16, out_features=8, bias=True)\n",
      "    (3): Linear(in_features=8, out_features=3, bias=True)\n",
      "  )\n",
      ")>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ -283.6411,  2320.2124, -4321.7505],\n",
       "        [  -77.7950,    61.5888,  -418.1554],\n",
       "        [ -105.8213,   701.6616, -1393.0272],\n",
       "        [ -214.2239,  1167.0740, -2033.0388],\n",
       "        [ -245.0206,  1271.3246, -3184.8486],\n",
       "        [  -80.9450,  1219.4695, -2614.6204],\n",
       "        [ -208.2206,  1118.8560, -2225.1404],\n",
       "        [  -46.2048,   768.9744,  -509.6219],\n",
       "        [ -118.2406,   749.9640, -1883.3269],\n",
       "        [ -137.8341,  1170.8188, -2459.0908]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from models import PCDModel_1, BlobModel\n",
    "\n",
    "\n",
    "model_0 = PCDModel_1(urinary_data.get_feature_count(), urinary_data.get_label_count()).to(device)\n",
    "print(model_0.state_dict)\n",
    "\n",
    "# Predicted logits\n",
    "pred_logits = model_0(X_train.to(device))[:10]\n",
    "display(pred_logits)\n",
    "\n",
    "# Predicted probabilities\n",
    "pred_prob = torch.softmax(pred_logits, dim=1)\n",
    "display(pred_prob)\n",
    "\n",
    "# Predicted classes\n",
    "pred_classes = torch.argmax(pred_prob, dim=1)\n",
    "display(pred_classes)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2110.980712890625, Accuracy: 36.07426834106445, Test Loss: 2037.3232421875, Test Accuracy: 33.050846099853516\n",
      "Epoch: 1, Loss: 2084.410888671875, Accuracy: 36.07426834106445, Test Loss: 1987.1661376953125, Test Accuracy: 33.050846099853516\n",
      "Epoch: 2, Loss: 2034.218505859375, Accuracy: 36.07426834106445, Test Loss: 1916.2852783203125, Test Accuracy: 33.050846099853516\n",
      "Epoch: 3, Loss: 1963.2847900390625, Accuracy: 36.07426834106445, Test Loss: 1827.444091796875, Test Accuracy: 33.050846099853516\n",
      "Epoch: 4, Loss: 1874.3736572265625, Accuracy: 36.07426834106445, Test Loss: 1723.24853515625, Test Accuracy: 33.050846099853516\n",
      "Epoch: 5, Loss: 1770.08984375, Accuracy: 36.07426834106445, Test Loss: 1606.1134033203125, Test Accuracy: 33.050846099853516\n",
      "Epoch: 6, Loss: 1652.9149169921875, Accuracy: 35.80902099609375, Test Loss: 1478.26123046875, Test Accuracy: 33.050846099853516\n",
      "Epoch: 7, Loss: 1525.0355224609375, Accuracy: 36.07426834106445, Test Loss: 1341.8369140625, Test Accuracy: 32.203392028808594\n",
      "Epoch: 8, Loss: 1388.6253662109375, Accuracy: 35.80902099609375, Test Loss: 1198.6319580078125, Test Accuracy: 32.203392028808594\n",
      "Epoch: 9, Loss: 1245.739501953125, Accuracy: 35.01325988769531, Test Loss: 1051.0069580078125, Test Accuracy: 33.050846099853516\n",
      "Epoch: 10, Loss: 1098.5069580078125, Accuracy: 34.748008728027344, Test Loss: 902.9991455078125, Test Accuracy: 34.74576187133789\n",
      "Epoch: 11, Loss: 950.1672973632812, Accuracy: 34.217506408691406, Test Loss: 763.2678833007812, Test Accuracy: 42.37288284301758\n",
      "Epoch: 12, Loss: 805.4645385742188, Accuracy: 37.40052795410156, Test Loss: 633.9179077148438, Test Accuracy: 44.06779861450195\n",
      "Epoch: 13, Loss: 671.9755249023438, Accuracy: 37.13528060913086, Test Loss: 523.117919921875, Test Accuracy: 42.37288284301758\n",
      "Epoch: 14, Loss: 559.8786010742188, Accuracy: 32.095489501953125, Test Loss: 459.36627197265625, Test Accuracy: 38.13559341430664\n",
      "Epoch: 15, Loss: 493.44903564453125, Accuracy: 30.238727569580078, Test Loss: 430.1910705566406, Test Accuracy: 37.28813552856445\n",
      "Epoch: 16, Loss: 461.2654724121094, Accuracy: 28.647214889526367, Test Loss: 405.3863220214844, Test Accuracy: 33.89830780029297\n",
      "Epoch: 17, Loss: 437.19683837890625, Accuracy: 27.055702209472656, Test Loss: 380.9822998046875, Test Accuracy: 32.203392028808594\n",
      "Epoch: 18, Loss: 414.5581970214844, Accuracy: 24.403182983398438, Test Loss: 359.41400146484375, Test Accuracy: 28.81355857849121\n",
      "Epoch: 19, Loss: 392.7190856933594, Accuracy: 23.6074275970459, Test Loss: 340.3019714355469, Test Accuracy: 28.81355857849121\n",
      "Epoch: 20, Loss: 372.177001953125, Accuracy: 23.342174530029297, Test Loss: 322.8119812011719, Test Accuracy: 29.66101837158203\n",
      "Epoch: 21, Loss: 355.1909484863281, Accuracy: 22.015914916992188, Test Loss: 308.0779113769531, Test Accuracy: 28.81355857849121\n",
      "Epoch: 22, Loss: 343.14910888671875, Accuracy: 20.159151077270508, Test Loss: 301.5067443847656, Test Accuracy: 28.81355857849121\n",
      "Epoch: 23, Loss: 338.6156921386719, Accuracy: 22.811670303344727, Test Loss: 307.73236083984375, Test Accuracy: 41.52542495727539\n",
      "Epoch: 24, Loss: 346.0330505371094, Accuracy: 32.8912467956543, Test Loss: 322.90887451171875, Test Accuracy: 44.915252685546875\n",
      "Epoch: 25, Loss: 360.8392639160156, Accuracy: 38.992042541503906, Test Loss: 334.4659118652344, Test Accuracy: 45.76271057128906\n",
      "Epoch: 26, Loss: 373.6987609863281, Accuracy: 39.78779983520508, Test Loss: 340.8474426269531, Test Accuracy: 44.915252685546875\n",
      "Epoch: 27, Loss: 380.42681884765625, Accuracy: 40.05304718017578, Test Loss: 340.2131652832031, Test Accuracy: 45.76271057128906\n",
      "Epoch: 28, Loss: 379.5776672363281, Accuracy: 40.05304718017578, Test Loss: 332.79168701171875, Test Accuracy: 45.76271057128906\n",
      "Epoch: 29, Loss: 371.1250305175781, Accuracy: 40.583553314208984, Test Loss: 319.02215576171875, Test Accuracy: 45.76271057128906\n",
      "Epoch: 30, Loss: 355.6807861328125, Accuracy: 40.318302154541016, Test Loss: 299.78997802734375, Test Accuracy: 44.915252685546875\n",
      "Epoch: 31, Loss: 334.2712097167969, Accuracy: 40.583553314208984, Test Loss: 276.3495788574219, Test Accuracy: 44.915252685546875\n",
      "Epoch: 32, Loss: 308.139892578125, Accuracy: 40.05304718017578, Test Loss: 249.67091369628906, Test Accuracy: 44.915252685546875\n",
      "Epoch: 33, Loss: 278.6347961425781, Accuracy: 40.583553314208984, Test Loss: 222.0146026611328, Test Accuracy: 44.06779861450195\n",
      "Epoch: 34, Loss: 247.72296142578125, Accuracy: 39.257293701171875, Test Loss: 194.80038452148438, Test Accuracy: 41.52542495727539\n",
      "Epoch: 35, Loss: 218.5542449951172, Accuracy: 35.543766021728516, Test Loss: 173.14328002929688, Test Accuracy: 38.13559341430664\n",
      "Epoch: 36, Loss: 193.88108825683594, Accuracy: 29.708221435546875, Test Loss: 157.1943359375, Test Accuracy: 30.508474349975586\n",
      "Epoch: 37, Loss: 175.98043823242188, Accuracy: 23.6074275970459, Test Loss: 145.37594604492188, Test Accuracy: 30.508474349975586\n",
      "Epoch: 38, Loss: 163.23509216308594, Accuracy: 22.546417236328125, Test Loss: 135.0548095703125, Test Accuracy: 33.89830780029297\n",
      "Epoch: 39, Loss: 152.4604034423828, Accuracy: 23.6074275970459, Test Loss: 126.44329833984375, Test Accuracy: 35.59321975708008\n",
      "Epoch: 40, Loss: 144.3397979736328, Accuracy: 25.994693756103516, Test Loss: 119.60975646972656, Test Accuracy: 38.13559341430664\n",
      "Epoch: 41, Loss: 139.99298095703125, Accuracy: 28.116708755493164, Test Loss: 113.8001937866211, Test Accuracy: 38.13559341430664\n",
      "Epoch: 42, Loss: 138.68270874023438, Accuracy: 30.238727569580078, Test Loss: 111.80990600585938, Test Accuracy: 38.13559341430664\n",
      "Epoch: 43, Loss: 138.0006561279297, Accuracy: 30.503978729248047, Test Loss: 112.18260192871094, Test Accuracy: 38.98305130004883\n",
      "Epoch: 44, Loss: 137.5359344482422, Accuracy: 31.564987182617188, Test Loss: 109.75459289550781, Test Accuracy: 39.830509185791016\n",
      "Epoch: 45, Loss: 133.7427520751953, Accuracy: 30.503978729248047, Test Loss: 102.06865692138672, Test Accuracy: 38.13559341430664\n",
      "Epoch: 46, Loss: 124.8499984741211, Accuracy: 32.360740661621094, Test Loss: 89.60043334960938, Test Accuracy: 37.28813552856445\n",
      "Epoch: 47, Loss: 111.20823669433594, Accuracy: 31.830238342285156, Test Loss: 74.29718780517578, Test Accuracy: 36.440677642822266\n",
      "Epoch: 48, Loss: 94.51734161376953, Accuracy: 29.708221435546875, Test Loss: 60.07667922973633, Test Accuracy: 39.830509185791016\n",
      "Epoch: 49, Loss: 79.88414764404297, Accuracy: 31.034481048583984, Test Loss: 59.26696014404297, Test Accuracy: 50.0\n",
      "Epoch: 50, Loss: 75.05035400390625, Accuracy: 39.78779983520508, Test Loss: 66.28936004638672, Test Accuracy: 51.694915771484375\n",
      "Epoch: 51, Loss: 79.43612670898438, Accuracy: 43.50132751464844, Test Loss: 73.46256256103516, Test Accuracy: 54.23728942871094\n",
      "Epoch: 52, Loss: 85.75384521484375, Accuracy: 45.09283447265625, Test Loss: 78.0561752319336, Test Accuracy: 52.5423698425293\n",
      "Epoch: 53, Loss: 90.71681213378906, Accuracy: 45.62334060668945, Test Loss: 78.92288208007812, Test Accuracy: 52.5423698425293\n",
      "Epoch: 54, Loss: 91.71086120605469, Accuracy: 45.358089447021484, Test Loss: 76.39490509033203, Test Accuracy: 53.389827728271484\n",
      "Epoch: 55, Loss: 88.65804290771484, Accuracy: 46.153846740722656, Test Loss: 71.1047592163086, Test Accuracy: 55.084747314453125\n",
      "Epoch: 56, Loss: 82.735595703125, Accuracy: 47.2148551940918, Test Loss: 64.6722183227539, Test Accuracy: 55.93220520019531\n",
      "Epoch: 57, Loss: 76.71971130371094, Accuracy: 45.88859558105469, Test Loss: 58.935794830322266, Test Accuracy: 51.694915771484375\n",
      "Epoch: 58, Loss: 71.4592514038086, Accuracy: 44.82758712768555, Test Loss: 55.5913200378418, Test Accuracy: 50.0\n",
      "Epoch: 59, Loss: 69.15238189697266, Accuracy: 41.644561767578125, Test Loss: 56.68777847290039, Test Accuracy: 44.915252685546875\n",
      "Epoch: 60, Loss: 71.18544006347656, Accuracy: 38.196285247802734, Test Loss: 60.7250862121582, Test Accuracy: 44.06779861450195\n",
      "Epoch: 61, Loss: 74.64971923828125, Accuracy: 36.604774475097656, Test Loss: 62.21995544433594, Test Accuracy: 44.915252685546875\n",
      "Epoch: 62, Loss: 76.09542083740234, Accuracy: 37.40052795410156, Test Loss: 59.78657531738281, Test Accuracy: 44.915252685546875\n",
      "Epoch: 63, Loss: 73.7003402709961, Accuracy: 37.13528060913086, Test Loss: 55.15839385986328, Test Accuracy: 43.2203369140625\n",
      "Epoch: 64, Loss: 69.34928894042969, Accuracy: 39.257293701171875, Test Loss: 52.43449020385742, Test Accuracy: 50.0\n",
      "Epoch: 65, Loss: 65.8672103881836, Accuracy: 41.909812927246094, Test Loss: 52.475128173828125, Test Accuracy: 52.5423698425293\n",
      "Epoch: 66, Loss: 64.817626953125, Accuracy: 46.153846740722656, Test Loss: 53.84891891479492, Test Accuracy: 52.5423698425293\n",
      "Epoch: 67, Loss: 65.20610809326172, Accuracy: 48.0106086730957, Test Loss: 54.95074462890625, Test Accuracy: 52.5423698425293\n",
      "Epoch: 68, Loss: 66.00177001953125, Accuracy: 48.541114807128906, Test Loss: 55.111961364746094, Test Accuracy: 54.23728942871094\n",
      "Epoch: 69, Loss: 66.01490783691406, Accuracy: 48.27585983276367, Test Loss: 54.286319732666016, Test Accuracy: 54.23728942871094\n",
      "Epoch: 70, Loss: 65.1053237915039, Accuracy: 48.27585983276367, Test Loss: 52.56401062011719, Test Accuracy: 53.389827728271484\n",
      "Epoch: 71, Loss: 63.387359619140625, Accuracy: 48.27585983276367, Test Loss: 50.19981002807617, Test Accuracy: 53.389827728271484\n",
      "Epoch: 72, Loss: 61.216033935546875, Accuracy: 48.27585983276367, Test Loss: 47.60451126098633, Test Accuracy: 54.23728942871094\n",
      "Epoch: 73, Loss: 59.154945373535156, Accuracy: 47.480106353759766, Test Loss: 45.60824203491211, Test Accuracy: 51.694915771484375\n",
      "Epoch: 74, Loss: 58.08073425292969, Accuracy: 45.62334060668945, Test Loss: 44.49882888793945, Test Accuracy: 50.84745788574219\n",
      "Epoch: 75, Loss: 57.78706741333008, Accuracy: 41.909812927246094, Test Loss: 43.9697151184082, Test Accuracy: 49.15254211425781\n",
      "Epoch: 76, Loss: 58.094261169433594, Accuracy: 39.78779983520508, Test Loss: 43.53483200073242, Test Accuracy: 45.76271057128906\n",
      "Epoch: 77, Loss: 57.9084587097168, Accuracy: 38.196285247802734, Test Loss: 42.64479446411133, Test Accuracy: 47.45762634277344\n",
      "Epoch: 78, Loss: 56.834529876708984, Accuracy: 39.257293701171875, Test Loss: 41.83517837524414, Test Accuracy: 51.694915771484375\n",
      "Epoch: 79, Loss: 55.329307556152344, Accuracy: 41.644561767578125, Test Loss: 41.5713996887207, Test Accuracy: 52.5423698425293\n",
      "Epoch: 80, Loss: 54.2809944152832, Accuracy: 44.297080993652344, Test Loss: 41.68506622314453, Test Accuracy: 52.5423698425293\n",
      "Epoch: 81, Loss: 53.64672088623047, Accuracy: 44.031829833984375, Test Loss: 41.95583724975586, Test Accuracy: 55.93220520019531\n",
      "Epoch: 82, Loss: 53.445098876953125, Accuracy: 44.56233215332031, Test Loss: 42.018680572509766, Test Accuracy: 55.084747314453125\n",
      "Epoch: 83, Loss: 53.28249740600586, Accuracy: 44.031829833984375, Test Loss: 41.71760940551758, Test Accuracy: 55.93220520019531\n",
      "Epoch: 84, Loss: 52.948612213134766, Accuracy: 43.50132751464844, Test Loss: 41.01030349731445, Test Accuracy: 55.084747314453125\n",
      "Epoch: 85, Loss: 52.31824493408203, Accuracy: 42.970821380615234, Test Loss: 40.038455963134766, Test Accuracy: 54.23728942871094\n",
      "Epoch: 86, Loss: 51.49127197265625, Accuracy: 43.50132751464844, Test Loss: 39.135440826416016, Test Accuracy: 50.84745788574219\n",
      "Epoch: 87, Loss: 50.66254425048828, Accuracy: 42.17506790161133, Test Loss: 38.47278594970703, Test Accuracy: 50.0\n",
      "Epoch: 88, Loss: 50.09233474731445, Accuracy: 42.705570220947266, Test Loss: 37.96290969848633, Test Accuracy: 48.305084228515625\n",
      "Epoch: 89, Loss: 49.795989990234375, Accuracy: 41.11405944824219, Test Loss: 37.63057327270508, Test Accuracy: 47.45762634277344\n",
      "Epoch: 90, Loss: 49.575103759765625, Accuracy: 40.05304718017578, Test Loss: 37.30495834350586, Test Accuracy: 47.45762634277344\n",
      "Epoch: 91, Loss: 49.197776794433594, Accuracy: 40.318302154541016, Test Loss: 36.933475494384766, Test Accuracy: 47.45762634277344\n",
      "Epoch: 92, Loss: 48.5927619934082, Accuracy: 40.318302154541016, Test Loss: 36.550785064697266, Test Accuracy: 48.305084228515625\n",
      "Epoch: 93, Loss: 47.9019775390625, Accuracy: 41.379310607910156, Test Loss: 36.2834587097168, Test Accuracy: 50.0\n",
      "Epoch: 94, Loss: 47.35905838012695, Accuracy: 41.11405944824219, Test Loss: 36.086883544921875, Test Accuracy: 50.0\n",
      "Epoch: 95, Loss: 47.01035690307617, Accuracy: 40.583553314208984, Test Loss: 35.90305709838867, Test Accuracy: 50.84745788574219\n",
      "Epoch: 96, Loss: 46.68515396118164, Accuracy: 40.583553314208984, Test Loss: 35.6613883972168, Test Accuracy: 53.389827728271484\n",
      "Epoch: 97, Loss: 46.30176544189453, Accuracy: 41.379310607910156, Test Loss: 35.29974365234375, Test Accuracy: 53.389827728271484\n",
      "Epoch: 98, Loss: 45.832740783691406, Accuracy: 40.84880828857422, Test Loss: 34.86492156982422, Test Accuracy: 50.84745788574219\n",
      "Epoch: 99, Loss: 45.32085037231445, Accuracy: 40.318302154541016, Test Loss: 34.418819427490234, Test Accuracy: 50.84745788574219\n",
      "Epoch: 100, Loss: 44.812843322753906, Accuracy: 40.84880828857422, Test Loss: 34.02494430541992, Test Accuracy: 48.305084228515625\n",
      "Epoch: 101, Loss: 44.38808059692383, Accuracy: 40.05304718017578, Test Loss: 33.777740478515625, Test Accuracy: 48.305084228515625\n",
      "Epoch: 102, Loss: 44.07919692993164, Accuracy: 38.72678756713867, Test Loss: 33.54767608642578, Test Accuracy: 48.305084228515625\n",
      "Epoch: 103, Loss: 43.76571273803711, Accuracy: 38.46154022216797, Test Loss: 33.32008361816406, Test Accuracy: 49.15254211425781\n",
      "Epoch: 104, Loss: 43.3642692565918, Accuracy: 38.72678756713867, Test Loss: 33.088775634765625, Test Accuracy: 50.0\n",
      "Epoch: 105, Loss: 42.931392669677734, Accuracy: 39.78779983520508, Test Loss: 32.89099884033203, Test Accuracy: 50.0\n",
      "Epoch: 106, Loss: 42.57201385498047, Accuracy: 40.318302154541016, Test Loss: 32.77747344970703, Test Accuracy: 50.0\n",
      "Epoch: 107, Loss: 42.291011810302734, Accuracy: 40.318302154541016, Test Loss: 32.640132904052734, Test Accuracy: 50.84745788574219\n",
      "Epoch: 108, Loss: 42.0189208984375, Accuracy: 40.318302154541016, Test Loss: 32.436492919921875, Test Accuracy: 51.694915771484375\n",
      "Epoch: 109, Loss: 41.70661163330078, Accuracy: 40.318302154541016, Test Loss: 32.164512634277344, Test Accuracy: 50.84745788574219\n",
      "Epoch: 110, Loss: 41.353824615478516, Accuracy: 40.05304718017578, Test Loss: 31.887531280517578, Test Accuracy: 50.0\n",
      "Epoch: 111, Loss: 41.01017379760742, Accuracy: 39.78779983520508, Test Loss: 31.65181541442871, Test Accuracy: 50.0\n",
      "Epoch: 112, Loss: 40.721073150634766, Accuracy: 40.05304718017578, Test Loss: 31.422183990478516, Test Accuracy: 49.15254211425781\n",
      "Epoch: 113, Loss: 40.445823669433594, Accuracy: 39.257293701171875, Test Loss: 31.192527770996094, Test Accuracy: 50.0\n",
      "Epoch: 114, Loss: 40.14898681640625, Accuracy: 38.992042541503906, Test Loss: 30.965150833129883, Test Accuracy: 50.0\n",
      "Epoch: 115, Loss: 39.819549560546875, Accuracy: 40.05304718017578, Test Loss: 30.740507125854492, Test Accuracy: 50.0\n",
      "Epoch: 116, Loss: 39.50014114379883, Accuracy: 39.522544860839844, Test Loss: 30.521987915039062, Test Accuracy: 50.84745788574219\n",
      "Epoch: 117, Loss: 39.20589065551758, Accuracy: 39.257293701171875, Test Loss: 30.30699920654297, Test Accuracy: 50.84745788574219\n",
      "Epoch: 118, Loss: 38.92789840698242, Accuracy: 40.583553314208984, Test Loss: 30.068552017211914, Test Accuracy: 50.84745788574219\n",
      "Epoch: 119, Loss: 38.64110565185547, Accuracy: 40.05304718017578, Test Loss: 29.799734115600586, Test Accuracy: 50.84745788574219\n",
      "Epoch: 120, Loss: 38.33721923828125, Accuracy: 40.583553314208984, Test Loss: 29.52478790283203, Test Accuracy: 50.84745788574219\n",
      "Epoch: 121, Loss: 38.0378303527832, Accuracy: 39.522544860839844, Test Loss: 29.261577606201172, Test Accuracy: 50.0\n",
      "Epoch: 122, Loss: 37.75611877441406, Accuracy: 39.257293701171875, Test Loss: 29.007566452026367, Test Accuracy: 50.0\n",
      "Epoch: 123, Loss: 37.4850959777832, Accuracy: 38.992042541503906, Test Loss: 28.76087188720703, Test Accuracy: 50.0\n",
      "Epoch: 124, Loss: 37.211021423339844, Accuracy: 39.257293701171875, Test Loss: 28.521854400634766, Test Accuracy: 50.0\n",
      "Epoch: 125, Loss: 36.92939376831055, Accuracy: 38.992042541503906, Test Loss: 28.290584564208984, Test Accuracy: 50.0\n",
      "Epoch: 126, Loss: 36.64997863769531, Accuracy: 38.72678756713867, Test Loss: 28.06745147705078, Test Accuracy: 50.0\n",
      "Epoch: 127, Loss: 36.381752014160156, Accuracy: 38.992042541503906, Test Loss: 27.849510192871094, Test Accuracy: 50.0\n",
      "Epoch: 128, Loss: 36.12132263183594, Accuracy: 38.992042541503906, Test Loss: 27.629003524780273, Test Accuracy: 50.0\n",
      "Epoch: 129, Loss: 35.85919189453125, Accuracy: 38.992042541503906, Test Loss: 27.403860092163086, Test Accuracy: 49.15254211425781\n",
      "Epoch: 130, Loss: 35.59300231933594, Accuracy: 38.992042541503906, Test Loss: 27.180299758911133, Test Accuracy: 48.305084228515625\n",
      "Epoch: 131, Loss: 35.32794189453125, Accuracy: 38.72678756713867, Test Loss: 26.966400146484375, Test Accuracy: 48.305084228515625\n",
      "Epoch: 132, Loss: 35.068702697753906, Accuracy: 38.72678756713867, Test Loss: 26.765602111816406, Test Accuracy: 49.15254211425781\n",
      "Epoch: 133, Loss: 34.81332778930664, Accuracy: 38.46154022216797, Test Loss: 26.574668884277344, Test Accuracy: 49.15254211425781\n",
      "Epoch: 134, Loss: 34.55694580078125, Accuracy: 38.196285247802734, Test Loss: 26.38973617553711, Test Accuracy: 50.0\n",
      "Epoch: 135, Loss: 34.29828643798828, Accuracy: 38.72678756713867, Test Loss: 26.208860397338867, Test Accuracy: 50.0\n",
      "Epoch: 136, Loss: 34.04081344604492, Accuracy: 38.72678756713867, Test Loss: 26.031476974487305, Test Accuracy: 50.0\n",
      "Epoch: 137, Loss: 33.787166595458984, Accuracy: 38.992042541503906, Test Loss: 25.85664939880371, Test Accuracy: 50.0\n",
      "Epoch: 138, Loss: 33.53636169433594, Accuracy: 38.72678756713867, Test Loss: 25.682493209838867, Test Accuracy: 50.0\n",
      "Epoch: 139, Loss: 33.286251068115234, Accuracy: 38.72678756713867, Test Loss: 25.50865936279297, Test Accuracy: 50.0\n",
      "Epoch: 140, Loss: 33.03651428222656, Accuracy: 39.257293701171875, Test Loss: 25.33721160888672, Test Accuracy: 49.15254211425781\n",
      "Epoch: 141, Loss: 32.78864288330078, Accuracy: 39.257293701171875, Test Loss: 25.169858932495117, Test Accuracy: 48.305084228515625\n",
      "Epoch: 142, Loss: 32.54365921020508, Accuracy: 39.522544860839844, Test Loss: 25.006011962890625, Test Accuracy: 48.305084228515625\n",
      "Epoch: 143, Loss: 32.30093002319336, Accuracy: 38.992042541503906, Test Loss: 24.84419822692871, Test Accuracy: 48.305084228515625\n",
      "Epoch: 144, Loss: 32.058773040771484, Accuracy: 38.992042541503906, Test Loss: 24.68391990661621, Test Accuracy: 48.305084228515625\n",
      "Epoch: 145, Loss: 31.816579818725586, Accuracy: 39.257293701171875, Test Loss: 24.52599334716797, Test Accuracy: 49.15254211425781\n",
      "Epoch: 146, Loss: 31.575214385986328, Accuracy: 39.257293701171875, Test Loss: 24.371400833129883, Test Accuracy: 49.15254211425781\n",
      "Epoch: 147, Loss: 31.33538246154785, Accuracy: 39.257293701171875, Test Loss: 24.21986198425293, Test Accuracy: 50.0\n",
      "Epoch: 148, Loss: 31.096843719482422, Accuracy: 39.522544860839844, Test Loss: 24.069889068603516, Test Accuracy: 50.84745788574219\n",
      "Epoch: 149, Loss: 30.859012603759766, Accuracy: 39.522544860839844, Test Loss: 23.920473098754883, Test Accuracy: 50.84745788574219\n",
      "Epoch: 150, Loss: 30.62188148498535, Accuracy: 39.522544860839844, Test Loss: 23.77195930480957, Test Accuracy: 50.84745788574219\n",
      "Epoch: 151, Loss: 30.38617706298828, Accuracy: 39.522544860839844, Test Loss: 23.62545394897461, Test Accuracy: 50.84745788574219\n",
      "Epoch: 152, Loss: 30.15259552001953, Accuracy: 39.522544860839844, Test Loss: 23.481721878051758, Test Accuracy: 50.84745788574219\n",
      "Epoch: 153, Loss: 29.921051025390625, Accuracy: 39.257293701171875, Test Loss: 23.34099769592285, Test Accuracy: 50.84745788574219\n",
      "Epoch: 154, Loss: 29.691009521484375, Accuracy: 38.992042541503906, Test Loss: 23.203336715698242, Test Accuracy: 50.84745788574219\n",
      "Epoch: 155, Loss: 29.462413787841797, Accuracy: 39.257293701171875, Test Loss: 23.068429946899414, Test Accuracy: 51.694915771484375\n",
      "Epoch: 156, Loss: 29.235685348510742, Accuracy: 39.522544860839844, Test Loss: 22.935029983520508, Test Accuracy: 51.694915771484375\n",
      "Epoch: 157, Loss: 29.010995864868164, Accuracy: 39.522544860839844, Test Loss: 22.801490783691406, Test Accuracy: 51.694915771484375\n",
      "Epoch: 158, Loss: 28.788179397583008, Accuracy: 40.05304718017578, Test Loss: 22.666656494140625, Test Accuracy: 51.694915771484375\n",
      "Epoch: 159, Loss: 28.566917419433594, Accuracy: 39.78779983520508, Test Loss: 22.530536651611328, Test Accuracy: 51.694915771484375\n",
      "Epoch: 160, Loss: 28.347230911254883, Accuracy: 39.522544860839844, Test Loss: 22.39412498474121, Test Accuracy: 51.694915771484375\n",
      "Epoch: 161, Loss: 28.129417419433594, Accuracy: 39.522544860839844, Test Loss: 22.258304595947266, Test Accuracy: 51.694915771484375\n",
      "Epoch: 162, Loss: 27.913570404052734, Accuracy: 39.522544860839844, Test Loss: 22.123310089111328, Test Accuracy: 51.694915771484375\n",
      "Epoch: 163, Loss: 27.69940948486328, Accuracy: 40.05304718017578, Test Loss: 21.988746643066406, Test Accuracy: 50.84745788574219\n",
      "Epoch: 164, Loss: 27.48666000366211, Accuracy: 40.318302154541016, Test Loss: 21.854230880737305, Test Accuracy: 51.694915771484375\n",
      "Epoch: 165, Loss: 27.27549171447754, Accuracy: 40.05304718017578, Test Loss: 21.719200134277344, Test Accuracy: 50.84745788574219\n",
      "Epoch: 166, Loss: 27.06608772277832, Accuracy: 40.318302154541016, Test Loss: 21.583099365234375, Test Accuracy: 50.0\n",
      "Epoch: 167, Loss: 26.85817527770996, Accuracy: 40.583553314208984, Test Loss: 21.44575309753418, Test Accuracy: 50.0\n",
      "Epoch: 168, Loss: 26.65145492553711, Accuracy: 40.583553314208984, Test Loss: 21.30765151977539, Test Accuracy: 50.0\n",
      "Epoch: 169, Loss: 26.445941925048828, Accuracy: 40.583553314208984, Test Loss: 21.169143676757812, Test Accuracy: 50.0\n",
      "Epoch: 170, Loss: 26.2418270111084, Accuracy: 40.583553314208984, Test Loss: 21.03005599975586, Test Accuracy: 50.0\n",
      "Epoch: 171, Loss: 26.039161682128906, Accuracy: 40.84880828857422, Test Loss: 20.889936447143555, Test Accuracy: 49.15254211425781\n",
      "Epoch: 172, Loss: 25.837779998779297, Accuracy: 40.84880828857422, Test Loss: 20.748477935791016, Test Accuracy: 49.15254211425781\n",
      "Epoch: 173, Loss: 25.6376953125, Accuracy: 40.583553314208984, Test Loss: 20.605772018432617, Test Accuracy: 49.15254211425781\n",
      "Epoch: 174, Loss: 25.439083099365234, Accuracy: 40.583553314208984, Test Loss: 20.46224021911621, Test Accuracy: 49.15254211425781\n",
      "Epoch: 175, Loss: 25.242080688476562, Accuracy: 40.318302154541016, Test Loss: 20.318195343017578, Test Accuracy: 49.15254211425781\n",
      "Epoch: 176, Loss: 25.046663284301758, Accuracy: 40.05304718017578, Test Loss: 20.173988342285156, Test Accuracy: 49.15254211425781\n",
      "Epoch: 177, Loss: 24.85267448425293, Accuracy: 39.78779983520508, Test Loss: 20.029949188232422, Test Accuracy: 49.15254211425781\n",
      "Epoch: 178, Loss: 24.660097122192383, Accuracy: 39.78779983520508, Test Loss: 19.886302947998047, Test Accuracy: 49.15254211425781\n",
      "Epoch: 179, Loss: 24.469024658203125, Accuracy: 39.78779983520508, Test Loss: 19.743045806884766, Test Accuracy: 49.15254211425781\n",
      "Epoch: 180, Loss: 24.27937889099121, Accuracy: 40.05304718017578, Test Loss: 19.600065231323242, Test Accuracy: 50.0\n",
      "Epoch: 181, Loss: 24.091079711914062, Accuracy: 40.318302154541016, Test Loss: 19.457454681396484, Test Accuracy: 49.15254211425781\n",
      "Epoch: 182, Loss: 23.904081344604492, Accuracy: 40.583553314208984, Test Loss: 19.31556510925293, Test Accuracy: 49.15254211425781\n",
      "Epoch: 183, Loss: 23.71849822998047, Accuracy: 40.318302154541016, Test Loss: 19.17486000061035, Test Accuracy: 49.15254211425781\n",
      "Epoch: 184, Loss: 23.53436279296875, Accuracy: 40.318302154541016, Test Loss: 19.035743713378906, Test Accuracy: 49.15254211425781\n",
      "Epoch: 185, Loss: 23.351511001586914, Accuracy: 40.318302154541016, Test Loss: 18.8984432220459, Test Accuracy: 49.15254211425781\n",
      "Epoch: 186, Loss: 23.169757843017578, Accuracy: 40.05304718017578, Test Loss: 18.76290512084961, Test Accuracy: 49.15254211425781\n",
      "Epoch: 187, Loss: 22.989103317260742, Accuracy: 39.522544860839844, Test Loss: 18.628877639770508, Test Accuracy: 49.15254211425781\n",
      "Epoch: 188, Loss: 22.809572219848633, Accuracy: 39.522544860839844, Test Loss: 18.4958438873291, Test Accuracy: 49.15254211425781\n",
      "Epoch: 189, Loss: 22.63104248046875, Accuracy: 39.522544860839844, Test Loss: 18.363481521606445, Test Accuracy: 49.15254211425781\n",
      "Epoch: 190, Loss: 22.45343589782715, Accuracy: 39.522544860839844, Test Loss: 18.23200035095215, Test Accuracy: 48.305084228515625\n",
      "Epoch: 191, Loss: 22.27678108215332, Accuracy: 39.522544860839844, Test Loss: 18.1019229888916, Test Accuracy: 48.305084228515625\n",
      "Epoch: 192, Loss: 22.101112365722656, Accuracy: 39.78779983520508, Test Loss: 17.973661422729492, Test Accuracy: 48.305084228515625\n",
      "Epoch: 193, Loss: 21.926340103149414, Accuracy: 39.78779983520508, Test Loss: 17.847139358520508, Test Accuracy: 48.305084228515625\n",
      "Epoch: 194, Loss: 21.7524471282959, Accuracy: 39.78779983520508, Test Loss: 17.721759796142578, Test Accuracy: 48.305084228515625\n",
      "Epoch: 195, Loss: 21.579511642456055, Accuracy: 40.05304718017578, Test Loss: 17.596721649169922, Test Accuracy: 48.305084228515625\n",
      "Epoch: 196, Loss: 21.407440185546875, Accuracy: 40.583553314208984, Test Loss: 17.471590042114258, Test Accuracy: 48.305084228515625\n",
      "Epoch: 197, Loss: 21.236154556274414, Accuracy: 40.583553314208984, Test Loss: 17.346830368041992, Test Accuracy: 48.305084228515625\n",
      "Epoch: 198, Loss: 21.065696716308594, Accuracy: 40.318302154541016, Test Loss: 17.22304916381836, Test Accuracy: 48.305084228515625\n",
      "Epoch: 199, Loss: 20.895936965942383, Accuracy: 40.583553314208984, Test Loss: 17.100467681884766, Test Accuracy: 48.305084228515625\n",
      "Epoch: 200, Loss: 20.72684669494629, Accuracy: 40.583553314208984, Test Loss: 16.978593826293945, Test Accuracy: 47.45762634277344\n",
      "Epoch: 201, Loss: 20.558380126953125, Accuracy: 40.583553314208984, Test Loss: 16.856603622436523, Test Accuracy: 47.45762634277344\n",
      "Epoch: 202, Loss: 20.39051628112793, Accuracy: 40.583553314208984, Test Loss: 16.733964920043945, Test Accuracy: 47.45762634277344\n",
      "Epoch: 203, Loss: 20.2231502532959, Accuracy: 40.583553314208984, Test Loss: 16.610992431640625, Test Accuracy: 47.45762634277344\n",
      "Epoch: 204, Loss: 20.056283950805664, Accuracy: 40.583553314208984, Test Loss: 16.488231658935547, Test Accuracy: 47.45762634277344\n",
      "Epoch: 205, Loss: 19.889923095703125, Accuracy: 40.583553314208984, Test Loss: 16.365938186645508, Test Accuracy: 47.45762634277344\n",
      "Epoch: 206, Loss: 19.72401237487793, Accuracy: 40.318302154541016, Test Loss: 16.24382209777832, Test Accuracy: 47.45762634277344\n",
      "Epoch: 207, Loss: 19.55854034423828, Accuracy: 40.318302154541016, Test Loss: 16.12127113342285, Test Accuracy: 47.45762634277344\n",
      "Epoch: 208, Loss: 19.393526077270508, Accuracy: 40.318302154541016, Test Loss: 15.997882843017578, Test Accuracy: 47.45762634277344\n",
      "Epoch: 209, Loss: 19.22893714904785, Accuracy: 40.318302154541016, Test Loss: 15.873831748962402, Test Accuracy: 47.45762634277344\n",
      "Epoch: 210, Loss: 19.06475830078125, Accuracy: 40.318302154541016, Test Loss: 15.749638557434082, Test Accuracy: 47.45762634277344\n",
      "Epoch: 211, Loss: 18.901029586791992, Accuracy: 40.583553314208984, Test Loss: 15.625541687011719, Test Accuracy: 47.45762634277344\n",
      "Epoch: 212, Loss: 18.73769187927246, Accuracy: 40.583553314208984, Test Loss: 15.501440048217773, Test Accuracy: 47.45762634277344\n",
      "Epoch: 213, Loss: 18.57476234436035, Accuracy: 40.583553314208984, Test Loss: 15.376911163330078, Test Accuracy: 47.45762634277344\n",
      "Epoch: 214, Loss: 18.412267684936523, Accuracy: 41.11405944824219, Test Loss: 15.251731872558594, Test Accuracy: 47.45762634277344\n",
      "Epoch: 215, Loss: 18.25017547607422, Accuracy: 41.379310607910156, Test Loss: 15.126063346862793, Test Accuracy: 47.45762634277344\n",
      "Epoch: 216, Loss: 18.0885066986084, Accuracy: 41.379310607910156, Test Loss: 15.000293731689453, Test Accuracy: 47.45762634277344\n",
      "Epoch: 217, Loss: 17.927217483520508, Accuracy: 41.379310607910156, Test Loss: 14.874666213989258, Test Accuracy: 47.45762634277344\n",
      "Epoch: 218, Loss: 17.766332626342773, Accuracy: 41.379310607910156, Test Loss: 14.749105453491211, Test Accuracy: 48.305084228515625\n",
      "Epoch: 219, Loss: 17.60584259033203, Accuracy: 41.379310607910156, Test Loss: 14.623391151428223, Test Accuracy: 48.305084228515625\n",
      "Epoch: 220, Loss: 17.44574737548828, Accuracy: 41.11405944824219, Test Loss: 14.497429847717285, Test Accuracy: 48.305084228515625\n",
      "Epoch: 221, Loss: 17.28604507446289, Accuracy: 41.11405944824219, Test Loss: 14.37134838104248, Test Accuracy: 48.305084228515625\n",
      "Epoch: 222, Loss: 17.12671661376953, Accuracy: 41.379310607910156, Test Loss: 14.245382308959961, Test Accuracy: 48.305084228515625\n",
      "Epoch: 223, Loss: 16.967792510986328, Accuracy: 41.379310607910156, Test Loss: 14.119674682617188, Test Accuracy: 48.305084228515625\n",
      "Epoch: 224, Loss: 16.809261322021484, Accuracy: 42.4403190612793, Test Loss: 13.994213104248047, Test Accuracy: 48.305084228515625\n",
      "Epoch: 225, Loss: 16.65110206604004, Accuracy: 42.4403190612793, Test Loss: 13.8688383102417, Test Accuracy: 48.305084228515625\n",
      "Epoch: 226, Loss: 16.493343353271484, Accuracy: 42.4403190612793, Test Loss: 13.743501663208008, Test Accuracy: 48.305084228515625\n",
      "Epoch: 227, Loss: 16.335969924926758, Accuracy: 42.4403190612793, Test Loss: 13.618279457092285, Test Accuracy: 48.305084228515625\n",
      "Epoch: 228, Loss: 16.178977966308594, Accuracy: 42.4403190612793, Test Loss: 13.493325233459473, Test Accuracy: 48.305084228515625\n",
      "Epoch: 229, Loss: 16.022382736206055, Accuracy: 42.705570220947266, Test Loss: 13.368735313415527, Test Accuracy: 48.305084228515625\n",
      "Epoch: 230, Loss: 15.866215705871582, Accuracy: 42.705570220947266, Test Loss: 13.244446754455566, Test Accuracy: 48.305084228515625\n",
      "Epoch: 231, Loss: 15.71045207977295, Accuracy: 42.705570220947266, Test Loss: 13.120368957519531, Test Accuracy: 48.305084228515625\n",
      "Epoch: 232, Loss: 15.555069923400879, Accuracy: 42.705570220947266, Test Loss: 12.996535301208496, Test Accuracy: 48.305084228515625\n",
      "Epoch: 233, Loss: 15.400115966796875, Accuracy: 42.705570220947266, Test Loss: 12.872997283935547, Test Accuracy: 48.305084228515625\n",
      "Epoch: 234, Loss: 15.245586395263672, Accuracy: 42.970821380615234, Test Loss: 12.749824523925781, Test Accuracy: 49.15254211425781\n",
      "Epoch: 235, Loss: 15.091485023498535, Accuracy: 42.705570220947266, Test Loss: 12.62707233428955, Test Accuracy: 49.15254211425781\n",
      "Epoch: 236, Loss: 14.937785148620605, Accuracy: 42.705570220947266, Test Loss: 12.504708290100098, Test Accuracy: 49.15254211425781\n",
      "Epoch: 237, Loss: 14.784525871276855, Accuracy: 42.705570220947266, Test Loss: 12.38269329071045, Test Accuracy: 49.15254211425781\n",
      "Epoch: 238, Loss: 14.631685256958008, Accuracy: 42.970821380615234, Test Loss: 12.261069297790527, Test Accuracy: 49.15254211425781\n",
      "Epoch: 239, Loss: 14.47927474975586, Accuracy: 43.2360725402832, Test Loss: 12.139863967895508, Test Accuracy: 49.15254211425781\n",
      "Epoch: 240, Loss: 14.327281951904297, Accuracy: 43.2360725402832, Test Loss: 12.019113540649414, Test Accuracy: 50.84745788574219\n",
      "Epoch: 241, Loss: 14.1757230758667, Accuracy: 43.2360725402832, Test Loss: 11.898805618286133, Test Accuracy: 50.84745788574219\n",
      "Epoch: 242, Loss: 14.024599075317383, Accuracy: 43.2360725402832, Test Loss: 11.778909683227539, Test Accuracy: 50.84745788574219\n",
      "Epoch: 243, Loss: 13.8739013671875, Accuracy: 43.2360725402832, Test Loss: 11.659436225891113, Test Accuracy: 50.84745788574219\n",
      "Epoch: 244, Loss: 13.72364616394043, Accuracy: 43.50132751464844, Test Loss: 11.540375709533691, Test Accuracy: 50.84745788574219\n",
      "Epoch: 245, Loss: 13.573856353759766, Accuracy: 43.50132751464844, Test Loss: 11.421704292297363, Test Accuracy: 50.84745788574219\n",
      "Epoch: 246, Loss: 13.424529075622559, Accuracy: 43.50132751464844, Test Loss: 11.303383827209473, Test Accuracy: 51.694915771484375\n",
      "Epoch: 247, Loss: 13.275662422180176, Accuracy: 43.50132751464844, Test Loss: 11.185359001159668, Test Accuracy: 51.694915771484375\n",
      "Epoch: 248, Loss: 13.127304077148438, Accuracy: 43.50132751464844, Test Loss: 11.067609786987305, Test Accuracy: 51.694915771484375\n",
      "Epoch: 249, Loss: 12.979455947875977, Accuracy: 43.50132751464844, Test Loss: 10.950089454650879, Test Accuracy: 51.694915771484375\n",
      "Epoch: 250, Loss: 12.832151412963867, Accuracy: 44.031829833984375, Test Loss: 10.832698822021484, Test Accuracy: 51.694915771484375\n",
      "Epoch: 251, Loss: 12.685386657714844, Accuracy: 44.031829833984375, Test Loss: 10.71533489227295, Test Accuracy: 50.84745788574219\n",
      "Epoch: 252, Loss: 12.539207458496094, Accuracy: 44.031829833984375, Test Loss: 10.597947120666504, Test Accuracy: 50.84745788574219\n",
      "Epoch: 253, Loss: 12.393590927124023, Accuracy: 44.031829833984375, Test Loss: 10.480480194091797, Test Accuracy: 50.84745788574219\n",
      "Epoch: 254, Loss: 12.24854850769043, Accuracy: 44.031829833984375, Test Loss: 10.362908363342285, Test Accuracy: 50.84745788574219\n",
      "Epoch: 255, Loss: 12.104072570800781, Accuracy: 44.297080993652344, Test Loss: 10.245163917541504, Test Accuracy: 51.694915771484375\n",
      "Epoch: 256, Loss: 11.96016788482666, Accuracy: 44.297080993652344, Test Loss: 10.127239227294922, Test Accuracy: 51.694915771484375\n",
      "Epoch: 257, Loss: 11.816825866699219, Accuracy: 44.297080993652344, Test Loss: 10.009101867675781, Test Accuracy: 51.694915771484375\n",
      "Epoch: 258, Loss: 11.674040794372559, Accuracy: 44.56233215332031, Test Loss: 9.890851974487305, Test Accuracy: 51.694915771484375\n",
      "Epoch: 259, Loss: 11.531807899475098, Accuracy: 44.56233215332031, Test Loss: 9.772571563720703, Test Accuracy: 51.694915771484375\n",
      "Epoch: 260, Loss: 11.39015007019043, Accuracy: 45.358089447021484, Test Loss: 9.65430736541748, Test Accuracy: 51.694915771484375\n",
      "Epoch: 261, Loss: 11.249053001403809, Accuracy: 45.62334060668945, Test Loss: 9.536062240600586, Test Accuracy: 51.694915771484375\n",
      "Epoch: 262, Loss: 11.108592987060547, Accuracy: 45.62334060668945, Test Loss: 9.417953491210938, Test Accuracy: 51.694915771484375\n",
      "Epoch: 263, Loss: 10.968745231628418, Accuracy: 45.62334060668945, Test Loss: 9.300121307373047, Test Accuracy: 51.694915771484375\n",
      "Epoch: 264, Loss: 10.829561233520508, Accuracy: 45.88859558105469, Test Loss: 9.182616233825684, Test Accuracy: 53.389827728271484\n",
      "Epoch: 265, Loss: 10.691052436828613, Accuracy: 45.88859558105469, Test Loss: 9.065544128417969, Test Accuracy: 53.389827728271484\n",
      "Epoch: 266, Loss: 10.553248405456543, Accuracy: 45.62334060668945, Test Loss: 8.948939323425293, Test Accuracy: 53.389827728271484\n",
      "Epoch: 267, Loss: 10.416186332702637, Accuracy: 45.62334060668945, Test Loss: 8.83290958404541, Test Accuracy: 53.389827728271484\n",
      "Epoch: 268, Loss: 10.279858589172363, Accuracy: 45.88859558105469, Test Loss: 8.71756649017334, Test Accuracy: 53.389827728271484\n",
      "Epoch: 269, Loss: 10.144293785095215, Accuracy: 46.419097900390625, Test Loss: 8.602993965148926, Test Accuracy: 53.389827728271484\n",
      "Epoch: 270, Loss: 10.009461402893066, Accuracy: 46.684349060058594, Test Loss: 8.489178657531738, Test Accuracy: 52.5423698425293\n",
      "Epoch: 271, Loss: 9.87539291381836, Accuracy: 46.684349060058594, Test Loss: 8.376204490661621, Test Accuracy: 53.389827728271484\n",
      "Epoch: 272, Loss: 9.742049217224121, Accuracy: 46.94960021972656, Test Loss: 8.264130592346191, Test Accuracy: 53.389827728271484\n",
      "Epoch: 273, Loss: 9.609471321105957, Accuracy: 46.94960021972656, Test Loss: 8.153053283691406, Test Accuracy: 54.23728942871094\n",
      "Epoch: 274, Loss: 9.477621078491211, Accuracy: 47.2148551940918, Test Loss: 8.042927742004395, Test Accuracy: 54.23728942871094\n",
      "Epoch: 275, Loss: 9.346502304077148, Accuracy: 47.480106353759766, Test Loss: 7.933806896209717, Test Accuracy: 55.084747314453125\n",
      "Epoch: 276, Loss: 9.216099739074707, Accuracy: 48.0106086730957, Test Loss: 7.8256707191467285, Test Accuracy: 55.93220520019531\n",
      "Epoch: 277, Loss: 9.086405754089355, Accuracy: 48.0106086730957, Test Loss: 7.71857213973999, Test Accuracy: 55.93220520019531\n",
      "Epoch: 278, Loss: 8.957429885864258, Accuracy: 48.0106086730957, Test Loss: 7.612444877624512, Test Accuracy: 55.93220520019531\n",
      "Epoch: 279, Loss: 8.829157829284668, Accuracy: 48.0106086730957, Test Loss: 7.5072455406188965, Test Accuracy: 55.93220520019531\n",
      "Epoch: 280, Loss: 8.701584815979004, Accuracy: 48.0106086730957, Test Loss: 7.402936935424805, Test Accuracy: 56.779659271240234\n",
      "Epoch: 281, Loss: 8.57473087310791, Accuracy: 48.27585983276367, Test Loss: 7.299500465393066, Test Accuracy: 56.779659271240234\n",
      "Epoch: 282, Loss: 8.448548316955566, Accuracy: 48.27585983276367, Test Loss: 7.196837902069092, Test Accuracy: 56.779659271240234\n",
      "Epoch: 283, Loss: 8.323099136352539, Accuracy: 48.27585983276367, Test Loss: 7.09489631652832, Test Accuracy: 56.779659271240234\n",
      "Epoch: 284, Loss: 8.198373794555664, Accuracy: 47.745357513427734, Test Loss: 6.99357795715332, Test Accuracy: 56.779659271240234\n",
      "Epoch: 285, Loss: 8.074362754821777, Accuracy: 48.0106086730957, Test Loss: 6.892848014831543, Test Accuracy: 56.779659271240234\n",
      "Epoch: 286, Loss: 7.951099395751953, Accuracy: 48.27585983276367, Test Loss: 6.792623043060303, Test Accuracy: 56.779659271240234\n",
      "Epoch: 287, Loss: 7.828573703765869, Accuracy: 48.541114807128906, Test Loss: 6.692781925201416, Test Accuracy: 56.779659271240234\n",
      "Epoch: 288, Loss: 7.706778049468994, Accuracy: 48.541114807128906, Test Loss: 6.593275547027588, Test Accuracy: 56.779659271240234\n",
      "Epoch: 289, Loss: 7.585765838623047, Accuracy: 48.27585983276367, Test Loss: 6.494052886962891, Test Accuracy: 56.779659271240234\n",
      "Epoch: 290, Loss: 7.465494155883789, Accuracy: 48.27585983276367, Test Loss: 6.394999027252197, Test Accuracy: 56.779659271240234\n",
      "Epoch: 291, Loss: 7.345993995666504, Accuracy: 48.0106086730957, Test Loss: 6.296037197113037, Test Accuracy: 56.779659271240234\n",
      "Epoch: 292, Loss: 7.227272033691406, Accuracy: 48.541114807128906, Test Loss: 6.1971540451049805, Test Accuracy: 56.779659271240234\n",
      "Epoch: 293, Loss: 7.109333515167236, Accuracy: 48.806365966796875, Test Loss: 6.098332405090332, Test Accuracy: 56.779659271240234\n",
      "Epoch: 294, Loss: 6.992162227630615, Accuracy: 49.071617126464844, Test Loss: 5.999482154846191, Test Accuracy: 56.779659271240234\n",
      "Epoch: 295, Loss: 6.875772476196289, Accuracy: 49.33686828613281, Test Loss: 5.90069055557251, Test Accuracy: 56.779659271240234\n",
      "Epoch: 296, Loss: 6.760188579559326, Accuracy: 49.60211944580078, Test Loss: 5.802025318145752, Test Accuracy: 56.779659271240234\n",
      "Epoch: 297, Loss: 6.645417213439941, Accuracy: 49.60211944580078, Test Loss: 5.7034831047058105, Test Accuracy: 56.779659271240234\n",
      "Epoch: 298, Loss: 6.531471252441406, Accuracy: 49.60211944580078, Test Loss: 5.6051836013793945, Test Accuracy: 56.779659271240234\n",
      "Epoch: 299, Loss: 6.418381690979004, Accuracy: 49.867374420166016, Test Loss: 5.507246971130371, Test Accuracy: 56.779659271240234\n",
      "Epoch: 300, Loss: 6.3061909675598145, Accuracy: 49.33686828613281, Test Loss: 5.409775733947754, Test Accuracy: 57.62711715698242\n",
      "Epoch: 301, Loss: 6.1949076652526855, Accuracy: 49.867374420166016, Test Loss: 5.312880992889404, Test Accuracy: 57.62711715698242\n",
      "Epoch: 302, Loss: 6.084570407867432, Accuracy: 49.867374420166016, Test Loss: 5.216669082641602, Test Accuracy: 56.779659271240234\n",
      "Epoch: 303, Loss: 5.975195407867432, Accuracy: 50.132625579833984, Test Loss: 5.121312618255615, Test Accuracy: 57.62711715698242\n",
      "Epoch: 304, Loss: 5.866801738739014, Accuracy: 50.132625579833984, Test Loss: 5.026926040649414, Test Accuracy: 57.62711715698242\n",
      "Epoch: 305, Loss: 5.759432315826416, Accuracy: 50.66313171386719, Test Loss: 4.933687686920166, Test Accuracy: 57.62711715698242\n",
      "Epoch: 306, Loss: 5.653099536895752, Accuracy: 50.66313171386719, Test Loss: 4.841753959655762, Test Accuracy: 57.62711715698242\n",
      "Epoch: 307, Loss: 5.547842502593994, Accuracy: 50.66313171386719, Test Loss: 4.751297950744629, Test Accuracy: 57.62711715698242\n",
      "Epoch: 308, Loss: 5.443687915802002, Accuracy: 50.66313171386719, Test Loss: 4.66249942779541, Test Accuracy: 57.62711715698242\n",
      "Epoch: 309, Loss: 5.3406500816345215, Accuracy: 50.66313171386719, Test Loss: 4.57544469833374, Test Accuracy: 57.62711715698242\n",
      "Epoch: 310, Loss: 5.2387542724609375, Accuracy: 50.39788055419922, Test Loss: 4.490261554718018, Test Accuracy: 57.62711715698242\n",
      "Epoch: 311, Loss: 5.138031959533691, Accuracy: 50.132625579833984, Test Loss: 4.407011985778809, Test Accuracy: 56.779659271240234\n",
      "Epoch: 312, Loss: 5.038473606109619, Accuracy: 50.92837905883789, Test Loss: 4.3257365226745605, Test Accuracy: 56.779659271240234\n",
      "Epoch: 313, Loss: 4.940155506134033, Accuracy: 50.92837905883789, Test Loss: 4.246515274047852, Test Accuracy: 56.779659271240234\n",
      "Epoch: 314, Loss: 4.843080997467041, Accuracy: 50.92837905883789, Test Loss: 4.169428825378418, Test Accuracy: 56.779659271240234\n",
      "Epoch: 315, Loss: 4.7472968101501465, Accuracy: 50.92837905883789, Test Loss: 4.094595909118652, Test Accuracy: 57.62711715698242\n",
      "Epoch: 316, Loss: 4.652901649475098, Accuracy: 51.19363021850586, Test Loss: 4.022190570831299, Test Accuracy: 57.62711715698242\n",
      "Epoch: 317, Loss: 4.559993743896484, Accuracy: 51.458885192871094, Test Loss: 3.952341318130493, Test Accuracy: 57.62711715698242\n",
      "Epoch: 318, Loss: 4.468629360198975, Accuracy: 51.72413635253906, Test Loss: 3.8851726055145264, Test Accuracy: 58.47457504272461\n",
      "Epoch: 319, Loss: 4.3789215087890625, Accuracy: 51.72413635253906, Test Loss: 3.8206627368927, Test Accuracy: 58.47457504272461\n",
      "Epoch: 320, Loss: 4.290921688079834, Accuracy: 52.519893646240234, Test Loss: 3.75868558883667, Test Accuracy: 58.47457504272461\n",
      "Epoch: 321, Loss: 4.204677104949951, Accuracy: 52.7851448059082, Test Loss: 3.6989388465881348, Test Accuracy: 58.47457504272461\n",
      "Epoch: 322, Loss: 4.120214462280273, Accuracy: 53.05039978027344, Test Loss: 3.6412205696105957, Test Accuracy: 58.47457504272461\n",
      "Epoch: 323, Loss: 4.037586212158203, Accuracy: 53.58089828491211, Test Loss: 3.5852975845336914, Test Accuracy: 58.47457504272461\n",
      "Epoch: 324, Loss: 3.9567596912384033, Accuracy: 53.58089828491211, Test Loss: 3.530822515487671, Test Accuracy: 58.47457504272461\n",
      "Epoch: 325, Loss: 3.877753496170044, Accuracy: 53.84614944458008, Test Loss: 3.477672815322876, Test Accuracy: 57.62711715698242\n",
      "Epoch: 326, Loss: 3.800565004348755, Accuracy: 53.58089828491211, Test Loss: 3.4256248474121094, Test Accuracy: 57.62711715698242\n",
      "Epoch: 327, Loss: 3.7252378463745117, Accuracy: 54.11140441894531, Test Loss: 3.3744325637817383, Test Accuracy: 58.47457504272461\n",
      "Epoch: 328, Loss: 3.651801824569702, Accuracy: 54.11140441894531, Test Loss: 3.3239758014678955, Test Accuracy: 58.47457504272461\n",
      "Epoch: 329, Loss: 3.5803022384643555, Accuracy: 53.84614944458008, Test Loss: 3.2741971015930176, Test Accuracy: 58.47457504272461\n",
      "Epoch: 330, Loss: 3.510845184326172, Accuracy: 54.37665557861328, Test Loss: 3.224921464920044, Test Accuracy: 57.62711715698242\n",
      "Epoch: 331, Loss: 3.4435064792633057, Accuracy: 54.64190673828125, Test Loss: 3.1761326789855957, Test Accuracy: 57.62711715698242\n",
      "Epoch: 332, Loss: 3.3783981800079346, Accuracy: 55.43766784667969, Test Loss: 3.12782883644104, Test Accuracy: 57.62711715698242\n",
      "Epoch: 333, Loss: 3.3155977725982666, Accuracy: 55.43766784667969, Test Loss: 3.079929828643799, Test Accuracy: 57.62711715698242\n",
      "Epoch: 334, Loss: 3.2551541328430176, Accuracy: 55.17241287231445, Test Loss: 3.0324532985687256, Test Accuracy: 56.779659271240234\n",
      "Epoch: 335, Loss: 3.1970434188842773, Accuracy: 55.968170166015625, Test Loss: 2.985506057739258, Test Accuracy: 56.779659271240234\n",
      "Epoch: 336, Loss: 3.141172170639038, Accuracy: 56.23341751098633, Test Loss: 2.9389760494232178, Test Accuracy: 57.62711715698242\n",
      "Epoch: 337, Loss: 3.0874557495117188, Accuracy: 56.49867248535156, Test Loss: 2.8930723667144775, Test Accuracy: 57.62711715698242\n",
      "Epoch: 338, Loss: 3.035773515701294, Accuracy: 56.49867248535156, Test Loss: 2.8478658199310303, Test Accuracy: 57.62711715698242\n",
      "Epoch: 339, Loss: 2.985976457595825, Accuracy: 56.76392364501953, Test Loss: 2.8034493923187256, Test Accuracy: 57.62711715698242\n",
      "Epoch: 340, Loss: 2.9379825592041016, Accuracy: 56.23341751098633, Test Loss: 2.7600369453430176, Test Accuracy: 57.62711715698242\n",
      "Epoch: 341, Loss: 2.8916759490966797, Accuracy: 56.23341751098633, Test Loss: 2.7177178859710693, Test Accuracy: 57.62711715698242\n",
      "Epoch: 342, Loss: 2.8469581604003906, Accuracy: 56.23341751098633, Test Loss: 2.6765694618225098, Test Accuracy: 57.62711715698242\n",
      "Epoch: 343, Loss: 2.803781270980835, Accuracy: 56.23341751098633, Test Loss: 2.636845827102661, Test Accuracy: 58.47457504272461\n",
      "Epoch: 344, Loss: 2.762075901031494, Accuracy: 55.702919006347656, Test Loss: 2.5984973907470703, Test Accuracy: 57.62711715698242\n",
      "Epoch: 345, Loss: 2.721784830093384, Accuracy: 55.702919006347656, Test Loss: 2.5616424083709717, Test Accuracy: 57.62711715698242\n",
      "Epoch: 346, Loss: 2.682877540588379, Accuracy: 55.968170166015625, Test Loss: 2.5263681411743164, Test Accuracy: 57.62711715698242\n",
      "Epoch: 347, Loss: 2.645306348800659, Accuracy: 56.23341751098633, Test Loss: 2.492502212524414, Test Accuracy: 58.47457504272461\n",
      "Epoch: 348, Loss: 2.6090753078460693, Accuracy: 56.23341751098633, Test Loss: 2.460280656814575, Test Accuracy: 57.62711715698242\n",
      "Epoch: 349, Loss: 2.5741217136383057, Accuracy: 56.76392364501953, Test Loss: 2.429342031478882, Test Accuracy: 57.62711715698242\n",
      "Epoch: 350, Loss: 2.5404438972473145, Accuracy: 56.23341751098633, Test Loss: 2.3998897075653076, Test Accuracy: 56.779659271240234\n",
      "Epoch: 351, Loss: 2.50801157951355, Accuracy: 56.23341751098633, Test Loss: 2.3716495037078857, Test Accuracy: 55.93220520019531\n",
      "Epoch: 352, Loss: 2.476783037185669, Accuracy: 57.0291748046875, Test Loss: 2.3445241451263428, Test Accuracy: 55.93220520019531\n",
      "Epoch: 353, Loss: 2.4467453956604004, Accuracy: 56.49867248535156, Test Loss: 2.318573474884033, Test Accuracy: 55.93220520019531\n",
      "Epoch: 354, Loss: 2.4178988933563232, Accuracy: 56.76392364501953, Test Loss: 2.293389081954956, Test Accuracy: 55.93220520019531\n",
      "Epoch: 355, Loss: 2.390151023864746, Accuracy: 56.23341751098633, Test Loss: 2.269228458404541, Test Accuracy: 56.779659271240234\n",
      "Epoch: 356, Loss: 2.363502264022827, Accuracy: 56.49867248535156, Test Loss: 2.245753049850464, Test Accuracy: 56.779659271240234\n",
      "Epoch: 357, Loss: 2.337912082672119, Accuracy: 57.0291748046875, Test Loss: 2.223125696182251, Test Accuracy: 56.779659271240234\n",
      "Epoch: 358, Loss: 2.3133208751678467, Accuracy: 57.294429779052734, Test Loss: 2.2013115882873535, Test Accuracy: 56.779659271240234\n",
      "Epoch: 359, Loss: 2.2897088527679443, Accuracy: 57.5596809387207, Test Loss: 2.1801388263702393, Test Accuracy: 56.779659271240234\n",
      "Epoch: 360, Loss: 2.267003059387207, Accuracy: 57.82493209838867, Test Loss: 2.159973621368408, Test Accuracy: 55.93220520019531\n",
      "Epoch: 361, Loss: 2.245185613632202, Accuracy: 58.090187072753906, Test Loss: 2.1403346061706543, Test Accuracy: 56.779659271240234\n",
      "Epoch: 362, Loss: 2.224191904067993, Accuracy: 58.355438232421875, Test Loss: 2.1217613220214844, Test Accuracy: 57.62711715698242\n",
      "Epoch: 363, Loss: 2.2039833068847656, Accuracy: 58.620689392089844, Test Loss: 2.1037402153015137, Test Accuracy: 58.47457504272461\n",
      "Epoch: 364, Loss: 2.184532403945923, Accuracy: 58.620689392089844, Test Loss: 2.0866539478302, Test Accuracy: 58.47457504272461\n",
      "Epoch: 365, Loss: 2.1657917499542236, Accuracy: 58.620689392089844, Test Loss: 2.0702085494995117, Test Accuracy: 58.47457504272461\n",
      "Epoch: 366, Loss: 2.1477460861206055, Accuracy: 58.88593673706055, Test Loss: 2.054525375366211, Test Accuracy: 58.47457504272461\n",
      "Epoch: 367, Loss: 2.130347490310669, Accuracy: 59.15119171142578, Test Loss: 2.0394985675811768, Test Accuracy: 57.62711715698242\n",
      "Epoch: 368, Loss: 2.1135916709899902, Accuracy: 58.88593673706055, Test Loss: 2.0250370502471924, Test Accuracy: 57.62711715698242\n",
      "Epoch: 369, Loss: 2.097440004348755, Accuracy: 59.15119171142578, Test Loss: 2.0111289024353027, Test Accuracy: 57.62711715698242\n",
      "Epoch: 370, Loss: 2.081864595413208, Accuracy: 59.41644287109375, Test Loss: 1.9976269006729126, Test Accuracy: 57.62711715698242\n",
      "Epoch: 371, Loss: 2.0668625831604004, Accuracy: 58.88593673706055, Test Loss: 1.9845608472824097, Test Accuracy: 57.62711715698242\n",
      "Epoch: 372, Loss: 2.0523946285247803, Accuracy: 58.88593673706055, Test Loss: 1.9716975688934326, Test Accuracy: 57.62711715698242\n",
      "Epoch: 373, Loss: 2.038435220718384, Accuracy: 58.620689392089844, Test Loss: 1.9591723680496216, Test Accuracy: 57.62711715698242\n",
      "Epoch: 374, Loss: 2.024972438812256, Accuracy: 59.15119171142578, Test Loss: 1.9466423988342285, Test Accuracy: 56.779659271240234\n",
      "Epoch: 375, Loss: 2.011988878250122, Accuracy: 58.88593673706055, Test Loss: 1.93449068069458, Test Accuracy: 55.93220520019531\n",
      "Epoch: 376, Loss: 1.9994474649429321, Accuracy: 58.88593673706055, Test Loss: 1.9221991300582886, Test Accuracy: 55.93220520019531\n",
      "Epoch: 377, Loss: 1.9873212575912476, Accuracy: 59.41644287109375, Test Loss: 1.910287618637085, Test Accuracy: 55.93220520019531\n",
      "Epoch: 378, Loss: 1.9756040573120117, Accuracy: 59.15119171142578, Test Loss: 1.89823317527771, Test Accuracy: 55.93220520019531\n",
      "Epoch: 379, Loss: 1.9642750024795532, Accuracy: 59.68169403076172, Test Loss: 1.8865842819213867, Test Accuracy: 55.93220520019531\n",
      "Epoch: 380, Loss: 1.953285574913025, Accuracy: 59.94694900512695, Test Loss: 1.87488853931427, Test Accuracy: 55.93220520019531\n",
      "Epoch: 381, Loss: 1.9426560401916504, Accuracy: 60.21220016479492, Test Loss: 1.863598346710205, Test Accuracy: 55.93220520019531\n",
      "Epoch: 382, Loss: 1.9323468208312988, Accuracy: 60.742706298828125, Test Loss: 1.8523763418197632, Test Accuracy: 56.779659271240234\n",
      "Epoch: 383, Loss: 1.9223568439483643, Accuracy: 60.742706298828125, Test Loss: 1.8414965867996216, Test Accuracy: 56.779659271240234\n",
      "Epoch: 384, Loss: 1.912642478942871, Accuracy: 60.742706298828125, Test Loss: 1.8308881521224976, Test Accuracy: 56.779659271240234\n",
      "Epoch: 385, Loss: 1.9032227993011475, Accuracy: 60.742706298828125, Test Loss: 1.8205167055130005, Test Accuracy: 56.779659271240234\n",
      "Epoch: 386, Loss: 1.8940696716308594, Accuracy: 61.007957458496094, Test Loss: 1.8105146884918213, Test Accuracy: 56.779659271240234\n",
      "Epoch: 387, Loss: 1.8851635456085205, Accuracy: 61.007957458496094, Test Loss: 1.8007208108901978, Test Accuracy: 56.779659271240234\n",
      "Epoch: 388, Loss: 1.8765093088150024, Accuracy: 61.007957458496094, Test Loss: 1.7912904024124146, Test Accuracy: 56.779659271240234\n",
      "Epoch: 389, Loss: 1.868077278137207, Accuracy: 61.007957458496094, Test Loss: 1.782058596611023, Test Accuracy: 56.779659271240234\n",
      "Epoch: 390, Loss: 1.8598729372024536, Accuracy: 61.27321243286133, Test Loss: 1.7731297016143799, Test Accuracy: 57.62711715698242\n",
      "Epoch: 391, Loss: 1.851880669593811, Accuracy: 61.8037109375, Test Loss: 1.7643927335739136, Test Accuracy: 57.62711715698242\n",
      "Epoch: 392, Loss: 1.844100832939148, Accuracy: 61.8037109375, Test Loss: 1.7559311389923096, Test Accuracy: 58.47457504272461\n",
      "Epoch: 393, Loss: 1.8365113735198975, Accuracy: 61.8037109375, Test Loss: 1.7475918531417847, Test Accuracy: 58.47457504272461\n",
      "Epoch: 394, Loss: 1.8291001319885254, Accuracy: 62.06896209716797, Test Loss: 1.73953378200531, Test Accuracy: 58.47457504272461\n",
      "Epoch: 395, Loss: 1.8218894004821777, Accuracy: 62.06896209716797, Test Loss: 1.731579065322876, Test Accuracy: 58.47457504272461\n",
      "Epoch: 396, Loss: 1.8148415088653564, Accuracy: 62.06896209716797, Test Loss: 1.7238173484802246, Test Accuracy: 58.47457504272461\n",
      "Epoch: 397, Loss: 1.807964563369751, Accuracy: 62.06896209716797, Test Loss: 1.716261625289917, Test Accuracy: 58.47457504272461\n",
      "Epoch: 398, Loss: 1.8012418746948242, Accuracy: 62.59946823120117, Test Loss: 1.7088263034820557, Test Accuracy: 58.47457504272461\n",
      "Epoch: 399, Loss: 1.7946795225143433, Accuracy: 62.3342170715332, Test Loss: 1.7015867233276367, Test Accuracy: 59.32203674316406\n",
      "Epoch: 400, Loss: 1.7882585525512695, Accuracy: 62.3342170715332, Test Loss: 1.6944409608840942, Test Accuracy: 59.32203674316406\n",
      "Epoch: 401, Loss: 1.7819733619689941, Accuracy: 62.3342170715332, Test Loss: 1.6875196695327759, Test Accuracy: 58.47457504272461\n",
      "Epoch: 402, Loss: 1.7758285999298096, Accuracy: 62.3342170715332, Test Loss: 1.6806743144989014, Test Accuracy: 58.47457504272461\n",
      "Epoch: 403, Loss: 1.76981520652771, Accuracy: 62.86471939086914, Test Loss: 1.6740578413009644, Test Accuracy: 58.47457504272461\n",
      "Epoch: 404, Loss: 1.7639399766921997, Accuracy: 63.129974365234375, Test Loss: 1.667522668838501, Test Accuracy: 58.47457504272461\n",
      "Epoch: 405, Loss: 1.7581866979599, Accuracy: 63.129974365234375, Test Loss: 1.6611932516098022, Test Accuracy: 58.47457504272461\n",
      "Epoch: 406, Loss: 1.752548098564148, Accuracy: 63.129974365234375, Test Loss: 1.6549257040023804, Test Accuracy: 58.47457504272461\n",
      "Epoch: 407, Loss: 1.7470283508300781, Accuracy: 63.129974365234375, Test Loss: 1.6488711833953857, Test Accuracy: 58.47457504272461\n",
      "Epoch: 408, Loss: 1.7416118383407593, Accuracy: 63.129974365234375, Test Loss: 1.6428641080856323, Test Accuracy: 58.47457504272461\n",
      "Epoch: 409, Loss: 1.7362957000732422, Accuracy: 63.129974365234375, Test Loss: 1.6370123624801636, Test Accuracy: 58.47457504272461\n",
      "Epoch: 410, Loss: 1.7310986518859863, Accuracy: 63.129974365234375, Test Loss: 1.6312483549118042, Test Accuracy: 58.47457504272461\n",
      "Epoch: 411, Loss: 1.72599458694458, Accuracy: 63.129974365234375, Test Loss: 1.6255520582199097, Test Accuracy: 58.47457504272461\n",
      "Epoch: 412, Loss: 1.7209848165512085, Accuracy: 63.129974365234375, Test Loss: 1.6200450658798218, Test Accuracy: 58.47457504272461\n",
      "Epoch: 413, Loss: 1.7160645723342896, Accuracy: 63.129974365234375, Test Loss: 1.614493489265442, Test Accuracy: 58.47457504272461\n",
      "Epoch: 414, Loss: 1.7112452983856201, Accuracy: 63.129974365234375, Test Loss: 1.609136700630188, Test Accuracy: 59.32203674316406\n",
      "Epoch: 415, Loss: 1.7065030336380005, Accuracy: 63.129974365234375, Test Loss: 1.6037920713424683, Test Accuracy: 60.16949462890625\n",
      "Epoch: 416, Loss: 1.701850414276123, Accuracy: 63.129974365234375, Test Loss: 1.5984842777252197, Test Accuracy: 61.01694869995117\n",
      "Epoch: 417, Loss: 1.6972743272781372, Accuracy: 63.129974365234375, Test Loss: 1.593362808227539, Test Accuracy: 61.01694869995117\n",
      "Epoch: 418, Loss: 1.6927711963653564, Accuracy: 63.129974365234375, Test Loss: 1.5881574153900146, Test Accuracy: 61.01694869995117\n",
      "Epoch: 419, Loss: 1.6883392333984375, Accuracy: 62.86471939086914, Test Loss: 1.5831069946289062, Test Accuracy: 61.01694869995117\n",
      "Epoch: 420, Loss: 1.6839958429336548, Accuracy: 63.395225524902344, Test Loss: 1.578117847442627, Test Accuracy: 61.01694869995117\n",
      "Epoch: 421, Loss: 1.6797271966934204, Accuracy: 63.66047668457031, Test Loss: 1.573099970817566, Test Accuracy: 61.01694869995117\n",
      "Epoch: 422, Loss: 1.6754992008209229, Accuracy: 63.66047668457031, Test Loss: 1.5682646036148071, Test Accuracy: 61.01694869995117\n",
      "Epoch: 423, Loss: 1.6713712215423584, Accuracy: 63.92573165893555, Test Loss: 1.5633503198623657, Test Accuracy: 61.01694869995117\n",
      "Epoch: 424, Loss: 1.6672661304473877, Accuracy: 63.92573165893555, Test Loss: 1.5585894584655762, Test Accuracy: 61.01694869995117\n",
      "Epoch: 425, Loss: 1.6632455587387085, Accuracy: 63.92573165893555, Test Loss: 1.5538674592971802, Test Accuracy: 61.01694869995117\n",
      "Epoch: 426, Loss: 1.6592817306518555, Accuracy: 63.92573165893555, Test Loss: 1.5491514205932617, Test Accuracy: 61.01694869995117\n",
      "Epoch: 427, Loss: 1.6553764343261719, Accuracy: 63.92573165893555, Test Loss: 1.5445866584777832, Test Accuracy: 61.01694869995117\n",
      "Epoch: 428, Loss: 1.6515198945999146, Accuracy: 64.19097900390625, Test Loss: 1.5400069952011108, Test Accuracy: 61.86440658569336\n",
      "Epoch: 429, Loss: 1.6477307081222534, Accuracy: 64.19097900390625, Test Loss: 1.5355197191238403, Test Accuracy: 61.86440658569336\n",
      "Epoch: 430, Loss: 1.6439807415008545, Accuracy: 64.19097900390625, Test Loss: 1.5310851335525513, Test Accuracy: 61.86440658569336\n",
      "Epoch: 431, Loss: 1.6402884721755981, Accuracy: 64.45623016357422, Test Loss: 1.5267012119293213, Test Accuracy: 61.86440658569336\n",
      "Epoch: 432, Loss: 1.636642336845398, Accuracy: 64.72148132324219, Test Loss: 1.5223692655563354, Test Accuracy: 62.71186447143555\n",
      "Epoch: 433, Loss: 1.6330393552780151, Accuracy: 64.98673248291016, Test Loss: 1.5181254148483276, Test Accuracy: 62.71186447143555\n",
      "Epoch: 434, Loss: 1.6294986009597778, Accuracy: 64.98673248291016, Test Loss: 1.5138853788375854, Test Accuracy: 62.71186447143555\n",
      "Epoch: 435, Loss: 1.6259765625, Accuracy: 64.98673248291016, Test Loss: 1.509731411933899, Test Accuracy: 62.71186447143555\n",
      "Epoch: 436, Loss: 1.622507929801941, Accuracy: 65.25199127197266, Test Loss: 1.5056134462356567, Test Accuracy: 62.71186447143555\n",
      "Epoch: 437, Loss: 1.619083046913147, Accuracy: 65.25199127197266, Test Loss: 1.5015416145324707, Test Accuracy: 63.559322357177734\n",
      "Epoch: 438, Loss: 1.6157017946243286, Accuracy: 65.7824935913086, Test Loss: 1.4975154399871826, Test Accuracy: 63.559322357177734\n",
      "Epoch: 439, Loss: 1.6123425960540771, Accuracy: 65.7824935913086, Test Loss: 1.4935452938079834, Test Accuracy: 63.559322357177734\n",
      "Epoch: 440, Loss: 1.609041690826416, Accuracy: 65.51724243164062, Test Loss: 1.489571452140808, Test Accuracy: 63.559322357177734\n",
      "Epoch: 441, Loss: 1.6057645082473755, Accuracy: 65.7824935913086, Test Loss: 1.4856709241867065, Test Accuracy: 63.559322357177734\n",
      "Epoch: 442, Loss: 1.6025354862213135, Accuracy: 65.7824935913086, Test Loss: 1.4818114042282104, Test Accuracy: 63.559322357177734\n",
      "Epoch: 443, Loss: 1.5993268489837646, Accuracy: 65.7824935913086, Test Loss: 1.4779691696166992, Test Accuracy: 63.559322357177734\n",
      "Epoch: 444, Loss: 1.596165657043457, Accuracy: 65.7824935913086, Test Loss: 1.474172592163086, Test Accuracy: 63.559322357177734\n",
      "Epoch: 445, Loss: 1.5930274724960327, Accuracy: 65.7824935913086, Test Loss: 1.4704352617263794, Test Accuracy: 63.559322357177734\n",
      "Epoch: 446, Loss: 1.589926838874817, Accuracy: 66.04774475097656, Test Loss: 1.4666835069656372, Test Accuracy: 63.559322357177734\n",
      "Epoch: 447, Loss: 1.5868473052978516, Accuracy: 66.04774475097656, Test Loss: 1.46303129196167, Test Accuracy: 63.559322357177734\n",
      "Epoch: 448, Loss: 1.583813190460205, Accuracy: 66.04774475097656, Test Loss: 1.4593961238861084, Test Accuracy: 63.559322357177734\n",
      "Epoch: 449, Loss: 1.5808056592941284, Accuracy: 66.04774475097656, Test Loss: 1.4557801485061646, Test Accuracy: 63.559322357177734\n",
      "Epoch: 450, Loss: 1.577817440032959, Accuracy: 66.04774475097656, Test Loss: 1.452261209487915, Test Accuracy: 63.559322357177734\n",
      "Epoch: 451, Loss: 1.574855923652649, Accuracy: 66.04774475097656, Test Loss: 1.4487026929855347, Test Accuracy: 63.559322357177734\n",
      "Epoch: 452, Loss: 1.5719338655471802, Accuracy: 65.7824935913086, Test Loss: 1.4452458620071411, Test Accuracy: 63.559322357177734\n",
      "Epoch: 453, Loss: 1.5690317153930664, Accuracy: 65.7824935913086, Test Loss: 1.4418047666549683, Test Accuracy: 63.559322357177734\n",
      "Epoch: 454, Loss: 1.5661612749099731, Accuracy: 65.7824935913086, Test Loss: 1.4383935928344727, Test Accuracy: 63.559322357177734\n",
      "Epoch: 455, Loss: 1.5633082389831543, Accuracy: 65.7824935913086, Test Loss: 1.4350531101226807, Test Accuracy: 63.559322357177734\n",
      "Epoch: 456, Loss: 1.5604881048202515, Accuracy: 66.04774475097656, Test Loss: 1.4317020177841187, Test Accuracy: 63.559322357177734\n",
      "Epoch: 457, Loss: 1.5576939582824707, Accuracy: 66.04774475097656, Test Loss: 1.4284148216247559, Test Accuracy: 63.559322357177734\n",
      "Epoch: 458, Loss: 1.554923415184021, Accuracy: 66.31299591064453, Test Loss: 1.4251389503479004, Test Accuracy: 63.559322357177734\n",
      "Epoch: 459, Loss: 1.5521719455718994, Accuracy: 66.31299591064453, Test Loss: 1.421890139579773, Test Accuracy: 63.559322357177734\n",
      "Epoch: 460, Loss: 1.5494425296783447, Accuracy: 66.31299591064453, Test Loss: 1.4187352657318115, Test Accuracy: 63.559322357177734\n",
      "Epoch: 461, Loss: 1.5467398166656494, Accuracy: 66.31299591064453, Test Loss: 1.4155265092849731, Test Accuracy: 63.559322357177734\n",
      "Epoch: 462, Loss: 1.544037938117981, Accuracy: 66.57825469970703, Test Loss: 1.412418007850647, Test Accuracy: 63.559322357177734\n",
      "Epoch: 463, Loss: 1.5413836240768433, Accuracy: 66.57825469970703, Test Loss: 1.4093130826950073, Test Accuracy: 63.559322357177734\n",
      "Epoch: 464, Loss: 1.5387505292892456, Accuracy: 66.57825469970703, Test Loss: 1.4062174558639526, Test Accuracy: 63.559322357177734\n",
      "Epoch: 465, Loss: 1.5361188650131226, Accuracy: 66.57825469970703, Test Loss: 1.4031964540481567, Test Accuracy: 63.559322357177734\n",
      "Epoch: 466, Loss: 1.5335170030593872, Accuracy: 66.57825469970703, Test Loss: 1.4001423120498657, Test Accuracy: 63.559322357177734\n",
      "Epoch: 467, Loss: 1.5309412479400635, Accuracy: 66.57825469970703, Test Loss: 1.3971725702285767, Test Accuracy: 63.559322357177734\n",
      "Epoch: 468, Loss: 1.5283762216567993, Accuracy: 66.57825469970703, Test Loss: 1.3942158222198486, Test Accuracy: 63.559322357177734\n",
      "Epoch: 469, Loss: 1.5258485078811646, Accuracy: 66.57825469970703, Test Loss: 1.391249656677246, Test Accuracy: 63.559322357177734\n",
      "Epoch: 470, Loss: 1.5233181715011597, Accuracy: 66.57825469970703, Test Loss: 1.3883776664733887, Test Accuracy: 63.559322357177734\n",
      "Epoch: 471, Loss: 1.5208044052124023, Accuracy: 66.57825469970703, Test Loss: 1.3854587078094482, Test Accuracy: 63.559322357177734\n",
      "Epoch: 472, Loss: 1.5183310508728027, Accuracy: 66.57825469970703, Test Loss: 1.3826262950897217, Test Accuracy: 63.559322357177734\n",
      "Epoch: 473, Loss: 1.51585054397583, Accuracy: 66.57825469970703, Test Loss: 1.3797730207443237, Test Accuracy: 63.559322357177734\n",
      "Epoch: 474, Loss: 1.513393759727478, Accuracy: 66.57825469970703, Test Loss: 1.3769716024398804, Test Accuracy: 63.559322357177734\n",
      "Epoch: 475, Loss: 1.510972261428833, Accuracy: 66.84349822998047, Test Loss: 1.3741899728775024, Test Accuracy: 63.559322357177734\n",
      "Epoch: 476, Loss: 1.508547067642212, Accuracy: 66.84349822998047, Test Loss: 1.3713903427124023, Test Accuracy: 63.559322357177734\n",
      "Epoch: 477, Loss: 1.5061382055282593, Accuracy: 66.84349822998047, Test Loss: 1.3686970472335815, Test Accuracy: 63.559322357177734\n",
      "Epoch: 478, Loss: 1.5037598609924316, Accuracy: 66.57825469970703, Test Loss: 1.3659610748291016, Test Accuracy: 63.559322357177734\n",
      "Epoch: 479, Loss: 1.5013803243637085, Accuracy: 66.84349822998047, Test Loss: 1.3632603883743286, Test Accuracy: 63.559322357177734\n",
      "Epoch: 480, Loss: 1.4990293979644775, Accuracy: 66.84349822998047, Test Loss: 1.360608458518982, Test Accuracy: 63.559322357177734\n",
      "Epoch: 481, Loss: 1.4966977834701538, Accuracy: 66.84349822998047, Test Loss: 1.3579508066177368, Test Accuracy: 63.559322357177734\n",
      "Epoch: 482, Loss: 1.4943803548812866, Accuracy: 66.84349822998047, Test Loss: 1.3553082942962646, Test Accuracy: 63.559322357177734\n",
      "Epoch: 483, Loss: 1.4920636415481567, Accuracy: 66.84349822998047, Test Loss: 1.3527203798294067, Test Accuracy: 63.559322357177734\n",
      "Epoch: 484, Loss: 1.4897687435150146, Accuracy: 66.84349822998047, Test Loss: 1.3501098155975342, Test Accuracy: 63.559322357177734\n",
      "Epoch: 485, Loss: 1.487491488456726, Accuracy: 66.84349822998047, Test Loss: 1.347548007965088, Test Accuracy: 63.559322357177734\n",
      "Epoch: 486, Loss: 1.4852235317230225, Accuracy: 66.84349822998047, Test Loss: 1.3449995517730713, Test Accuracy: 63.559322357177734\n",
      "Epoch: 487, Loss: 1.4829683303833008, Accuracy: 67.10874938964844, Test Loss: 1.3424482345581055, Test Accuracy: 63.559322357177734\n",
      "Epoch: 488, Loss: 1.480738639831543, Accuracy: 67.10874938964844, Test Loss: 1.339945673942566, Test Accuracy: 63.559322357177734\n",
      "Epoch: 489, Loss: 1.4785125255584717, Accuracy: 67.10874938964844, Test Loss: 1.3374587297439575, Test Accuracy: 63.559322357177734\n",
      "Epoch: 490, Loss: 1.4763017892837524, Accuracy: 67.10874938964844, Test Loss: 1.3349636793136597, Test Accuracy: 63.559322357177734\n",
      "Epoch: 491, Loss: 1.4741159677505493, Accuracy: 67.10874938964844, Test Loss: 1.3325234651565552, Test Accuracy: 63.559322357177734\n",
      "Epoch: 492, Loss: 1.4719197750091553, Accuracy: 67.10874938964844, Test Loss: 1.3300672769546509, Test Accuracy: 63.559322357177734\n",
      "Epoch: 493, Loss: 1.4697587490081787, Accuracy: 67.10874938964844, Test Loss: 1.3276342153549194, Test Accuracy: 63.559322357177734\n",
      "Epoch: 494, Loss: 1.467603325843811, Accuracy: 67.10874938964844, Test Loss: 1.3252537250518799, Test Accuracy: 63.559322357177734\n",
      "Epoch: 495, Loss: 1.4654521942138672, Accuracy: 67.10874938964844, Test Loss: 1.3228318691253662, Test Accuracy: 63.559322357177734\n",
      "Epoch: 496, Loss: 1.4633265733718872, Accuracy: 67.10874938964844, Test Loss: 1.3204634189605713, Test Accuracy: 63.559322357177734\n",
      "Epoch: 497, Loss: 1.461199402809143, Accuracy: 67.10874938964844, Test Loss: 1.318115472793579, Test Accuracy: 63.559322357177734\n",
      "Epoch: 498, Loss: 1.4590915441513062, Accuracy: 67.10874938964844, Test Loss: 1.315732717514038, Test Accuracy: 63.559322357177734\n",
      "Epoch: 499, Loss: 1.456999659538269, Accuracy: 67.10874938964844, Test Loss: 1.31345534324646, Test Accuracy: 63.559322357177734\n",
      "Epoch: 500, Loss: 1.454918622970581, Accuracy: 67.10874938964844, Test Loss: 1.311126947402954, Test Accuracy: 63.559322357177734\n",
      "Epoch: 501, Loss: 1.4528549909591675, Accuracy: 67.3740005493164, Test Loss: 1.3088319301605225, Test Accuracy: 63.559322357177734\n",
      "Epoch: 502, Loss: 1.4507901668548584, Accuracy: 67.3740005493164, Test Loss: 1.306579351425171, Test Accuracy: 63.559322357177734\n",
      "Epoch: 503, Loss: 1.4487398862838745, Accuracy: 67.3740005493164, Test Loss: 1.3042891025543213, Test Accuracy: 63.559322357177734\n",
      "Epoch: 504, Loss: 1.446703314781189, Accuracy: 67.3740005493164, Test Loss: 1.3020429611206055, Test Accuracy: 63.559322357177734\n",
      "Epoch: 505, Loss: 1.4446825981140137, Accuracy: 67.3740005493164, Test Loss: 1.2998591661453247, Test Accuracy: 63.559322357177734\n",
      "Epoch: 506, Loss: 1.4426631927490234, Accuracy: 67.3740005493164, Test Loss: 1.2975754737854004, Test Accuracy: 63.559322357177734\n",
      "Epoch: 507, Loss: 1.440658450126648, Accuracy: 67.3740005493164, Test Loss: 1.2953991889953613, Test Accuracy: 63.559322357177734\n",
      "Epoch: 508, Loss: 1.438672661781311, Accuracy: 67.3740005493164, Test Loss: 1.2932202816009521, Test Accuracy: 63.559322357177734\n",
      "Epoch: 509, Loss: 1.4366880655288696, Accuracy: 67.3740005493164, Test Loss: 1.2910325527191162, Test Accuracy: 63.559322357177734\n",
      "Epoch: 510, Loss: 1.434712290763855, Accuracy: 67.3740005493164, Test Loss: 1.288880467414856, Test Accuracy: 63.559322357177734\n",
      "Epoch: 511, Loss: 1.4327541589736938, Accuracy: 67.3740005493164, Test Loss: 1.2867708206176758, Test Accuracy: 63.559322357177734\n",
      "Epoch: 512, Loss: 1.4308117628097534, Accuracy: 67.3740005493164, Test Loss: 1.2845942974090576, Test Accuracy: 63.559322357177734\n",
      "Epoch: 513, Loss: 1.4288699626922607, Accuracy: 67.3740005493164, Test Loss: 1.2824859619140625, Test Accuracy: 63.559322357177734\n",
      "Epoch: 514, Loss: 1.4269355535507202, Accuracy: 67.3740005493164, Test Loss: 1.2803974151611328, Test Accuracy: 63.559322357177734\n",
      "Epoch: 515, Loss: 1.4250198602676392, Accuracy: 67.3740005493164, Test Loss: 1.2782883644104004, Test Accuracy: 63.559322357177734\n",
      "Epoch: 516, Loss: 1.4231094121932983, Accuracy: 67.3740005493164, Test Loss: 1.2762268781661987, Test Accuracy: 63.559322357177734\n",
      "Epoch: 517, Loss: 1.4212064743041992, Accuracy: 67.3740005493164, Test Loss: 1.2741550207138062, Test Accuracy: 63.559322357177734\n",
      "Epoch: 518, Loss: 1.4193238019943237, Accuracy: 67.3740005493164, Test Loss: 1.272114872932434, Test Accuracy: 63.559322357177734\n",
      "Epoch: 519, Loss: 1.4174433946609497, Accuracy: 67.3740005493164, Test Loss: 1.2700806856155396, Test Accuracy: 63.559322357177734\n",
      "Epoch: 520, Loss: 1.4155685901641846, Accuracy: 67.3740005493164, Test Loss: 1.2680370807647705, Test Accuracy: 63.559322357177734\n",
      "Epoch: 521, Loss: 1.4137098789215088, Accuracy: 67.3740005493164, Test Loss: 1.2660554647445679, Test Accuracy: 63.559322357177734\n",
      "Epoch: 522, Loss: 1.411848545074463, Accuracy: 67.3740005493164, Test Loss: 1.2640376091003418, Test Accuracy: 63.559322357177734\n",
      "Epoch: 523, Loss: 1.410020112991333, Accuracy: 67.10874938964844, Test Loss: 1.2620326280593872, Test Accuracy: 63.559322357177734\n",
      "Epoch: 524, Loss: 1.4081801176071167, Accuracy: 67.10874938964844, Test Loss: 1.2600972652435303, Test Accuracy: 63.559322357177734\n",
      "Epoch: 525, Loss: 1.4063597917556763, Accuracy: 67.10874938964844, Test Loss: 1.258118748664856, Test Accuracy: 63.559322357177734\n",
      "Epoch: 526, Loss: 1.4045504331588745, Accuracy: 67.10874938964844, Test Loss: 1.256173014640808, Test Accuracy: 63.559322357177734\n",
      "Epoch: 527, Loss: 1.4027453660964966, Accuracy: 67.10874938964844, Test Loss: 1.2542545795440674, Test Accuracy: 63.559322357177734\n",
      "Epoch: 528, Loss: 1.4009400606155396, Accuracy: 67.10874938964844, Test Loss: 1.2522975206375122, Test Accuracy: 63.559322357177734\n",
      "Epoch: 529, Loss: 1.3991519212722778, Accuracy: 67.10874938964844, Test Loss: 1.2504148483276367, Test Accuracy: 63.559322357177734\n",
      "Epoch: 530, Loss: 1.397373080253601, Accuracy: 67.10874938964844, Test Loss: 1.2485078573226929, Test Accuracy: 63.559322357177734\n",
      "Epoch: 531, Loss: 1.3956027030944824, Accuracy: 67.10874938964844, Test Loss: 1.2465883493423462, Test Accuracy: 63.559322357177734\n",
      "Epoch: 532, Loss: 1.3938453197479248, Accuracy: 67.10874938964844, Test Loss: 1.244747519493103, Test Accuracy: 63.559322357177734\n",
      "Epoch: 533, Loss: 1.3920921087265015, Accuracy: 67.10874938964844, Test Loss: 1.242873191833496, Test Accuracy: 63.559322357177734\n",
      "Epoch: 534, Loss: 1.3903470039367676, Accuracy: 67.10874938964844, Test Loss: 1.2410073280334473, Test Accuracy: 63.559322357177734\n",
      "Epoch: 535, Loss: 1.3886104822158813, Accuracy: 67.10874938964844, Test Loss: 1.2391867637634277, Test Accuracy: 63.559322357177734\n",
      "Epoch: 536, Loss: 1.3868752717971802, Accuracy: 67.10874938964844, Test Loss: 1.2373255491256714, Test Accuracy: 63.559322357177734\n",
      "Epoch: 537, Loss: 1.3851553201675415, Accuracy: 67.3740005493164, Test Loss: 1.2355097532272339, Test Accuracy: 63.559322357177734\n",
      "Epoch: 538, Loss: 1.3834409713745117, Accuracy: 67.3740005493164, Test Loss: 1.2337052822113037, Test Accuracy: 63.559322357177734\n",
      "Epoch: 539, Loss: 1.3817366361618042, Accuracy: 67.3740005493164, Test Loss: 1.2319226264953613, Test Accuracy: 63.559322357177734\n",
      "Epoch: 540, Loss: 1.3800524473190308, Accuracy: 67.3740005493164, Test Loss: 1.2300957441329956, Test Accuracy: 63.559322357177734\n",
      "Epoch: 541, Loss: 1.3783620595932007, Accuracy: 67.63925170898438, Test Loss: 1.2283374071121216, Test Accuracy: 63.559322357177734\n",
      "Epoch: 542, Loss: 1.3766735792160034, Accuracy: 67.63925170898438, Test Loss: 1.2265700101852417, Test Accuracy: 63.559322357177734\n",
      "Epoch: 543, Loss: 1.3750032186508179, Accuracy: 67.63925170898438, Test Loss: 1.2247916460037231, Test Accuracy: 62.71186447143555\n",
      "Epoch: 544, Loss: 1.373335838317871, Accuracy: 67.63925170898438, Test Loss: 1.2230621576309204, Test Accuracy: 62.71186447143555\n",
      "Epoch: 545, Loss: 1.3716869354248047, Accuracy: 67.63925170898438, Test Loss: 1.2213131189346313, Test Accuracy: 61.86440658569336\n",
      "Epoch: 546, Loss: 1.3700281381607056, Accuracy: 67.63925170898438, Test Loss: 1.2196018695831299, Test Accuracy: 61.86440658569336\n",
      "Epoch: 547, Loss: 1.368396282196045, Accuracy: 67.63925170898438, Test Loss: 1.2178722620010376, Test Accuracy: 63.559322357177734\n",
      "Epoch: 548, Loss: 1.3667633533477783, Accuracy: 67.63925170898438, Test Loss: 1.2161794900894165, Test Accuracy: 64.40678405761719\n",
      "Epoch: 549, Loss: 1.3651204109191895, Accuracy: 67.63925170898438, Test Loss: 1.21449613571167, Test Accuracy: 64.40678405761719\n",
      "Epoch: 550, Loss: 1.3635032176971436, Accuracy: 67.63925170898438, Test Loss: 1.2127985954284668, Test Accuracy: 64.40678405761719\n",
      "Epoch: 551, Loss: 1.3618876934051514, Accuracy: 67.63925170898438, Test Loss: 1.2111406326293945, Test Accuracy: 64.40678405761719\n",
      "Epoch: 552, Loss: 1.3602888584136963, Accuracy: 67.63925170898438, Test Loss: 1.2094602584838867, Test Accuracy: 64.40678405761719\n",
      "Epoch: 553, Loss: 1.3586835861206055, Accuracy: 67.63925170898438, Test Loss: 1.2077889442443848, Test Accuracy: 64.40678405761719\n",
      "Epoch: 554, Loss: 1.3570939302444458, Accuracy: 67.63925170898438, Test Loss: 1.206176996231079, Test Accuracy: 64.40678405761719\n",
      "Epoch: 555, Loss: 1.355514645576477, Accuracy: 67.90451049804688, Test Loss: 1.2045010328292847, Test Accuracy: 64.40678405761719\n",
      "Epoch: 556, Loss: 1.353934407234192, Accuracy: 67.90451049804688, Test Loss: 1.2028809785842896, Test Accuracy: 64.40678405761719\n",
      "Epoch: 557, Loss: 1.3523608446121216, Accuracy: 68.16976165771484, Test Loss: 1.2012956142425537, Test Accuracy: 64.40678405761719\n",
      "Epoch: 558, Loss: 1.3508082628250122, Accuracy: 68.16976165771484, Test Loss: 1.1996219158172607, Test Accuracy: 64.40678405761719\n",
      "Epoch: 559, Loss: 1.3492568731307983, Accuracy: 68.43501281738281, Test Loss: 1.198044776916504, Test Accuracy: 64.40678405761719\n",
      "Epoch: 560, Loss: 1.3476972579956055, Accuracy: 68.43501281738281, Test Loss: 1.1964746713638306, Test Accuracy: 64.40678405761719\n",
      "Epoch: 561, Loss: 1.3461554050445557, Accuracy: 68.43501281738281, Test Loss: 1.1948487758636475, Test Accuracy: 64.40678405761719\n",
      "Epoch: 562, Loss: 1.3446162939071655, Accuracy: 68.43501281738281, Test Loss: 1.1932958364486694, Test Accuracy: 64.40678405761719\n",
      "Epoch: 563, Loss: 1.3430863618850708, Accuracy: 68.70026397705078, Test Loss: 1.1917189359664917, Test Accuracy: 64.40678405761719\n",
      "Epoch: 564, Loss: 1.3415642976760864, Accuracy: 68.70026397705078, Test Loss: 1.1901618242263794, Test Accuracy: 64.40678405761719\n",
      "Epoch: 565, Loss: 1.3400462865829468, Accuracy: 68.70026397705078, Test Loss: 1.1886190176010132, Test Accuracy: 64.40678405761719\n",
      "Epoch: 566, Loss: 1.3385419845581055, Accuracy: 68.70026397705078, Test Loss: 1.1870503425598145, Test Accuracy: 64.40678405761719\n",
      "Epoch: 567, Loss: 1.3370388746261597, Accuracy: 68.70026397705078, Test Loss: 1.185552716255188, Test Accuracy: 64.40678405761719\n",
      "Epoch: 568, Loss: 1.3355348110198975, Accuracy: 68.70026397705078, Test Loss: 1.1840134859085083, Test Accuracy: 64.40678405761719\n",
      "Epoch: 569, Loss: 1.334047794342041, Accuracy: 68.70026397705078, Test Loss: 1.1824957132339478, Test Accuracy: 64.40678405761719\n",
      "Epoch: 570, Loss: 1.3325601816177368, Accuracy: 68.70026397705078, Test Loss: 1.1809800863265991, Test Accuracy: 65.25423431396484\n",
      "Epoch: 571, Loss: 1.3310812711715698, Accuracy: 68.70026397705078, Test Loss: 1.179513931274414, Test Accuracy: 65.25423431396484\n",
      "Epoch: 572, Loss: 1.329607367515564, Accuracy: 68.70026397705078, Test Loss: 1.177986979484558, Test Accuracy: 65.25423431396484\n",
      "Epoch: 573, Loss: 1.328138828277588, Accuracy: 68.70026397705078, Test Loss: 1.1765413284301758, Test Accuracy: 66.10169219970703\n",
      "Epoch: 574, Loss: 1.3266819715499878, Accuracy: 68.70026397705078, Test Loss: 1.175032377243042, Test Accuracy: 66.10169219970703\n",
      "Epoch: 575, Loss: 1.3252273797988892, Accuracy: 68.70026397705078, Test Loss: 1.1735795736312866, Test Accuracy: 66.10169219970703\n",
      "Epoch: 576, Loss: 1.3237860202789307, Accuracy: 68.70026397705078, Test Loss: 1.172117829322815, Test Accuracy: 66.10169219970703\n",
      "Epoch: 577, Loss: 1.32234787940979, Accuracy: 68.70026397705078, Test Loss: 1.1706589460372925, Test Accuracy: 66.10169219970703\n",
      "Epoch: 578, Loss: 1.3209108114242554, Accuracy: 68.70026397705078, Test Loss: 1.169219732284546, Test Accuracy: 66.10169219970703\n",
      "Epoch: 579, Loss: 1.319475769996643, Accuracy: 68.70026397705078, Test Loss: 1.167765498161316, Test Accuracy: 66.10169219970703\n",
      "Epoch: 580, Loss: 1.3180593252182007, Accuracy: 68.70026397705078, Test Loss: 1.1663745641708374, Test Accuracy: 66.10169219970703\n",
      "Epoch: 581, Loss: 1.3166329860687256, Accuracy: 68.70026397705078, Test Loss: 1.164925217628479, Test Accuracy: 66.10169219970703\n",
      "Epoch: 582, Loss: 1.3152201175689697, Accuracy: 68.70026397705078, Test Loss: 1.1635323762893677, Test Accuracy: 66.10169219970703\n",
      "Epoch: 583, Loss: 1.313821792602539, Accuracy: 68.70026397705078, Test Loss: 1.1621201038360596, Test Accuracy: 66.10169219970703\n",
      "Epoch: 584, Loss: 1.312423825263977, Accuracy: 68.70026397705078, Test Loss: 1.160689115524292, Test Accuracy: 66.10169219970703\n",
      "Epoch: 585, Loss: 1.3110241889953613, Accuracy: 68.70026397705078, Test Loss: 1.1593470573425293, Test Accuracy: 66.10169219970703\n",
      "Epoch: 586, Loss: 1.309638500213623, Accuracy: 68.96551513671875, Test Loss: 1.1579426527023315, Test Accuracy: 66.10169219970703\n",
      "Epoch: 587, Loss: 1.3082513809204102, Accuracy: 68.96551513671875, Test Loss: 1.1565680503845215, Test Accuracy: 66.10169219970703\n",
      "Epoch: 588, Loss: 1.306877613067627, Accuracy: 68.96551513671875, Test Loss: 1.1552187204360962, Test Accuracy: 66.10169219970703\n",
      "Epoch: 589, Loss: 1.305503487586975, Accuracy: 68.96551513671875, Test Loss: 1.1538197994232178, Test Accuracy: 66.10169219970703\n",
      "Epoch: 590, Loss: 1.3041422367095947, Accuracy: 68.96551513671875, Test Loss: 1.1524862051010132, Test Accuracy: 66.10169219970703\n",
      "Epoch: 591, Loss: 1.3027849197387695, Accuracy: 68.96551513671875, Test Loss: 1.151165246963501, Test Accuracy: 66.10169219970703\n",
      "Epoch: 592, Loss: 1.3014295101165771, Accuracy: 68.96551513671875, Test Loss: 1.1497557163238525, Test Accuracy: 66.10169219970703\n",
      "Epoch: 593, Loss: 1.3000794649124146, Accuracy: 68.96551513671875, Test Loss: 1.148496389389038, Test Accuracy: 66.10169219970703\n",
      "Epoch: 594, Loss: 1.2987351417541504, Accuracy: 68.96551513671875, Test Loss: 1.1471176147460938, Test Accuracy: 66.10169219970703\n",
      "Epoch: 595, Loss: 1.2973895072937012, Accuracy: 68.96551513671875, Test Loss: 1.1457935571670532, Test Accuracy: 66.10169219970703\n",
      "Epoch: 596, Loss: 1.2960597276687622, Accuracy: 68.70026397705078, Test Loss: 1.1445482969284058, Test Accuracy: 66.10169219970703\n",
      "Epoch: 597, Loss: 1.294734239578247, Accuracy: 68.70026397705078, Test Loss: 1.143157958984375, Test Accuracy: 66.10169219970703\n",
      "Epoch: 598, Loss: 1.293408751487732, Accuracy: 68.96551513671875, Test Loss: 1.1419341564178467, Test Accuracy: 66.10169219970703\n",
      "Epoch: 599, Loss: 1.2920972108840942, Accuracy: 68.96551513671875, Test Loss: 1.1406062841415405, Test Accuracy: 66.10169219970703\n",
      "Epoch: 600, Loss: 1.2907750606536865, Accuracy: 68.96551513671875, Test Loss: 1.1393039226531982, Test Accuracy: 66.10169219970703\n",
      "Epoch: 601, Loss: 1.2894632816314697, Accuracy: 68.96551513671875, Test Loss: 1.1380738019943237, Test Accuracy: 66.10169219970703\n",
      "Epoch: 602, Loss: 1.2881649732589722, Accuracy: 68.96551513671875, Test Loss: 1.1367533206939697, Test Accuracy: 66.10169219970703\n",
      "Epoch: 603, Loss: 1.2868715524673462, Accuracy: 68.70026397705078, Test Loss: 1.1355139017105103, Test Accuracy: 66.10169219970703\n",
      "Epoch: 604, Loss: 1.2855806350708008, Accuracy: 68.70026397705078, Test Loss: 1.1342406272888184, Test Accuracy: 66.10169219970703\n",
      "Epoch: 605, Loss: 1.28428316116333, Accuracy: 68.70026397705078, Test Loss: 1.132978916168213, Test Accuracy: 66.10169219970703\n",
      "Epoch: 606, Loss: 1.2830058336257935, Accuracy: 68.70026397705078, Test Loss: 1.1317769289016724, Test Accuracy: 66.10169219970703\n",
      "Epoch: 607, Loss: 1.2817296981811523, Accuracy: 68.70026397705078, Test Loss: 1.1304963827133179, Test Accuracy: 66.10169219970703\n",
      "Epoch: 608, Loss: 1.2804471254348755, Accuracy: 68.70026397705078, Test Loss: 1.1292741298675537, Test Accuracy: 66.10169219970703\n",
      "Epoch: 609, Loss: 1.279183030128479, Accuracy: 68.70026397705078, Test Loss: 1.1280678510665894, Test Accuracy: 66.10169219970703\n",
      "Epoch: 610, Loss: 1.2779221534729004, Accuracy: 68.70026397705078, Test Loss: 1.12679922580719, Test Accuracy: 66.10169219970703\n",
      "Epoch: 611, Loss: 1.27666437625885, Accuracy: 68.70026397705078, Test Loss: 1.1256557703018188, Test Accuracy: 66.10169219970703\n",
      "Epoch: 612, Loss: 1.275413155555725, Accuracy: 68.70026397705078, Test Loss: 1.1243789196014404, Test Accuracy: 66.10169219970703\n",
      "Epoch: 613, Loss: 1.2741625308990479, Accuracy: 68.70026397705078, Test Loss: 1.1231874227523804, Test Accuracy: 66.10169219970703\n",
      "Epoch: 614, Loss: 1.272910714149475, Accuracy: 68.70026397705078, Test Loss: 1.1220301389694214, Test Accuracy: 66.10169219970703\n",
      "Epoch: 615, Loss: 1.271688461303711, Accuracy: 68.70026397705078, Test Loss: 1.120783805847168, Test Accuracy: 66.10169219970703\n",
      "Epoch: 616, Loss: 1.2704448699951172, Accuracy: 68.70026397705078, Test Loss: 1.119646668434143, Test Accuracy: 66.10169219970703\n",
      "Epoch: 617, Loss: 1.269213080406189, Accuracy: 68.70026397705078, Test Loss: 1.1184678077697754, Test Accuracy: 66.10169219970703\n",
      "Epoch: 618, Loss: 1.2679864168167114, Accuracy: 68.70026397705078, Test Loss: 1.1172289848327637, Test Accuracy: 66.10169219970703\n",
      "Epoch: 619, Loss: 1.2667596340179443, Accuracy: 68.70026397705078, Test Loss: 1.116153359413147, Test Accuracy: 66.10169219970703\n",
      "Epoch: 620, Loss: 1.265551209449768, Accuracy: 68.70026397705078, Test Loss: 1.1149353981018066, Test Accuracy: 66.10169219970703\n",
      "Epoch: 621, Loss: 1.2643386125564575, Accuracy: 68.70026397705078, Test Loss: 1.1137871742248535, Test Accuracy: 66.10169219970703\n",
      "Epoch: 622, Loss: 1.2631338834762573, Accuracy: 68.70026397705078, Test Loss: 1.1126723289489746, Test Accuracy: 66.10169219970703\n",
      "Epoch: 623, Loss: 1.2619256973266602, Accuracy: 68.70026397705078, Test Loss: 1.1114802360534668, Test Accuracy: 66.10169219970703\n",
      "Epoch: 624, Loss: 1.2607321739196777, Accuracy: 68.70026397705078, Test Loss: 1.110387921333313, Test Accuracy: 66.10169219970703\n",
      "Epoch: 625, Loss: 1.2595382928848267, Accuracy: 68.70026397705078, Test Loss: 1.1092382669448853, Test Accuracy: 66.10169219970703\n",
      "Epoch: 626, Loss: 1.258345365524292, Accuracy: 68.96551513671875, Test Loss: 1.1081039905548096, Test Accuracy: 66.10169219970703\n",
      "Epoch: 627, Loss: 1.2571659088134766, Accuracy: 68.96551513671875, Test Loss: 1.1070280075073242, Test Accuracy: 66.10169219970703\n",
      "Epoch: 628, Loss: 1.2559916973114014, Accuracy: 68.96551513671875, Test Loss: 1.1058619022369385, Test Accuracy: 66.10169219970703\n",
      "Epoch: 629, Loss: 1.2548097372055054, Accuracy: 69.23076629638672, Test Loss: 1.1047779321670532, Test Accuracy: 66.10169219970703\n",
      "Epoch: 630, Loss: 1.2536381483078003, Accuracy: 69.23076629638672, Test Loss: 1.1036815643310547, Test Accuracy: 66.10169219970703\n",
      "Epoch: 631, Loss: 1.2524784803390503, Accuracy: 69.23076629638672, Test Loss: 1.102547526359558, Test Accuracy: 66.10169219970703\n",
      "Epoch: 632, Loss: 1.2513127326965332, Accuracy: 69.23076629638672, Test Loss: 1.1015026569366455, Test Accuracy: 66.10169219970703\n",
      "Epoch: 633, Loss: 1.2501542568206787, Accuracy: 69.23076629638672, Test Loss: 1.1003825664520264, Test Accuracy: 66.10169219970703\n",
      "Epoch: 634, Loss: 1.2490016222000122, Accuracy: 69.49601745605469, Test Loss: 1.099286437034607, Test Accuracy: 66.10169219970703\n",
      "Epoch: 635, Loss: 1.2478399276733398, Accuracy: 69.49601745605469, Test Loss: 1.0982425212860107, Test Accuracy: 66.10169219970703\n",
      "Epoch: 636, Loss: 1.2466996908187866, Accuracy: 69.49601745605469, Test Loss: 1.0971415042877197, Test Accuracy: 66.10169219970703\n",
      "Epoch: 637, Loss: 1.2455586194992065, Accuracy: 69.49601745605469, Test Loss: 1.0960968732833862, Test Accuracy: 66.10169219970703\n",
      "Epoch: 638, Loss: 1.2444121837615967, Accuracy: 69.49601745605469, Test Loss: 1.0950291156768799, Test Accuracy: 66.10169219970703\n",
      "Epoch: 639, Loss: 1.2432849407196045, Accuracy: 69.49601745605469, Test Loss: 1.0939786434173584, Test Accuracy: 66.10169219970703\n",
      "Epoch: 640, Loss: 1.2421495914459229, Accuracy: 69.49601745605469, Test Loss: 1.0929279327392578, Test Accuracy: 66.10169219970703\n",
      "Epoch: 641, Loss: 1.2410283088684082, Accuracy: 69.49601745605469, Test Loss: 1.0918848514556885, Test Accuracy: 66.10169219970703\n",
      "Epoch: 642, Loss: 1.2399026155471802, Accuracy: 69.76126861572266, Test Loss: 1.0908443927764893, Test Accuracy: 66.10169219970703\n",
      "Epoch: 643, Loss: 1.2387803792953491, Accuracy: 69.76126861572266, Test Loss: 1.0898206233978271, Test Accuracy: 66.10169219970703\n",
      "Epoch: 644, Loss: 1.2376644611358643, Accuracy: 69.76126861572266, Test Loss: 1.0887984037399292, Test Accuracy: 66.10169219970703\n",
      "Epoch: 645, Loss: 1.2365514039993286, Accuracy: 69.76126861572266, Test Loss: 1.0877407789230347, Test Accuracy: 66.10169219970703\n",
      "Epoch: 646, Loss: 1.2354546785354614, Accuracy: 70.02651977539062, Test Loss: 1.0867563486099243, Test Accuracy: 66.10169219970703\n",
      "Epoch: 647, Loss: 1.2343438863754272, Accuracy: 70.02651977539062, Test Loss: 1.0857176780700684, Test Accuracy: 66.10169219970703\n",
      "Epoch: 648, Loss: 1.2332466840744019, Accuracy: 70.02651977539062, Test Loss: 1.0847256183624268, Test Accuracy: 66.10169219970703\n",
      "Epoch: 649, Loss: 1.2321451902389526, Accuracy: 70.02651977539062, Test Loss: 1.083711862564087, Test Accuracy: 66.10169219970703\n",
      "Epoch: 650, Loss: 1.231056809425354, Accuracy: 70.02651977539062, Test Loss: 1.0827229022979736, Test Accuracy: 66.10169219970703\n",
      "Epoch: 651, Loss: 1.229958415031433, Accuracy: 70.29177856445312, Test Loss: 1.081724762916565, Test Accuracy: 66.10169219970703\n",
      "Epoch: 652, Loss: 1.228888988494873, Accuracy: 70.29177856445312, Test Loss: 1.0807493925094604, Test Accuracy: 66.10169219970703\n",
      "Epoch: 653, Loss: 1.22780179977417, Accuracy: 70.29177856445312, Test Loss: 1.0797312259674072, Test Accuracy: 66.10169219970703\n",
      "Epoch: 654, Loss: 1.2267225980758667, Accuracy: 70.29177856445312, Test Loss: 1.078786015510559, Test Accuracy: 66.10169219970703\n",
      "Epoch: 655, Loss: 1.2256484031677246, Accuracy: 70.29177856445312, Test Loss: 1.0777744054794312, Test Accuracy: 66.10169219970703\n",
      "Epoch: 656, Loss: 1.2245792150497437, Accuracy: 70.29177856445312, Test Loss: 1.0768307447433472, Test Accuracy: 66.10169219970703\n",
      "Epoch: 657, Loss: 1.2235102653503418, Accuracy: 70.29177856445312, Test Loss: 1.075855016708374, Test Accuracy: 66.10169219970703\n",
      "Epoch: 658, Loss: 1.2224483489990234, Accuracy: 70.29177856445312, Test Loss: 1.074894666671753, Test Accuracy: 66.10169219970703\n",
      "Epoch: 659, Loss: 1.221390962600708, Accuracy: 70.29177856445312, Test Loss: 1.073952078819275, Test Accuracy: 66.10169219970703\n",
      "Epoch: 660, Loss: 1.2203341722488403, Accuracy: 70.5570297241211, Test Loss: 1.072982668876648, Test Accuracy: 66.10169219970703\n",
      "Epoch: 661, Loss: 1.2192838191986084, Accuracy: 70.5570297241211, Test Loss: 1.0720536708831787, Test Accuracy: 66.10169219970703\n",
      "Epoch: 662, Loss: 1.218239665031433, Accuracy: 70.5570297241211, Test Loss: 1.0710947513580322, Test Accuracy: 66.10169219970703\n",
      "Epoch: 663, Loss: 1.2171931266784668, Accuracy: 70.5570297241211, Test Loss: 1.070175290107727, Test Accuracy: 66.10169219970703\n",
      "Epoch: 664, Loss: 1.2161502838134766, Accuracy: 70.5570297241211, Test Loss: 1.069238305091858, Test Accuracy: 66.10169219970703\n",
      "Epoch: 665, Loss: 1.2150992155075073, Accuracy: 70.5570297241211, Test Loss: 1.0683021545410156, Test Accuracy: 66.10169219970703\n",
      "Epoch: 666, Loss: 1.214078664779663, Accuracy: 70.5570297241211, Test Loss: 1.067404866218567, Test Accuracy: 66.10169219970703\n",
      "Epoch: 667, Loss: 1.2130417823791504, Accuracy: 70.5570297241211, Test Loss: 1.0664503574371338, Test Accuracy: 66.10169219970703\n",
      "Epoch: 668, Loss: 1.2120168209075928, Accuracy: 70.5570297241211, Test Loss: 1.0655566453933716, Test Accuracy: 66.10169219970703\n",
      "Epoch: 669, Loss: 1.210985541343689, Accuracy: 70.5570297241211, Test Loss: 1.0646549463272095, Test Accuracy: 66.10169219970703\n",
      "Epoch: 670, Loss: 1.2099645137786865, Accuracy: 70.5570297241211, Test Loss: 1.0637128353118896, Test Accuracy: 66.10169219970703\n",
      "Epoch: 671, Loss: 1.208946943283081, Accuracy: 70.5570297241211, Test Loss: 1.0628626346588135, Test Accuracy: 66.10169219970703\n",
      "Epoch: 672, Loss: 1.2079319953918457, Accuracy: 70.5570297241211, Test Loss: 1.061932921409607, Test Accuracy: 66.10169219970703\n",
      "Epoch: 673, Loss: 1.2069201469421387, Accuracy: 70.82228088378906, Test Loss: 1.061057209968567, Test Accuracy: 66.10169219970703\n",
      "Epoch: 674, Loss: 1.2059130668640137, Accuracy: 70.82228088378906, Test Loss: 1.0601451396942139, Test Accuracy: 66.10169219970703\n",
      "Epoch: 675, Loss: 1.2049137353897095, Accuracy: 70.5570297241211, Test Loss: 1.0592951774597168, Test Accuracy: 66.10169219970703\n",
      "Epoch: 676, Loss: 1.2039107084274292, Accuracy: 70.5570297241211, Test Loss: 1.0583806037902832, Test Accuracy: 66.10169219970703\n",
      "Epoch: 677, Loss: 1.2029072046279907, Accuracy: 70.82228088378906, Test Loss: 1.057529091835022, Test Accuracy: 66.10169219970703\n",
      "Epoch: 678, Loss: 1.2019118070602417, Accuracy: 70.82228088378906, Test Loss: 1.0566481351852417, Test Accuracy: 66.10169219970703\n",
      "Epoch: 679, Loss: 1.2009116411209106, Accuracy: 70.82228088378906, Test Loss: 1.0557798147201538, Test Accuracy: 66.10169219970703\n",
      "Epoch: 680, Loss: 1.1999293565750122, Accuracy: 70.82228088378906, Test Loss: 1.0549160242080688, Test Accuracy: 66.10169219970703\n",
      "Epoch: 681, Loss: 1.1989387273788452, Accuracy: 70.82228088378906, Test Loss: 1.0540441274642944, Test Accuracy: 66.10169219970703\n",
      "Epoch: 682, Loss: 1.1979478597640991, Accuracy: 71.08753204345703, Test Loss: 1.0531861782073975, Test Accuracy: 66.10169219970703\n",
      "Epoch: 683, Loss: 1.1969743967056274, Accuracy: 71.08753204345703, Test Loss: 1.0523457527160645, Test Accuracy: 66.10169219970703\n",
      "Epoch: 684, Loss: 1.195988655090332, Accuracy: 71.08753204345703, Test Loss: 1.0514779090881348, Test Accuracy: 66.10169219970703\n",
      "Epoch: 685, Loss: 1.1950205564498901, Accuracy: 71.352783203125, Test Loss: 1.0506534576416016, Test Accuracy: 66.10169219970703\n",
      "Epoch: 686, Loss: 1.1940512657165527, Accuracy: 71.352783203125, Test Loss: 1.0498204231262207, Test Accuracy: 66.10169219970703\n",
      "Epoch: 687, Loss: 1.1930794715881348, Accuracy: 71.352783203125, Test Loss: 1.0489400625228882, Test Accuracy: 66.10169219970703\n",
      "Epoch: 688, Loss: 1.1921106576919556, Accuracy: 71.352783203125, Test Loss: 1.0481919050216675, Test Accuracy: 66.10169219970703\n",
      "Epoch: 689, Loss: 1.1911511421203613, Accuracy: 71.352783203125, Test Loss: 1.047270655632019, Test Accuracy: 66.10169219970703\n",
      "Epoch: 690, Loss: 1.190185308456421, Accuracy: 71.352783203125, Test Loss: 1.046506643295288, Test Accuracy: 66.10169219970703\n",
      "Epoch: 691, Loss: 1.1892304420471191, Accuracy: 71.352783203125, Test Loss: 1.0456888675689697, Test Accuracy: 66.10169219970703\n",
      "Epoch: 692, Loss: 1.188280463218689, Accuracy: 71.352783203125, Test Loss: 1.044820785522461, Test Accuracy: 66.94915008544922\n",
      "Epoch: 693, Loss: 1.187319278717041, Accuracy: 71.352783203125, Test Loss: 1.0440701246261597, Test Accuracy: 66.94915008544922\n",
      "Epoch: 694, Loss: 1.186376929283142, Accuracy: 71.352783203125, Test Loss: 1.0432002544403076, Test Accuracy: 66.94915008544922\n",
      "Epoch: 695, Loss: 1.1854203939437866, Accuracy: 71.352783203125, Test Loss: 1.042450189590454, Test Accuracy: 66.94915008544922\n",
      "Epoch: 696, Loss: 1.184482455253601, Accuracy: 71.352783203125, Test Loss: 1.0416178703308105, Test Accuracy: 66.94915008544922\n",
      "Epoch: 697, Loss: 1.1835359334945679, Accuracy: 71.352783203125, Test Loss: 1.0408028364181519, Test Accuracy: 66.94915008544922\n",
      "Epoch: 698, Loss: 1.1826032400131226, Accuracy: 71.352783203125, Test Loss: 1.0400563478469849, Test Accuracy: 66.94915008544922\n",
      "Epoch: 699, Loss: 1.1816685199737549, Accuracy: 71.352783203125, Test Loss: 1.0392001867294312, Test Accuracy: 66.94915008544922\n",
      "Epoch: 700, Loss: 1.1807410717010498, Accuracy: 71.352783203125, Test Loss: 1.038472294807434, Test Accuracy: 66.94915008544922\n",
      "Epoch: 701, Loss: 1.1798014640808105, Accuracy: 71.352783203125, Test Loss: 1.0376518964767456, Test Accuracy: 66.94915008544922\n",
      "Epoch: 702, Loss: 1.178876519203186, Accuracy: 71.352783203125, Test Loss: 1.0368863344192505, Test Accuracy: 66.94915008544922\n",
      "Epoch: 703, Loss: 1.1779533624649048, Accuracy: 71.352783203125, Test Loss: 1.036124348640442, Test Accuracy: 66.94915008544922\n",
      "Epoch: 704, Loss: 1.177026629447937, Accuracy: 71.352783203125, Test Loss: 1.0353113412857056, Test Accuracy: 66.94915008544922\n",
      "Epoch: 705, Loss: 1.1761164665222168, Accuracy: 71.352783203125, Test Loss: 1.0345937013626099, Test Accuracy: 66.94915008544922\n",
      "Epoch: 706, Loss: 1.1751960515975952, Accuracy: 71.352783203125, Test Loss: 1.0337762832641602, Test Accuracy: 66.94915008544922\n",
      "Epoch: 707, Loss: 1.1742842197418213, Accuracy: 71.352783203125, Test Loss: 1.0330455303192139, Test Accuracy: 66.94915008544922\n",
      "Epoch: 708, Loss: 1.1733702421188354, Accuracy: 71.352783203125, Test Loss: 1.0322858095169067, Test Accuracy: 66.94915008544922\n",
      "Epoch: 709, Loss: 1.17245352268219, Accuracy: 71.352783203125, Test Loss: 1.031511664390564, Test Accuracy: 66.94915008544922\n",
      "Epoch: 710, Loss: 1.171559453010559, Accuracy: 71.352783203125, Test Loss: 1.0307674407958984, Test Accuracy: 66.94915008544922\n",
      "Epoch: 711, Loss: 1.1706448793411255, Accuracy: 71.352783203125, Test Loss: 1.030012845993042, Test Accuracy: 66.94915008544922\n",
      "Epoch: 712, Loss: 1.1697384119033813, Accuracy: 71.352783203125, Test Loss: 1.029276967048645, Test Accuracy: 66.94915008544922\n",
      "Epoch: 713, Loss: 1.168845295906067, Accuracy: 71.352783203125, Test Loss: 1.0285080671310425, Test Accuracy: 66.94915008544922\n",
      "Epoch: 714, Loss: 1.1679421663284302, Accuracy: 71.352783203125, Test Loss: 1.0277873277664185, Test Accuracy: 66.94915008544922\n",
      "Epoch: 715, Loss: 1.167052984237671, Accuracy: 71.352783203125, Test Loss: 1.0270624160766602, Test Accuracy: 66.94915008544922\n",
      "Epoch: 716, Loss: 1.1661601066589355, Accuracy: 71.352783203125, Test Loss: 1.0262882709503174, Test Accuracy: 66.94915008544922\n",
      "Epoch: 717, Loss: 1.1652746200561523, Accuracy: 71.352783203125, Test Loss: 1.0256154537200928, Test Accuracy: 66.94915008544922\n",
      "Epoch: 718, Loss: 1.1643847227096558, Accuracy: 71.352783203125, Test Loss: 1.0248225927352905, Test Accuracy: 66.94915008544922\n",
      "Epoch: 719, Loss: 1.163495659828186, Accuracy: 71.6180419921875, Test Loss: 1.0241461992263794, Test Accuracy: 66.94915008544922\n",
      "Epoch: 720, Loss: 1.1626214981079102, Accuracy: 71.6180419921875, Test Loss: 1.0234298706054688, Test Accuracy: 66.94915008544922\n",
      "Epoch: 721, Loss: 1.1617335081100464, Accuracy: 71.6180419921875, Test Loss: 1.0226589441299438, Test Accuracy: 66.94915008544922\n",
      "Epoch: 722, Loss: 1.1608575582504272, Accuracy: 71.6180419921875, Test Loss: 1.0220195055007935, Test Accuracy: 66.94915008544922\n",
      "Epoch: 723, Loss: 1.1599833965301514, Accuracy: 71.6180419921875, Test Loss: 1.0212595462799072, Test Accuracy: 66.94915008544922\n",
      "Epoch: 724, Loss: 1.159105896949768, Accuracy: 71.6180419921875, Test Loss: 1.0205706357955933, Test Accuracy: 66.94915008544922\n",
      "Epoch: 725, Loss: 1.1582293510437012, Accuracy: 71.6180419921875, Test Loss: 1.0198572874069214, Test Accuracy: 66.94915008544922\n",
      "Epoch: 726, Loss: 1.1573699712753296, Accuracy: 71.6180419921875, Test Loss: 1.0191521644592285, Test Accuracy: 66.94915008544922\n",
      "Epoch: 727, Loss: 1.1564998626708984, Accuracy: 71.6180419921875, Test Loss: 1.0184743404388428, Test Accuracy: 66.94915008544922\n",
      "Epoch: 728, Loss: 1.1556365489959717, Accuracy: 71.6180419921875, Test Loss: 1.017748236656189, Test Accuracy: 66.94915008544922\n",
      "Epoch: 729, Loss: 1.1547733545303345, Accuracy: 71.6180419921875, Test Loss: 1.0170559883117676, Test Accuracy: 66.94915008544922\n",
      "Epoch: 730, Loss: 1.1539106369018555, Accuracy: 71.6180419921875, Test Loss: 1.0163896083831787, Test Accuracy: 66.94915008544922\n",
      "Epoch: 731, Loss: 1.1530543565750122, Accuracy: 71.6180419921875, Test Loss: 1.0156681537628174, Test Accuracy: 66.94915008544922\n",
      "Epoch: 732, Loss: 1.1521965265274048, Accuracy: 71.6180419921875, Test Loss: 1.01503586769104, Test Accuracy: 66.94915008544922\n",
      "Epoch: 733, Loss: 1.1513383388519287, Accuracy: 71.6180419921875, Test Loss: 1.0143024921417236, Test Accuracy: 66.94915008544922\n",
      "Epoch: 734, Loss: 1.1504918336868286, Accuracy: 71.6180419921875, Test Loss: 1.013653039932251, Test Accuracy: 66.94915008544922\n",
      "Epoch: 735, Loss: 1.1496456861495972, Accuracy: 71.6180419921875, Test Loss: 1.012985110282898, Test Accuracy: 66.94915008544922\n",
      "Epoch: 736, Loss: 1.1487963199615479, Accuracy: 71.6180419921875, Test Loss: 1.012280821800232, Test Accuracy: 66.94915008544922\n",
      "Epoch: 737, Loss: 1.1479476690292358, Accuracy: 71.6180419921875, Test Loss: 1.0116521120071411, Test Accuracy: 66.94915008544922\n",
      "Epoch: 738, Loss: 1.1471025943756104, Accuracy: 71.6180419921875, Test Loss: 1.0109280347824097, Test Accuracy: 66.94915008544922\n",
      "Epoch: 739, Loss: 1.146264672279358, Accuracy: 71.6180419921875, Test Loss: 1.0103085041046143, Test Accuracy: 66.94915008544922\n",
      "Epoch: 740, Loss: 1.1454336643218994, Accuracy: 71.6180419921875, Test Loss: 1.0096043348312378, Test Accuracy: 66.94915008544922\n",
      "Epoch: 741, Loss: 1.14458167552948, Accuracy: 71.6180419921875, Test Loss: 1.008951187133789, Test Accuracy: 66.94915008544922\n",
      "Epoch: 742, Loss: 1.143749713897705, Accuracy: 71.6180419921875, Test Loss: 1.008323311805725, Test Accuracy: 66.94915008544922\n",
      "Epoch: 743, Loss: 1.142917275428772, Accuracy: 71.6180419921875, Test Loss: 1.0076136589050293, Test Accuracy: 66.94915008544922\n",
      "Epoch: 744, Loss: 1.1420847177505493, Accuracy: 71.6180419921875, Test Loss: 1.0070219039916992, Test Accuracy: 66.94915008544922\n",
      "Epoch: 745, Loss: 1.141250729560852, Accuracy: 71.6180419921875, Test Loss: 1.006301999092102, Test Accuracy: 66.94915008544922\n",
      "Epoch: 746, Loss: 1.1404273509979248, Accuracy: 71.6180419921875, Test Loss: 1.005717396736145, Test Accuracy: 66.94915008544922\n",
      "Epoch: 747, Loss: 1.139606237411499, Accuracy: 71.6180419921875, Test Loss: 1.0050464868545532, Test Accuracy: 66.94915008544922\n",
      "Epoch: 748, Loss: 1.138775110244751, Accuracy: 71.6180419921875, Test Loss: 1.0043847560882568, Test Accuracy: 67.79661560058594\n",
      "Epoch: 749, Loss: 1.1379605531692505, Accuracy: 71.6180419921875, Test Loss: 1.0037953853607178, Test Accuracy: 67.79661560058594\n",
      "Epoch: 750, Loss: 1.13712739944458, Accuracy: 71.6180419921875, Test Loss: 1.0030983686447144, Test Accuracy: 67.79661560058594\n",
      "Epoch: 751, Loss: 1.136313557624817, Accuracy: 71.6180419921875, Test Loss: 1.0025265216827393, Test Accuracy: 67.79661560058594\n",
      "Epoch: 752, Loss: 1.135499119758606, Accuracy: 71.6180419921875, Test Loss: 1.0018584728240967, Test Accuracy: 67.79661560058594\n",
      "Epoch: 753, Loss: 1.1346858739852905, Accuracy: 71.88328552246094, Test Loss: 1.0012480020523071, Test Accuracy: 67.79661560058594\n",
      "Epoch: 754, Loss: 1.1338706016540527, Accuracy: 71.88328552246094, Test Loss: 1.0006186962127686, Test Accuracy: 67.79661560058594\n",
      "Epoch: 755, Loss: 1.133065104484558, Accuracy: 71.88328552246094, Test Loss: 0.9999802708625793, Test Accuracy: 67.79661560058594\n",
      "Epoch: 756, Loss: 1.1322524547576904, Accuracy: 71.88328552246094, Test Loss: 0.9993775486946106, Test Accuracy: 67.79661560058594\n",
      "Epoch: 757, Loss: 1.13144052028656, Accuracy: 71.88328552246094, Test Loss: 0.9987335205078125, Test Accuracy: 67.79661560058594\n",
      "Epoch: 758, Loss: 1.1306465864181519, Accuracy: 71.88328552246094, Test Loss: 0.9981555342674255, Test Accuracy: 67.79661560058594\n",
      "Epoch: 759, Loss: 1.12984037399292, Accuracy: 71.88328552246094, Test Loss: 0.997490406036377, Test Accuracy: 67.79661560058594\n",
      "Epoch: 760, Loss: 1.1290377378463745, Accuracy: 71.88328552246094, Test Loss: 0.9969390034675598, Test Accuracy: 67.79661560058594\n",
      "Epoch: 761, Loss: 1.1282317638397217, Accuracy: 71.88328552246094, Test Loss: 0.9962477087974548, Test Accuracy: 67.79661560058594\n",
      "Epoch: 762, Loss: 1.1274338960647583, Accuracy: 71.88328552246094, Test Loss: 0.9957125782966614, Test Accuracy: 67.79661560058594\n",
      "Epoch: 763, Loss: 1.1266390085220337, Accuracy: 71.88328552246094, Test Loss: 0.9950547814369202, Test Accuracy: 67.79661560058594\n",
      "Epoch: 764, Loss: 1.1258491277694702, Accuracy: 71.6180419921875, Test Loss: 0.994465708732605, Test Accuracy: 67.79661560058594\n",
      "Epoch: 765, Loss: 1.1250450611114502, Accuracy: 71.6180419921875, Test Loss: 0.9939013719558716, Test Accuracy: 67.79661560058594\n",
      "Epoch: 766, Loss: 1.1242601871490479, Accuracy: 71.6180419921875, Test Loss: 0.9932258725166321, Test Accuracy: 67.79661560058594\n",
      "Epoch: 767, Loss: 1.123471975326538, Accuracy: 71.6180419921875, Test Loss: 0.9927148818969727, Test Accuracy: 67.79661560058594\n",
      "Epoch: 768, Loss: 1.122680425643921, Accuracy: 71.6180419921875, Test Loss: 0.9920346140861511, Test Accuracy: 67.79661560058594\n",
      "Epoch: 769, Loss: 1.1218957901000977, Accuracy: 71.6180419921875, Test Loss: 0.991503119468689, Test Accuracy: 67.79661560058594\n",
      "Epoch: 770, Loss: 1.121112585067749, Accuracy: 71.6180419921875, Test Loss: 0.9909089207649231, Test Accuracy: 67.79661560058594\n",
      "Epoch: 771, Loss: 1.1203221082687378, Accuracy: 71.6180419921875, Test Loss: 0.9902721047401428, Test Accuracy: 67.79661560058594\n",
      "Epoch: 772, Loss: 1.1195398569107056, Accuracy: 71.6180419921875, Test Loss: 0.9897459149360657, Test Accuracy: 68.64407348632812\n",
      "Epoch: 773, Loss: 1.1187618970870972, Accuracy: 71.6180419921875, Test Loss: 0.9891111850738525, Test Accuracy: 68.64407348632812\n",
      "Epoch: 774, Loss: 1.1179828643798828, Accuracy: 71.6180419921875, Test Loss: 0.9885491132736206, Test Accuracy: 68.64407348632812\n",
      "Epoch: 775, Loss: 1.1172075271606445, Accuracy: 71.6180419921875, Test Loss: 0.9879813194274902, Test Accuracy: 68.64407348632812\n",
      "Epoch: 776, Loss: 1.1164309978485107, Accuracy: 71.88328552246094, Test Loss: 0.9873557686805725, Test Accuracy: 68.64407348632812\n",
      "Epoch: 777, Loss: 1.1156558990478516, Accuracy: 71.88328552246094, Test Loss: 0.9868795275688171, Test Accuracy: 68.64407348632812\n",
      "Epoch: 778, Loss: 1.114890694618225, Accuracy: 71.88328552246094, Test Loss: 0.9861990809440613, Test Accuracy: 68.64407348632812\n",
      "Epoch: 779, Loss: 1.1141148805618286, Accuracy: 71.88328552246094, Test Loss: 0.9857033491134644, Test Accuracy: 68.64407348632812\n",
      "Epoch: 780, Loss: 1.1133408546447754, Accuracy: 71.88328552246094, Test Loss: 0.9850996732711792, Test Accuracy: 68.64407348632812\n",
      "Epoch: 781, Loss: 1.1125781536102295, Accuracy: 71.88328552246094, Test Loss: 0.9844969511032104, Test Accuracy: 68.64407348632812\n",
      "Epoch: 782, Loss: 1.1118144989013672, Accuracy: 71.88328552246094, Test Loss: 0.984015941619873, Test Accuracy: 68.64407348632812\n",
      "Epoch: 783, Loss: 1.111046314239502, Accuracy: 71.88328552246094, Test Loss: 0.9833546876907349, Test Accuracy: 68.64407348632812\n",
      "Epoch: 784, Loss: 1.1102842092514038, Accuracy: 71.88328552246094, Test Loss: 0.9828712344169617, Test Accuracy: 68.64407348632812\n",
      "Epoch: 785, Loss: 1.1095279455184937, Accuracy: 71.88328552246094, Test Loss: 0.982279360294342, Test Accuracy: 68.64407348632812\n",
      "Epoch: 786, Loss: 1.108762502670288, Accuracy: 71.88328552246094, Test Loss: 0.9817038774490356, Test Accuracy: 68.64407348632812\n",
      "Epoch: 787, Loss: 1.1080068349838257, Accuracy: 71.88328552246094, Test Loss: 0.9812002778053284, Test Accuracy: 69.49152374267578\n",
      "Epoch: 788, Loss: 1.1072485446929932, Accuracy: 71.88328552246094, Test Loss: 0.9805743098258972, Test Accuracy: 69.49152374267578\n",
      "Epoch: 789, Loss: 1.1064881086349487, Accuracy: 71.88328552246094, Test Loss: 0.9800630807876587, Test Accuracy: 69.49152374267578\n",
      "Epoch: 790, Loss: 1.10573410987854, Accuracy: 71.88328552246094, Test Loss: 0.9795084595680237, Test Accuracy: 69.49152374267578\n",
      "Epoch: 791, Loss: 1.1049779653549194, Accuracy: 71.88328552246094, Test Loss: 0.9789544343948364, Test Accuracy: 69.49152374267578\n",
      "Epoch: 792, Loss: 1.1042369604110718, Accuracy: 71.88328552246094, Test Loss: 0.9784321188926697, Test Accuracy: 69.49152374267578\n",
      "Epoch: 793, Loss: 1.1034870147705078, Accuracy: 71.88328552246094, Test Loss: 0.9778375625610352, Test Accuracy: 69.49152374267578\n",
      "Epoch: 794, Loss: 1.1027297973632812, Accuracy: 71.88328552246094, Test Loss: 0.9773362278938293, Test Accuracy: 69.49152374267578\n",
      "Epoch: 795, Loss: 1.1019880771636963, Accuracy: 71.88328552246094, Test Loss: 0.9767619371414185, Test Accuracy: 69.49152374267578\n",
      "Epoch: 796, Loss: 1.1012380123138428, Accuracy: 71.88328552246094, Test Loss: 0.9762378334999084, Test Accuracy: 69.49152374267578\n",
      "Epoch: 797, Loss: 1.1005040407180786, Accuracy: 71.88328552246094, Test Loss: 0.9756916761398315, Test Accuracy: 69.49152374267578\n",
      "Epoch: 798, Loss: 1.0997552871704102, Accuracy: 71.88328552246094, Test Loss: 0.9751465916633606, Test Accuracy: 69.49152374267578\n",
      "Epoch: 799, Loss: 1.0990104675292969, Accuracy: 71.88328552246094, Test Loss: 0.9746460914611816, Test Accuracy: 69.49152374267578\n",
      "Epoch: 800, Loss: 1.0982757806777954, Accuracy: 71.88328552246094, Test Loss: 0.9740529656410217, Test Accuracy: 69.49152374267578\n",
      "Epoch: 801, Loss: 1.0975316762924194, Accuracy: 71.88328552246094, Test Loss: 0.9736074209213257, Test Accuracy: 69.49152374267578\n",
      "Epoch: 802, Loss: 1.0968016386032104, Accuracy: 71.88328552246094, Test Loss: 0.9729928374290466, Test Accuracy: 69.49152374267578\n",
      "Epoch: 803, Loss: 1.096061110496521, Accuracy: 71.88328552246094, Test Loss: 0.9725219011306763, Test Accuracy: 69.49152374267578\n",
      "Epoch: 804, Loss: 1.0953283309936523, Accuracy: 71.88328552246094, Test Loss: 0.9719619750976562, Test Accuracy: 69.49152374267578\n",
      "Epoch: 805, Loss: 1.094597339630127, Accuracy: 71.88328552246094, Test Loss: 0.9714514017105103, Test Accuracy: 69.49152374267578\n",
      "Epoch: 806, Loss: 1.093856692314148, Accuracy: 72.41378784179688, Test Loss: 0.9709320068359375, Test Accuracy: 69.49152374267578\n",
      "Epoch: 807, Loss: 1.0931226015090942, Accuracy: 72.41378784179688, Test Loss: 0.9703943133354187, Test Accuracy: 69.49152374267578\n",
      "Epoch: 808, Loss: 1.092396855354309, Accuracy: 72.41378784179688, Test Loss: 0.9698960185050964, Test Accuracy: 69.49152374267578\n",
      "Epoch: 809, Loss: 1.0916690826416016, Accuracy: 72.41378784179688, Test Loss: 0.9693551063537598, Test Accuracy: 69.49152374267578\n",
      "Epoch: 810, Loss: 1.090941071510315, Accuracy: 72.41378784179688, Test Loss: 0.9688357710838318, Test Accuracy: 69.49152374267578\n",
      "Epoch: 811, Loss: 1.0902113914489746, Accuracy: 72.41378784179688, Test Loss: 0.9683380722999573, Test Accuracy: 69.49152374267578\n",
      "Epoch: 812, Loss: 1.0894904136657715, Accuracy: 72.41378784179688, Test Loss: 0.9677790403366089, Test Accuracy: 69.49152374267578\n",
      "Epoch: 813, Loss: 1.0887641906738281, Accuracy: 72.41378784179688, Test Loss: 0.9673370122909546, Test Accuracy: 69.49152374267578\n",
      "Epoch: 814, Loss: 1.088049054145813, Accuracy: 72.41378784179688, Test Loss: 0.9667807817459106, Test Accuracy: 69.49152374267578\n",
      "Epoch: 815, Loss: 1.0873228311538696, Accuracy: 72.41378784179688, Test Loss: 0.9662745594978333, Test Accuracy: 69.49152374267578\n",
      "Epoch: 816, Loss: 1.0866035223007202, Accuracy: 72.41378784179688, Test Loss: 0.965814471244812, Test Accuracy: 69.49152374267578\n",
      "Epoch: 817, Loss: 1.0858815908432007, Accuracy: 72.41378784179688, Test Loss: 0.9652173519134521, Test Accuracy: 69.49152374267578\n",
      "Epoch: 818, Loss: 1.0851707458496094, Accuracy: 72.41378784179688, Test Loss: 0.9648236036300659, Test Accuracy: 69.49152374267578\n",
      "Epoch: 819, Loss: 1.0844563245773315, Accuracy: 72.41378784179688, Test Loss: 0.9642151594161987, Test Accuracy: 68.64407348632812\n",
      "Epoch: 820, Loss: 1.0837322473526, Accuracy: 72.41378784179688, Test Loss: 0.963772714138031, Test Accuracy: 68.64407348632812\n",
      "Epoch: 821, Loss: 1.0830154418945312, Accuracy: 72.41378784179688, Test Loss: 0.9632608294487, Test Accuracy: 68.64407348632812\n",
      "Epoch: 822, Loss: 1.0823050737380981, Accuracy: 72.41378784179688, Test Loss: 0.9627183675765991, Test Accuracy: 68.64407348632812\n",
      "Epoch: 823, Loss: 1.0815954208374023, Accuracy: 72.41378784179688, Test Loss: 0.9622880816459656, Test Accuracy: 68.64407348632812\n",
      "Epoch: 824, Loss: 1.0808870792388916, Accuracy: 72.41378784179688, Test Loss: 0.9617342948913574, Test Accuracy: 68.64407348632812\n",
      "Epoch: 825, Loss: 1.0801682472229004, Accuracy: 72.41378784179688, Test Loss: 0.9612585306167603, Test Accuracy: 68.64407348632812\n",
      "Epoch: 826, Loss: 1.0794646739959717, Accuracy: 72.41378784179688, Test Loss: 0.9607748985290527, Test Accuracy: 68.64407348632812\n",
      "Epoch: 827, Loss: 1.0787626504898071, Accuracy: 72.41378784179688, Test Loss: 0.9602529406547546, Test Accuracy: 68.64407348632812\n",
      "Epoch: 828, Loss: 1.0780541896820068, Accuracy: 72.67904663085938, Test Loss: 0.9598084092140198, Test Accuracy: 68.64407348632812\n",
      "Epoch: 829, Loss: 1.0773531198501587, Accuracy: 72.67904663085938, Test Loss: 0.9592612385749817, Test Accuracy: 68.64407348632812\n",
      "Epoch: 830, Loss: 1.076638102531433, Accuracy: 72.67904663085938, Test Loss: 0.9588189125061035, Test Accuracy: 68.64407348632812\n",
      "Epoch: 831, Loss: 1.0759395360946655, Accuracy: 72.67904663085938, Test Loss: 0.9583043456077576, Test Accuracy: 68.64407348632812\n",
      "Epoch: 832, Loss: 1.0752434730529785, Accuracy: 72.67904663085938, Test Loss: 0.9578324556350708, Test Accuracy: 68.64407348632812\n",
      "Epoch: 833, Loss: 1.0745376348495483, Accuracy: 72.67904663085938, Test Loss: 0.9573461413383484, Test Accuracy: 68.64407348632812\n",
      "Epoch: 834, Loss: 1.0738451480865479, Accuracy: 72.67904663085938, Test Loss: 0.9568490982055664, Test Accuracy: 68.64407348632812\n",
      "Epoch: 835, Loss: 1.0731486082077026, Accuracy: 72.67904663085938, Test Loss: 0.9563932418823242, Test Accuracy: 68.64407348632812\n",
      "Epoch: 836, Loss: 1.0724455118179321, Accuracy: 72.67904663085938, Test Loss: 0.955879807472229, Test Accuracy: 68.64407348632812\n",
      "Epoch: 837, Loss: 1.0717521905899048, Accuracy: 72.67904663085938, Test Loss: 0.9554079174995422, Test Accuracy: 68.64407348632812\n",
      "Epoch: 838, Loss: 1.0710598230361938, Accuracy: 72.67904663085938, Test Loss: 0.9549420475959778, Test Accuracy: 68.64407348632812\n",
      "Epoch: 839, Loss: 1.0703603029251099, Accuracy: 72.67904663085938, Test Loss: 0.9544410109519958, Test Accuracy: 68.64407348632812\n",
      "Epoch: 840, Loss: 1.0696625709533691, Accuracy: 72.67904663085938, Test Loss: 0.9539971351623535, Test Accuracy: 68.64407348632812\n",
      "Epoch: 841, Loss: 1.0689778327941895, Accuracy: 72.67904663085938, Test Loss: 0.9535143375396729, Test Accuracy: 68.64407348632812\n",
      "Epoch: 842, Loss: 1.0682886838912964, Accuracy: 72.67904663085938, Test Loss: 0.9530333280563354, Test Accuracy: 68.64407348632812\n",
      "Epoch: 843, Loss: 1.0676053762435913, Accuracy: 72.67904663085938, Test Loss: 0.9525724053382874, Test Accuracy: 69.49152374267578\n",
      "Epoch: 844, Loss: 1.066912293434143, Accuracy: 72.67904663085938, Test Loss: 0.9521031379699707, Test Accuracy: 69.49152374267578\n",
      "Epoch: 845, Loss: 1.0662236213684082, Accuracy: 72.67904663085938, Test Loss: 0.9516368508338928, Test Accuracy: 69.49152374267578\n",
      "Epoch: 846, Loss: 1.0655404329299927, Accuracy: 72.67904663085938, Test Loss: 0.9511669874191284, Test Accuracy: 69.49152374267578\n",
      "Epoch: 847, Loss: 1.0648555755615234, Accuracy: 72.67904663085938, Test Loss: 0.9507009983062744, Test Accuracy: 69.49152374267578\n",
      "Epoch: 848, Loss: 1.0641658306121826, Accuracy: 72.67904663085938, Test Loss: 0.9502425193786621, Test Accuracy: 69.49152374267578\n",
      "Epoch: 849, Loss: 1.0634849071502686, Accuracy: 72.67904663085938, Test Loss: 0.9497434496879578, Test Accuracy: 69.49152374267578\n",
      "Epoch: 850, Loss: 1.062808632850647, Accuracy: 72.67904663085938, Test Loss: 0.9493190050125122, Test Accuracy: 69.49152374267578\n",
      "Epoch: 851, Loss: 1.0621236562728882, Accuracy: 72.67904663085938, Test Loss: 0.9488319158554077, Test Accuracy: 69.49152374267578\n",
      "Epoch: 852, Loss: 1.061443567276001, Accuracy: 72.67904663085938, Test Loss: 0.9483869075775146, Test Accuracy: 69.49152374267578\n",
      "Epoch: 853, Loss: 1.0607579946517944, Accuracy: 72.67904663085938, Test Loss: 0.9479216933250427, Test Accuracy: 69.49152374267578\n",
      "Epoch: 854, Loss: 1.0600849390029907, Accuracy: 72.67904663085938, Test Loss: 0.94744473695755, Test Accuracy: 69.49152374267578\n",
      "Epoch: 855, Loss: 1.0594062805175781, Accuracy: 72.67904663085938, Test Loss: 0.9470248222351074, Test Accuracy: 69.49152374267578\n",
      "Epoch: 856, Loss: 1.0587263107299805, Accuracy: 72.67904663085938, Test Loss: 0.946535587310791, Test Accuracy: 69.49152374267578\n",
      "Epoch: 857, Loss: 1.0580594539642334, Accuracy: 72.67904663085938, Test Loss: 0.946086049079895, Test Accuracy: 69.49152374267578\n",
      "Epoch: 858, Loss: 1.0573673248291016, Accuracy: 72.67904663085938, Test Loss: 0.9456425905227661, Test Accuracy: 69.49152374267578\n",
      "Epoch: 859, Loss: 1.056703805923462, Accuracy: 72.67904663085938, Test Loss: 0.9451714158058167, Test Accuracy: 69.49152374267578\n",
      "Epoch: 860, Loss: 1.056023359298706, Accuracy: 72.67904663085938, Test Loss: 0.944744884967804, Test Accuracy: 69.49152374267578\n",
      "Epoch: 861, Loss: 1.0553597211837769, Accuracy: 72.67904663085938, Test Loss: 0.9442803263664246, Test Accuracy: 69.49152374267578\n",
      "Epoch: 862, Loss: 1.0546891689300537, Accuracy: 72.67904663085938, Test Loss: 0.9438125491142273, Test Accuracy: 69.49152374267578\n",
      "Epoch: 863, Loss: 1.0540250539779663, Accuracy: 72.67904663085938, Test Loss: 0.943401575088501, Test Accuracy: 69.49152374267578\n",
      "Epoch: 864, Loss: 1.0533437728881836, Accuracy: 72.67904663085938, Test Loss: 0.942878246307373, Test Accuracy: 69.49152374267578\n",
      "Epoch: 865, Loss: 1.0526809692382812, Accuracy: 72.67904663085938, Test Loss: 0.9425077438354492, Test Accuracy: 69.49152374267578\n",
      "Epoch: 866, Loss: 1.0520176887512207, Accuracy: 72.67904663085938, Test Loss: 0.942011833190918, Test Accuracy: 69.49152374267578\n",
      "Epoch: 867, Loss: 1.0513461828231812, Accuracy: 72.67904663085938, Test Loss: 0.9415838718414307, Test Accuracy: 69.49152374267578\n",
      "Epoch: 868, Loss: 1.050682783126831, Accuracy: 72.67904663085938, Test Loss: 0.941166877746582, Test Accuracy: 69.49152374267578\n",
      "Epoch: 869, Loss: 1.0500162839889526, Accuracy: 72.67904663085938, Test Loss: 0.9406602382659912, Test Accuracy: 69.49152374267578\n",
      "Epoch: 870, Loss: 1.049351692199707, Accuracy: 72.67904663085938, Test Loss: 0.9402899742126465, Test Accuracy: 69.49152374267578\n",
      "Epoch: 871, Loss: 1.0486857891082764, Accuracy: 72.67904663085938, Test Loss: 0.9397884011268616, Test Accuracy: 69.49152374267578\n",
      "Epoch: 872, Loss: 1.048039197921753, Accuracy: 72.67904663085938, Test Loss: 0.9393906593322754, Test Accuracy: 69.49152374267578\n",
      "Epoch: 873, Loss: 1.0473672151565552, Accuracy: 72.67904663085938, Test Loss: 0.938921332359314, Test Accuracy: 69.49152374267578\n",
      "Epoch: 874, Loss: 1.0467073917388916, Accuracy: 72.67904663085938, Test Loss: 0.9384909272193909, Test Accuracy: 69.49152374267578\n",
      "Epoch: 875, Loss: 1.0460546016693115, Accuracy: 72.67904663085938, Test Loss: 0.9380812048912048, Test Accuracy: 69.49152374267578\n",
      "Epoch: 876, Loss: 1.045393705368042, Accuracy: 72.67904663085938, Test Loss: 0.9376115798950195, Test Accuracy: 69.49152374267578\n",
      "Epoch: 877, Loss: 1.0447337627410889, Accuracy: 72.67904663085938, Test Loss: 0.9372081160545349, Test Accuracy: 69.49152374267578\n",
      "Epoch: 878, Loss: 1.0440781116485596, Accuracy: 72.67904663085938, Test Loss: 0.9367347359657288, Test Accuracy: 69.49152374267578\n",
      "Epoch: 879, Loss: 1.0434268712997437, Accuracy: 72.67904663085938, Test Loss: 0.9363341927528381, Test Accuracy: 69.49152374267578\n",
      "Epoch: 880, Loss: 1.0427690744400024, Accuracy: 72.67904663085938, Test Loss: 0.9358674883842468, Test Accuracy: 69.49152374267578\n",
      "Epoch: 881, Loss: 1.0421136617660522, Accuracy: 72.67904663085938, Test Loss: 0.9354704022407532, Test Accuracy: 69.49152374267578\n",
      "Epoch: 882, Loss: 1.0414619445800781, Accuracy: 72.67904663085938, Test Loss: 0.935018002986908, Test Accuracy: 69.49152374267578\n",
      "Epoch: 883, Loss: 1.0408172607421875, Accuracy: 72.67904663085938, Test Loss: 0.9345903992652893, Test Accuracy: 69.49152374267578\n",
      "Epoch: 884, Loss: 1.040157675743103, Accuracy: 72.67904663085938, Test Loss: 0.9341636896133423, Test Accuracy: 69.49152374267578\n",
      "Epoch: 885, Loss: 1.0395108461380005, Accuracy: 72.67904663085938, Test Loss: 0.9337224364280701, Test Accuracy: 69.49152374267578\n",
      "Epoch: 886, Loss: 1.038861870765686, Accuracy: 72.67904663085938, Test Loss: 0.9333363175392151, Test Accuracy: 69.49152374267578\n",
      "Epoch: 887, Loss: 1.0382137298583984, Accuracy: 72.67904663085938, Test Loss: 0.9328698515892029, Test Accuracy: 69.49152374267578\n",
      "Epoch: 888, Loss: 1.037564754486084, Accuracy: 72.67904663085938, Test Loss: 0.9324699640274048, Test Accuracy: 69.49152374267578\n",
      "Epoch: 889, Loss: 1.0369162559509277, Accuracy: 72.41378784179688, Test Loss: 0.9320337176322937, Test Accuracy: 69.49152374267578\n",
      "Epoch: 890, Loss: 1.0362741947174072, Accuracy: 72.41378784179688, Test Loss: 0.9315900802612305, Test Accuracy: 69.49152374267578\n",
      "Epoch: 891, Loss: 1.0356310606002808, Accuracy: 72.41378784179688, Test Loss: 0.931213915348053, Test Accuracy: 69.49152374267578\n",
      "Epoch: 892, Loss: 1.0349737405776978, Accuracy: 72.41378784179688, Test Loss: 0.9307272434234619, Test Accuracy: 69.49152374267578\n",
      "Epoch: 893, Loss: 1.0343339443206787, Accuracy: 72.41378784179688, Test Loss: 0.9303584694862366, Test Accuracy: 69.49152374267578\n",
      "Epoch: 894, Loss: 1.033697485923767, Accuracy: 72.41378784179688, Test Loss: 0.9299135804176331, Test Accuracy: 69.49152374267578\n",
      "Epoch: 895, Loss: 1.033050298690796, Accuracy: 72.41378784179688, Test Loss: 0.9294794201850891, Test Accuracy: 69.49152374267578\n",
      "Epoch: 896, Loss: 1.0324089527130127, Accuracy: 72.41378784179688, Test Loss: 0.9291125535964966, Test Accuracy: 69.49152374267578\n",
      "Epoch: 897, Loss: 1.0317673683166504, Accuracy: 72.41378784179688, Test Loss: 0.928623616695404, Test Accuracy: 69.49152374267578\n",
      "Epoch: 898, Loss: 1.0311282873153687, Accuracy: 72.41378784179688, Test Loss: 0.928266167640686, Test Accuracy: 69.49152374267578\n",
      "Epoch: 899, Loss: 1.030490756034851, Accuracy: 72.41378784179688, Test Loss: 0.9278178811073303, Test Accuracy: 69.49152374267578\n",
      "Epoch: 900, Loss: 1.0298599004745483, Accuracy: 72.41378784179688, Test Loss: 0.9273895621299744, Test Accuracy: 69.49152374267578\n",
      "Epoch: 901, Loss: 1.0292145013809204, Accuracy: 72.41378784179688, Test Loss: 0.9270104765892029, Test Accuracy: 69.49152374267578\n",
      "Epoch: 902, Loss: 1.028578281402588, Accuracy: 72.41378784179688, Test Loss: 0.9265581965446472, Test Accuracy: 69.49152374267578\n",
      "Epoch: 903, Loss: 1.0279425382614136, Accuracy: 72.41378784179688, Test Loss: 0.926180362701416, Test Accuracy: 69.49152374267578\n",
      "Epoch: 904, Loss: 1.0273090600967407, Accuracy: 72.41378784179688, Test Loss: 0.9257385730743408, Test Accuracy: 69.49152374267578\n",
      "Epoch: 905, Loss: 1.0266761779785156, Accuracy: 72.41378784179688, Test Loss: 0.925329327583313, Test Accuracy: 69.49152374267578\n",
      "Epoch: 906, Loss: 1.0260326862335205, Accuracy: 72.41378784179688, Test Loss: 0.9249281287193298, Test Accuracy: 69.49152374267578\n",
      "Epoch: 907, Loss: 1.0254064798355103, Accuracy: 72.41378784179688, Test Loss: 0.924500048160553, Test Accuracy: 69.49152374267578\n",
      "Epoch: 908, Loss: 1.0247678756713867, Accuracy: 72.41378784179688, Test Loss: 0.9241108894348145, Test Accuracy: 69.49152374267578\n",
      "Epoch: 909, Loss: 1.0241440534591675, Accuracy: 72.41378784179688, Test Loss: 0.9236765503883362, Test Accuracy: 69.49152374267578\n",
      "Epoch: 910, Loss: 1.0235133171081543, Accuracy: 72.41378784179688, Test Loss: 0.9233030676841736, Test Accuracy: 69.49152374267578\n",
      "Epoch: 911, Loss: 1.0228835344314575, Accuracy: 72.41378784179688, Test Loss: 0.9228674173355103, Test Accuracy: 69.49152374267578\n",
      "Epoch: 912, Loss: 1.0222575664520264, Accuracy: 72.41378784179688, Test Loss: 0.9224879741668701, Test Accuracy: 69.49152374267578\n",
      "Epoch: 913, Loss: 1.021630883216858, Accuracy: 72.41378784179688, Test Loss: 0.922082781791687, Test Accuracy: 69.49152374267578\n",
      "Epoch: 914, Loss: 1.021004557609558, Accuracy: 72.41378784179688, Test Loss: 0.9216476678848267, Test Accuracy: 69.49152374267578\n",
      "Epoch: 915, Loss: 1.0203758478164673, Accuracy: 72.41378784179688, Test Loss: 0.9213069081306458, Test Accuracy: 69.49152374267578\n",
      "Epoch: 916, Loss: 1.0197540521621704, Accuracy: 72.41378784179688, Test Loss: 0.9208319783210754, Test Accuracy: 69.49152374267578\n",
      "Epoch: 917, Loss: 1.0191333293914795, Accuracy: 72.41378784179688, Test Loss: 0.9204832315444946, Test Accuracy: 69.49152374267578\n",
      "Epoch: 918, Loss: 1.0185034275054932, Accuracy: 72.41378784179688, Test Loss: 0.9200479388237, Test Accuracy: 70.33898162841797\n",
      "Epoch: 919, Loss: 1.0178807973861694, Accuracy: 72.41378784179688, Test Loss: 0.9196484684944153, Test Accuracy: 70.33898162841797\n",
      "Epoch: 920, Loss: 1.0172553062438965, Accuracy: 72.41378784179688, Test Loss: 0.9192718863487244, Test Accuracy: 70.33898162841797\n",
      "Epoch: 921, Loss: 1.0166343450546265, Accuracy: 72.67904663085938, Test Loss: 0.9188283681869507, Test Accuracy: 70.33898162841797\n",
      "Epoch: 922, Loss: 1.0160033702850342, Accuracy: 72.67904663085938, Test Loss: 0.9184596538543701, Test Accuracy: 70.33898162841797\n",
      "Epoch: 923, Loss: 1.0153963565826416, Accuracy: 72.67904663085938, Test Loss: 0.9180677533149719, Test Accuracy: 70.33898162841797\n",
      "Epoch: 924, Loss: 1.014766812324524, Accuracy: 72.67904663085938, Test Loss: 0.9176501631736755, Test Accuracy: 70.33898162841797\n",
      "Epoch: 925, Loss: 1.0141487121582031, Accuracy: 72.67904663085938, Test Loss: 0.9172948002815247, Test Accuracy: 70.33898162841797\n",
      "Epoch: 926, Loss: 1.0135380029678345, Accuracy: 72.67904663085938, Test Loss: 0.9168359041213989, Test Accuracy: 70.33898162841797\n",
      "Epoch: 927, Loss: 1.0129079818725586, Accuracy: 72.67904663085938, Test Loss: 0.9164869785308838, Test Accuracy: 70.33898162841797\n",
      "Epoch: 928, Loss: 1.01229989528656, Accuracy: 72.67904663085938, Test Loss: 0.9160672426223755, Test Accuracy: 70.33898162841797\n",
      "Epoch: 929, Loss: 1.0116863250732422, Accuracy: 72.67904663085938, Test Loss: 0.9156799912452698, Test Accuracy: 70.33898162841797\n",
      "Epoch: 930, Loss: 1.0110673904418945, Accuracy: 72.67904663085938, Test Loss: 0.91530442237854, Test Accuracy: 70.33898162841797\n",
      "Epoch: 931, Loss: 1.0104560852050781, Accuracy: 72.67904663085938, Test Loss: 0.9148798584938049, Test Accuracy: 70.33898162841797\n",
      "Epoch: 932, Loss: 1.009834885597229, Accuracy: 72.67904663085938, Test Loss: 0.9145170450210571, Test Accuracy: 70.33898162841797\n",
      "Epoch: 933, Loss: 1.0092229843139648, Accuracy: 72.67904663085938, Test Loss: 0.9141088724136353, Test Accuracy: 70.33898162841797\n",
      "Epoch: 934, Loss: 1.0086151361465454, Accuracy: 72.41378784179688, Test Loss: 0.913722574710846, Test Accuracy: 70.33898162841797\n",
      "Epoch: 935, Loss: 1.0079996585845947, Accuracy: 72.41378784179688, Test Loss: 0.9133297801017761, Test Accuracy: 70.33898162841797\n",
      "Epoch: 936, Loss: 1.0073853731155396, Accuracy: 72.41378784179688, Test Loss: 0.9129404425621033, Test Accuracy: 70.33898162841797\n",
      "Epoch: 937, Loss: 1.0067780017852783, Accuracy: 72.41378784179688, Test Loss: 0.9125429391860962, Test Accuracy: 70.33898162841797\n",
      "Epoch: 938, Loss: 1.0061712265014648, Accuracy: 72.41378784179688, Test Loss: 0.9121888279914856, Test Accuracy: 70.33898162841797\n",
      "Epoch: 939, Loss: 1.0055527687072754, Accuracy: 72.41378784179688, Test Loss: 0.9117335677146912, Test Accuracy: 70.33898162841797\n",
      "Epoch: 940, Loss: 1.0049481391906738, Accuracy: 72.41378784179688, Test Loss: 0.9114118218421936, Test Accuracy: 70.33898162841797\n",
      "Epoch: 941, Loss: 1.0043367147445679, Accuracy: 72.41378784179688, Test Loss: 0.9109672904014587, Test Accuracy: 70.33898162841797\n",
      "Epoch: 942, Loss: 1.0037339925765991, Accuracy: 72.41378784179688, Test Loss: 0.9106231331825256, Test Accuracy: 71.18643951416016\n",
      "Epoch: 943, Loss: 1.0031182765960693, Accuracy: 72.41378784179688, Test Loss: 0.9102005958557129, Test Accuracy: 71.18643951416016\n",
      "Epoch: 944, Loss: 1.002511978149414, Accuracy: 72.41378784179688, Test Loss: 0.90982985496521, Test Accuracy: 71.18643951416016\n",
      "Epoch: 945, Loss: 1.0019139051437378, Accuracy: 72.41378784179688, Test Loss: 0.9094702005386353, Test Accuracy: 71.18643951416016\n",
      "Epoch: 946, Loss: 1.001300573348999, Accuracy: 72.41378784179688, Test Loss: 0.9090243577957153, Test Accuracy: 71.18643951416016\n",
      "Epoch: 947, Loss: 1.000699758529663, Accuracy: 72.41378784179688, Test Loss: 0.9087043404579163, Test Accuracy: 71.18643951416016\n",
      "Epoch: 948, Loss: 1.00010347366333, Accuracy: 72.41378784179688, Test Loss: 0.9082970023155212, Test Accuracy: 72.03389739990234\n",
      "Epoch: 949, Loss: 0.9994925856590271, Accuracy: 72.41378784179688, Test Loss: 0.9078927636146545, Test Accuracy: 72.03389739990234\n",
      "Epoch: 950, Loss: 0.998897135257721, Accuracy: 72.41378784179688, Test Loss: 0.9075636267662048, Test Accuracy: 72.03389739990234\n",
      "Epoch: 951, Loss: 0.9982889890670776, Accuracy: 72.41378784179688, Test Loss: 0.907110869884491, Test Accuracy: 72.03389739990234\n",
      "Epoch: 952, Loss: 0.997692346572876, Accuracy: 72.41378784179688, Test Loss: 0.9068251848220825, Test Accuracy: 72.03389739990234\n",
      "Epoch: 953, Loss: 0.9970964789390564, Accuracy: 72.41378784179688, Test Loss: 0.9063428044319153, Test Accuracy: 72.03389739990234\n",
      "Epoch: 954, Loss: 0.9964877367019653, Accuracy: 72.41378784179688, Test Loss: 0.9060496091842651, Test Accuracy: 72.03389739990234\n",
      "Epoch: 955, Loss: 0.9958901405334473, Accuracy: 72.41378784179688, Test Loss: 0.9056347608566284, Test Accuracy: 72.03389739990234\n",
      "Epoch: 956, Loss: 0.9952988624572754, Accuracy: 72.41378784179688, Test Loss: 0.9052337408065796, Test Accuracy: 72.03389739990234\n",
      "Epoch: 957, Loss: 0.9946973323822021, Accuracy: 72.41378784179688, Test Loss: 0.9049287438392639, Test Accuracy: 72.03389739990234\n",
      "Epoch: 958, Loss: 0.9940970540046692, Accuracy: 72.41378784179688, Test Loss: 0.9044477343559265, Test Accuracy: 72.03389739990234\n",
      "Epoch: 959, Loss: 0.9935060739517212, Accuracy: 72.41378784179688, Test Loss: 0.9041696190834045, Test Accuracy: 72.03389739990234\n",
      "Epoch: 960, Loss: 0.9929174780845642, Accuracy: 72.41378784179688, Test Loss: 0.9037317633628845, Test Accuracy: 72.03389739990234\n",
      "Epoch: 961, Loss: 0.9923186302185059, Accuracy: 72.41378784179688, Test Loss: 0.9033621549606323, Test Accuracy: 72.03389739990234\n",
      "Epoch: 962, Loss: 0.9917208552360535, Accuracy: 72.41378784179688, Test Loss: 0.9030432105064392, Test Accuracy: 72.03389739990234\n",
      "Epoch: 963, Loss: 0.9911254644393921, Accuracy: 72.41378784179688, Test Loss: 0.902558445930481, Test Accuracy: 72.03389739990234\n",
      "Epoch: 964, Loss: 0.9905253052711487, Accuracy: 72.41378784179688, Test Loss: 0.9023211002349854, Test Accuracy: 72.03389739990234\n",
      "Epoch: 965, Loss: 0.9899409413337708, Accuracy: 72.41378784179688, Test Loss: 0.9018158316612244, Test Accuracy: 72.03389739990234\n",
      "Epoch: 966, Loss: 0.9893452525138855, Accuracy: 72.41378784179688, Test Loss: 0.9015364646911621, Test Accuracy: 72.03389739990234\n",
      "Epoch: 967, Loss: 0.9887616038322449, Accuracy: 72.41378784179688, Test Loss: 0.9011483788490295, Test Accuracy: 72.03389739990234\n",
      "Epoch: 968, Loss: 0.988172709941864, Accuracy: 72.41378784179688, Test Loss: 0.9007229804992676, Test Accuracy: 72.03389739990234\n",
      "Epoch: 969, Loss: 0.9875757098197937, Accuracy: 72.41378784179688, Test Loss: 0.9004707336425781, Test Accuracy: 72.03389739990234\n",
      "Epoch: 970, Loss: 0.9869893789291382, Accuracy: 72.1485366821289, Test Loss: 0.8999572396278381, Test Accuracy: 72.03389739990234\n",
      "Epoch: 971, Loss: 0.9863972663879395, Accuracy: 72.41378784179688, Test Loss: 0.8996972441673279, Test Accuracy: 72.03389739990234\n",
      "Epoch: 972, Loss: 0.9858129024505615, Accuracy: 72.1485366821289, Test Loss: 0.8992747068405151, Test Accuracy: 72.03389739990234\n",
      "Epoch: 973, Loss: 0.9852283000946045, Accuracy: 72.1485366821289, Test Loss: 0.898887038230896, Test Accuracy: 72.03389739990234\n",
      "Epoch: 974, Loss: 0.9846382737159729, Accuracy: 72.1485366821289, Test Loss: 0.8985987305641174, Test Accuracy: 72.03389739990234\n",
      "Epoch: 975, Loss: 0.9840494394302368, Accuracy: 72.1485366821289, Test Loss: 0.8981207013130188, Test Accuracy: 72.03389739990234\n",
      "Epoch: 976, Loss: 0.983470618724823, Accuracy: 72.1485366821289, Test Loss: 0.8978440165519714, Test Accuracy: 72.03389739990234\n",
      "Epoch: 977, Loss: 0.9828802943229675, Accuracy: 72.1485366821289, Test Loss: 0.8974097371101379, Test Accuracy: 72.03389739990234\n",
      "Epoch: 978, Loss: 0.9822984933853149, Accuracy: 72.1485366821289, Test Loss: 0.8970725536346436, Test Accuracy: 72.03389739990234\n",
      "Epoch: 979, Loss: 0.9817052483558655, Accuracy: 72.1485366821289, Test Loss: 0.8967017531394958, Test Accuracy: 72.03389739990234\n",
      "Epoch: 980, Loss: 0.9811322689056396, Accuracy: 72.1485366821289, Test Loss: 0.89631587266922, Test Accuracy: 72.03389739990234\n",
      "Epoch: 981, Loss: 0.9805464744567871, Accuracy: 72.1485366821289, Test Loss: 0.896003007888794, Test Accuracy: 72.03389739990234\n",
      "Epoch: 982, Loss: 0.9799614548683167, Accuracy: 72.1485366821289, Test Loss: 0.8955609798431396, Test Accuracy: 72.03389739990234\n",
      "Epoch: 983, Loss: 0.9793870449066162, Accuracy: 72.1485366821289, Test Loss: 0.8952734470367432, Test Accuracy: 72.03389739990234\n",
      "Epoch: 984, Loss: 0.9787999987602234, Accuracy: 72.1485366821289, Test Loss: 0.8948690295219421, Test Accuracy: 72.03389739990234\n",
      "Epoch: 985, Loss: 0.9782248735427856, Accuracy: 72.1485366821289, Test Loss: 0.8945069313049316, Test Accuracy: 72.03389739990234\n",
      "Epoch: 986, Loss: 0.9776440262794495, Accuracy: 72.1485366821289, Test Loss: 0.894169807434082, Test Accuracy: 72.03389739990234\n",
      "Epoch: 987, Loss: 0.9770587682723999, Accuracy: 72.1485366821289, Test Loss: 0.8937575817108154, Test Accuracy: 72.03389739990234\n",
      "Epoch: 988, Loss: 0.976477324962616, Accuracy: 72.1485366821289, Test Loss: 0.8934542536735535, Test Accuracy: 72.03389739990234\n",
      "Epoch: 989, Loss: 0.9758995175361633, Accuracy: 72.1485366821289, Test Loss: 0.8930273652076721, Test Accuracy: 72.03389739990234\n",
      "Epoch: 990, Loss: 0.9753212332725525, Accuracy: 72.1485366821289, Test Loss: 0.8927096724510193, Test Accuracy: 72.03389739990234\n",
      "Epoch: 991, Loss: 0.9747462868690491, Accuracy: 72.1485366821289, Test Loss: 0.8923469185829163, Test Accuracy: 72.03389739990234\n",
      "Epoch: 992, Loss: 0.9741670489311218, Accuracy: 72.1485366821289, Test Loss: 0.8919532299041748, Test Accuracy: 72.03389739990234\n",
      "Epoch: 993, Loss: 0.973598837852478, Accuracy: 72.1485366821289, Test Loss: 0.8916556239128113, Test Accuracy: 72.03389739990234\n",
      "Epoch: 994, Loss: 0.9730233550071716, Accuracy: 72.1485366821289, Test Loss: 0.8912335634231567, Test Accuracy: 72.03389739990234\n",
      "Epoch: 995, Loss: 0.9724404215812683, Accuracy: 72.1485366821289, Test Loss: 0.8909222483634949, Test Accuracy: 72.03389739990234\n",
      "Epoch: 996, Loss: 0.9718752503395081, Accuracy: 72.1485366821289, Test Loss: 0.890541672706604, Test Accuracy: 72.03389739990234\n",
      "Epoch: 997, Loss: 0.9713013172149658, Accuracy: 72.1485366821289, Test Loss: 0.8901780843734741, Test Accuracy: 72.03389739990234\n",
      "Epoch: 998, Loss: 0.9707236886024475, Accuracy: 72.1485366821289, Test Loss: 0.8898362517356873, Test Accuracy: 72.03389739990234\n",
      "Epoch: 999, Loss: 0.970150351524353, Accuracy: 72.1485366821289, Test Loss: 0.8894569277763367, Test Accuracy: 72.03389739990234\n"
     ]
    }
   ],
   "source": [
    "# Define loss function\n",
    "# Binary classification => BCELoss\n",
    "from models import train_binary_logits\n",
    "\n",
    "from models import MulticlassClassification\n",
    "from models import accuracy_fn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from matplotlib import pyplot as plt\n",
    "# TRAINING\n",
    "epochs = 10000\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_0.parameters(), lr=1E-6, momentum=0.9)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    model_0.train()\n",
    "\n",
    "    # 1. Forward pass\n",
    "    y_logits = model_0(X_train.to(device)).to(device)\n",
    "    y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
    "\n",
    "    #print(y_pred.shape)\n",
    "    # 2. Compute loss\n",
    "    loss = loss_fn(y_logits, y_train)\n",
    "    losses.append(loss)\n",
    "\n",
    "    # 2.1 Compute accuracy\n",
    "    acc = accuracy_fn(y_train, y_pred)\n",
    "\n",
    "    # 3. Optimizer zero_grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "    # 6. Test\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        # 6.1 Forward pass\n",
    "        test_logits = model_0(X_test).squeeze() \n",
    "        test_prob= torch.softmax(test_logits, dim = 1)\n",
    "        test_pred = torch.argmax(test_prob, dim = 1)\n",
    "        # 6.2 Compute loss\n",
    "        test_loss = loss_fn(test_logits, y_test)\n",
    "        # 6.3 Compute accuracy\n",
    "        test_acc = accuracy_fn(y_test, test_pred)\n",
    "    if epoch % 1 == 0:\n",
    "        print(\"Epoch: {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}\".format(epoch, loss, acc, test_loss, test_acc))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1.])\n",
      "tensor([-18.6728, -20.9609, -12.0012], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pred = model_0(X_test[10]).squeeze()\n",
    "print(y_test[10])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
